{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uiu/miniconda3/envs/tf_conda/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import nibabel\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from skimage.filters import unsharp_mask\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from skimage.transform import resize\n",
    "from dipy.align.imwarp import SymmetricDiffeomorphicRegistration\n",
    "from dipy.align.metrics import CCMetric\n",
    "from dipy.align.imaffine import AffineMap\n",
    "from dipy.align import resample\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Activation, Dense, Flatten\n",
    "from tensorflow.keras.layers import Conv3D, AveragePooling3D, MaxPooling3D\n",
    "from tensorflow.keras.layers import add, multiply, GlobalAveragePooling3D, GlobalMaxPooling3D, Reshape\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import six\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bn_relu(input):\n",
    "    \"\"\"Helper to build a BN -> relu block (by @raghakot).\"\"\"\n",
    "    norm = BatchNormalization(axis=CHANNEL_AXIS)(input)\n",
    "    return Activation(\"relu\")(norm)\n",
    "\n",
    "def _conv_bn_relu3D(**conv_params):\n",
    "    filters = conv_params[\"filters\"]\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1, 1))\n",
    "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1e-4))\n",
    "\n",
    "    def f(input):\n",
    "        conv = Conv3D(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            strides=strides,\n",
    "            kernel_initializer=kernel_initializer,\n",
    "            padding=padding,\n",
    "            kernel_regularizer=kernel_regularizer,\n",
    "        )(input)\n",
    "        return _bn_relu(conv)\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bn_relu_conv3d(**conv_params):\n",
    "    filters = conv_params[\"filters\"]\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1, 1))\n",
    "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1e-4))\n",
    "\n",
    "    def f(input):\n",
    "        activation = _bn_relu(input)\n",
    "        return Conv3D(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            strides=strides,\n",
    "            kernel_initializer=kernel_initializer,\n",
    "            padding=padding,\n",
    "            kernel_regularizer=kernel_regularizer,\n",
    "        )(activation)\n",
    "\n",
    "    return f\n",
    "\n",
    "def _shortcut3d(input, residual):\n",
    "    stride_dim1 = ceil(input.shape[DIM1_AXIS] / residual.shape[DIM1_AXIS])\n",
    "    stride_dim2 = ceil(input.shape[DIM2_AXIS] / residual.shape[DIM2_AXIS])\n",
    "    stride_dim3 = ceil(input.shape[DIM3_AXIS] / residual.shape[DIM3_AXIS])\n",
    "    equal_channels = residual.shape[CHANNEL_AXIS] == input.shape[CHANNEL_AXIS]\n",
    "\n",
    "    shortcut = input\n",
    "    if stride_dim1 > 1 or stride_dim2 > 1 or stride_dim3 > 1 or not equal_channels:\n",
    "        shortcut = Conv3D(\n",
    "            filters=residual.shape[CHANNEL_AXIS],\n",
    "            kernel_size=(1, 1, 1),\n",
    "            strides=(stride_dim1, stride_dim2, stride_dim3),\n",
    "            kernel_initializer=\"he_normal\",\n",
    "            padding=\"valid\",\n",
    "            kernel_regularizer=l2(1e-4),\n",
    "        )(input)\n",
    "    return add([shortcut, residual])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _conv_bn_relu3D(**conv_params):\n",
    "    filters = conv_params[\"filters\"]\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1, 1))\n",
    "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1e-4))\n",
    "\n",
    "    def f(input):\n",
    "        conv = Conv3D(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            strides=strides,\n",
    "            kernel_initializer=kernel_initializer,\n",
    "            padding=padding,\n",
    "            kernel_regularizer=kernel_regularizer,\n",
    "        )(input)\n",
    "        return _bn_relu(conv)\n",
    "\n",
    "    return f\n",
    "\n",
    "def _bn_relu_conv3d(**conv_params):\n",
    "    filters = conv_params[\"filters\"]\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1, 1))\n",
    "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1e-4))\n",
    "\n",
    "    def f(input):\n",
    "        activation = _bn_relu(input)\n",
    "        return Conv3D(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            strides=strides,\n",
    "            kernel_initializer=kernel_initializer,\n",
    "            padding=padding,\n",
    "            kernel_regularizer=kernel_regularizer,\n",
    "        )(activation)\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _shortcut3d(input, residual):\n",
    "    stride_dim1 = ceil(input.shape[DIM1_AXIS] / residual.shape[DIM1_AXIS])\n",
    "    stride_dim2 = ceil(input.shape[DIM2_AXIS] / residual.shape[DIM2_AXIS])\n",
    "    stride_dim3 = ceil(input.shape[DIM3_AXIS] / residual.shape[DIM3_AXIS])\n",
    "    equal_channels = residual.shape[CHANNEL_AXIS] == input.shape[CHANNEL_AXIS]\n",
    "\n",
    "    shortcut = input\n",
    "    if stride_dim1 > 1 or stride_dim2 > 1 or stride_dim3 > 1 or not equal_channels:\n",
    "        shortcut = Conv3D(\n",
    "            filters=residual.shape[CHANNEL_AXIS],\n",
    "            kernel_size=(1, 1, 1),\n",
    "            strides=(stride_dim1, stride_dim2, stride_dim3),\n",
    "            kernel_initializer=\"he_normal\",\n",
    "            padding=\"valid\",\n",
    "            kernel_regularizer=l2(1e-4),\n",
    "        )(input)\n",
    "    return add([shortcut, residual])\n",
    "\n",
    "def _residual_block_with_cbam(\n",
    "    filters,\n",
    "    kernel_regularizer,\n",
    "    is_first_layer=False,\n",
    "):\n",
    "    def f(input):\n",
    "        strides = (2, 2, 2) if not is_first_layer else (1, 1, 1)\n",
    "        conv1 = _conv_bn_relu3D(\n",
    "            filters=filters,\n",
    "            kernel_size=(5, 5, 5),  # Changed kernel size\n",
    "            strides=strides,\n",
    "            kernel_regularizer=kernel_regularizer,\n",
    "        )(input)\n",
    "        \n",
    "        conv2 = _conv_bn_relu3D(\n",
    "            filters=filters,\n",
    "            kernel_size=(5, 5, 5),  # Changed kernel size\n",
    "            kernel_regularizer=kernel_regularizer,\n",
    "        )(conv1)\n",
    "\n",
    "        # CBAM module\n",
    "        channel_avg_pool = GlobalAveragePooling3D()(conv2)\n",
    "        channel_max_pool = GlobalMaxPooling3D()(conv2)\n",
    "        channel_attention = add([Dense(filters // 2, activation='relu')(channel_avg_pool),\n",
    "                                 Dense(filters // 2, activation='relu')(channel_max_pool)])\n",
    "        channel_attention = Activation('sigmoid')(Dense(filters, activation='relu')(channel_attention))\n",
    "        channel_attention = Reshape((1, 1, 1, filters))(channel_attention)\n",
    "        channel_attention = multiply([conv2, channel_attention])\n",
    "\n",
    "        spatial_attention = Conv3D(1, (1, 1, 1), activation='sigmoid', padding='same', kernel_initializer='he_normal')(conv2)\n",
    "        attention = multiply([conv2, spatial_attention])\n",
    "\n",
    "        conv2 = add([channel_attention, attention])\n",
    "        \n",
    "        return _shortcut3d(input, conv2)\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_block(\n",
    "    filters,\n",
    "    strides=(1, 1, 1),\n",
    "    kernel_regularizer=l2(1e-4),\n",
    "    is_first_block_of_first_layer=False,\n",
    "):\n",
    "    def f(input):\n",
    "        if is_first_block_of_first_layer:\n",
    "            conv1 = Conv3D(\n",
    "                filters=filters,\n",
    "                kernel_size=(5, 5, 5),  # Changed kernel size\n",
    "                strides=strides,\n",
    "                padding=\"same\",\n",
    "                kernel_initializer=\"he_normal\",\n",
    "                kernel_regularizer=kernel_regularizer,\n",
    "            )(input)\n",
    "        else:\n",
    "            conv1 = _bn_relu_conv3d(\n",
    "                filters=filters,\n",
    "                kernel_size=(5, 5, 5),  # Changed kernel size\n",
    "                strides=strides,\n",
    "                kernel_regularizer=kernel_regularizer,\n",
    "            )(input)\n",
    "\n",
    "        residual = _bn_relu_conv3d(\n",
    "            filters=filters,\n",
    "            kernel_size=(5, 5, 5),  # Changed kernel size\n",
    "            kernel_regularizer=kernel_regularizer,\n",
    "        )(conv1)\n",
    "        return _shortcut3d(input, residual)\n",
    "\n",
    "    return f\n",
    "\n",
    "def _handle_data_format():\n",
    "    global DIM1_AXIS\n",
    "    global DIM2_AXIS\n",
    "    global DIM3_AXIS\n",
    "    global CHANNEL_AXIS\n",
    "    if K.image_data_format() == \"channels_last\":\n",
    "        DIM1_AXIS = 1\n",
    "        DIM2_AXIS = 2\n",
    "        DIM3_AXIS = 3\n",
    "        CHANNEL_AXIS = 4\n",
    "    else:\n",
    "        CHANNEL_AXIS = 1\n",
    "        DIM1_AXIS = 2\n",
    "        DIM2_AXIS = 3\n",
    "        DIM3_AXIS = 4\n",
    "\n",
    "def _get_block(identifier):\n",
    "    if isinstance(identifier, six.string_types):\n",
    "        res = globals().get(identifier)\n",
    "        if not res:\n",
    "            raise ValueError(\"Invalid {}\".format(identifier))\n",
    "        return res\n",
    "    return identifier\n",
    "\n",
    "class Resnet3DBuilder(object):\n",
    "    \"\"\"ResNet3D.\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def build(input_shape, num_outputs, block_fn, repetitions, reg_factor):\n",
    "        \"\"\"Instantiate a vanilla ResNet3D keras model.\n",
    "\n",
    "        # Arguments\n",
    "            input_shape: Tuple of input shape in the format\n",
    "            (conv_dim1, conv_dim2, conv_dim3, channels) if dim_ordering='tf'\n",
    "            (filter, conv_dim1, conv_dim2, conv_dim3) if dim_ordering='th'\n",
    "            num_outputs: The number of outputs at the final softmax layer\n",
    "            block_fn: Unit block to use {'basic_block', 'bottlenack_block'}\n",
    "            repetitions: Repetitions of unit blocks\n",
    "        # Returns\n",
    "            model: a 3D ResNet model that takes a 5D tensor (volumetric images\n",
    "            in batch) as input and returns a 1D vector (prediction) as output.\n",
    "        \"\"\"\n",
    "        _handle_data_format()\n",
    "        if len(input_shape) != 4:\n",
    "            raise ValueError(\n",
    "                \"Input shape should be a tuple \"\n",
    "                \"(conv_dim1, conv_dim2, conv_dim3, channels) \"\n",
    "                \"for tensorflow as backend or \"\n",
    "                \"(channels, conv_dim1, conv_dim2, conv_dim3) \"\n",
    "                \"for theano as backend\"\n",
    "            )\n",
    "\n",
    "        block_fn = _get_block(block_fn)\n",
    "        input = Input(shape=input_shape)\n",
    "        # first conv\n",
    "        conv1 = _conv_bn_relu3D(\n",
    "            filters=128,  # Changed filter size\n",
    "            kernel_size=(5, 5, 5),  # Changed kernel size\n",
    "            strides=(2, 2, 2),\n",
    "            kernel_regularizer=l2(reg_factor),\n",
    "        )(input)\n",
    "        pool1 = MaxPooling3D(pool_size=(3, 3, 3), strides=(2, 2, 2), padding=\"same\")(\n",
    "            conv1\n",
    "        )\n",
    "\n",
    "        # repeat blocks\n",
    "        block = pool1\n",
    "        filters = 128  # Changed filter size\n",
    "        for i, r in enumerate(repetitions):\n",
    "            block = _residual_block_with_cbam(\n",
    "                filters=filters,\n",
    "                kernel_regularizer=l2(reg_factor),\n",
    "                is_first_layer=(i == 0),\n",
    "            )(block)\n",
    "            filters *= 2\n",
    "\n",
    "        # last activation\n",
    "        block_output = _bn_relu(block)\n",
    "\n",
    "        # average pool and classification\n",
    "        pool2 = AveragePooling3D(\n",
    "            pool_size=(\n",
    "                block.shape[DIM1_AXIS],\n",
    "                block.shape[DIM2_AXIS],\n",
    "                block.shape[DIM3_AXIS],\n",
    "            ),\n",
    "            strides=(1, 1, 1),\n",
    "        )(block_output)\n",
    "        flatten1 = Flatten()(pool2)\n",
    "        if num_outputs > 1:\n",
    "            dense = Dense(\n",
    "                units=num_outputs,\n",
    "                kernel_initializer=\"he_normal\",\n",
    "                activation=\"softmax\",\n",
    "                kernel_regularizer=l2(reg_factor),\n",
    "            )(flatten1)\n",
    "        else:\n",
    "            dense = Dense(\n",
    "                units=num_outputs,\n",
    "                kernel_initializer=\"he_normal\",\n",
    "                activation=\"sigmoid\",\n",
    "                kernel_regularizer=l2(reg_factor),\n",
    "            )(flatten1)\n",
    "\n",
    "        model = Model(inputs=input, outputs=dense)\n",
    "        return model\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_18(input_shape, num_outputs, reg_factor=1e-4):\n",
    "        \"\"\"Build resnet 18.\"\"\"\n",
    "        return Resnet3DBuilder.build(\n",
    "            input_shape, num_outputs, basic_block, [2, 2, 2, 2], reg_factor=reg_factor\n",
    "        )\n",
    "    @staticmethod\n",
    "    def build_resnet_34(input_shape, num_outputs, reg_factor=1e-4):\n",
    "        \"\"\"Build resnet 34.\"\"\"\n",
    "        return Resnet3DBuilder.build(\n",
    "            input_shape, num_outputs, basic_block, [3, 4, 6, 3], reg_factor=reg_factor\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_50(input_shape, num_outputs, reg_factor=1e-4):\n",
    "        \"\"\"Build resnet 50.\"\"\"\n",
    "        return Resnet3DBuilder.build(\n",
    "            input_shape, num_outputs, basic_block, [3, 4, 6, 3], reg_factor=reg_factor\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_101(input_shape, num_outputs, reg_factor=1e-4):\n",
    "        \"\"\"Build resnet 101.\"\"\"\n",
    "        return Resnet3DBuilder.build(\n",
    "            input_shape, num_outputs, basic_block, [3, 4, 23, 3], reg_factor=reg_factor\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_152(input_shape, num_outputs, reg_factor=1e-4):\n",
    "        \"\"\"Build resnet 152.\"\"\"\n",
    "        return Resnet3DBuilder.build(\n",
    "            input_shape, num_outputs, basic_block, [3, 16, 36, 6], reg_factor=reg_factor\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the model\n",
    "def apply_mask(aseg_image, brain_image, labels = [17, 53, 2, 7, 41, 46]):\n",
    "    brain_data = aseg_image.get_fdata()\n",
    "    aseg_data = aseg_image.get_fdata()\n",
    "    origin_data = brain_image.get_fdata()\n",
    "    \n",
    "    brain_mask = np.zeros_like(aseg_data)\n",
    "    for label in labels:\n",
    "        brain_mask += np.where((aseg_data == label), 1, 0)\n",
    "\n",
    "    new_image = origin_data * brain_mask\n",
    "    \n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_slice(slice_data):\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    enhanced_slice = clahe.apply(slice_data.astype(np.uint8))\n",
    "\n",
    "    return enhanced_slice\n",
    "\n",
    "def enhance_image(img_data):\n",
    "    enhanced_image = np.zeros_like(img_data)\n",
    "    for i in range(img_data.shape[2]):\n",
    "        enhanced_image[:, :, i] = enhance_slice(img_data[:, :, i])\n",
    "    return enhanced_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpen_image(image, strength=1.0):\n",
    "    sharpened_image = unsharp_mask(image, radius=1, amount=strength)\n",
    "    return sharpened_image\n",
    "\n",
    "def apply_nonlinear_registration(moving_image, fixed_image):\n",
    "    metric = CCMetric(3)\n",
    "\n",
    "    sdr = SymmetricDiffeomorphicRegistration(metric, [10, 10, 10], step_length=0.25, ss_sigma_factor=1.5)\n",
    "\n",
    "    mapping = sdr.optimize(fixed_image, moving_image)\n",
    "\n",
    "    warped_moving_image = mapping.transform(moving_image)\n",
    "\n",
    "    return warped_moving_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_fixed(image_type, target_shape):\n",
    "    aseg_image = nibabel.load('/home/uiu/Project/adni-1-5t-filtered-preprocessed-quickseg-dataset/AD/I65597.nii')\n",
    "    base_path = \"/home/uiu/Project/adni-1-5t-filtered-preprocessed-quickseg-dataset/AD/I65597.nii/mri/orig.mgz\"\n",
    "    origin_image =  nibabel.load(base_path)\n",
    "    \n",
    "    if (image_type == 'roi') :\n",
    "        image = apply_mask(aseg_image, origin_image)\n",
    "        image = resize(image, target_shape, anti_aliasing=True)\n",
    "        image = sharpen_image(image)\n",
    "        return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import rotate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(image, rotation_range):\n",
    "    rotation_angle = np.random.uniform(-rotation_range, rotation_range)\n",
    "    rotated_image = rotate(image, rotation_angle, reshape=False)\n",
    "    \n",
    "    return rotated_image\n",
    "\n",
    "\n",
    "\n",
    "def image_loader_roi(image_path, target_shape, type_dt=''):\n",
    "    aseg_image = nibabel.load(image_path)\n",
    "    base_path = \"/\".join(image_path.split('/')[:-1]) + \"/orig.mgz\"\n",
    "    base_image =  nibabel.load(base_path)\n",
    "    \n",
    "    image = apply_mask(aseg_image, base_image)\n",
    "    image = resize(image, target_shape, anti_aliasing=True)\n",
    "    image = enhance_image(image)\n",
    "    image = sharpen_image(image)\n",
    "    \n",
    "    if type_dt=='train':\n",
    "        image = augment(image, 50)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127, 505, array([1.03909465, 0.96374046]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def data_generator(paths, labels, batch_size, target_shape, image_type, type_dt=''):\n",
    "    while True:\n",
    "        for i in range(0, len(paths), batch_size):\n",
    "            batch_paths = paths[i:i+batch_size]\n",
    "            batch_labels = labels[i:i+batch_size]\n",
    "            batch_images = []\n",
    "            \n",
    "    \n",
    "            if image_type == 'roi':\n",
    "                batch_images = [image_loader_roi(image, target_shape, type_dt) for image in batch_paths]\n",
    "\n",
    "\n",
    "            batch_images = np.stack([batch_images] * 1, axis=-1)\n",
    "\n",
    "            batch_labels = to_categorical(batch_labels, num_classes=2)\n",
    "            yield np.array(batch_images), batch_labels\n",
    "base_dir = '/home/uiu/Project/adni-1-5t-filtered-preprocessed-quickseg-dataset'\n",
    "ad = os.path.join(base_dir, 'AD')\n",
    "mci = os.path.join(base_dir, 'MCI')\n",
    "cn = os.path.join(base_dir, 'CN')\n",
    "# original shape (257, 257, 257)\n",
    "\n",
    "ad_images= []\n",
    "mci_images = []\n",
    "cn_images = []\n",
    "\n",
    "for subject_dir in os.listdir(ad):\n",
    "    mri_path = os.path.join(ad, subject_dir, 'mri', 'aparc.DKTatlas+aseg.deep.mgz')\n",
    "    if not (len(os.listdir(os.path.join(ad, subject_dir, 'mri'))) < 6):\n",
    "        ad_images.append(mri_path)\n",
    "        \n",
    "for subject_dir in os.listdir(mci):\n",
    "    mri_path = os.path.join(mci, subject_dir, 'mri', 'aparc.DKTatlas+aseg.deep.mgz')\n",
    "    \n",
    "    if not (len(os.listdir(os.path.join(mci, subject_dir, 'mri'))) < 6):\n",
    "        mci_images.append(mri_path)\n",
    "        \n",
    "for subject_dir in os.listdir(cn):\n",
    "    mri_path = os.path.join(cn, subject_dir, 'mri', 'aparc.DKTatlas+aseg.deep.mgz')\n",
    "    if not (len(os.listdir(os.path.join(cn, subject_dir, 'mri'))) < 6):\n",
    "        cn_images.append(mri_path)\n",
    "\n",
    "\n",
    "image_path = mci_images + cn_images + cn_images[:len(mci_images)-len(cn_images)]\n",
    "labels = [0] * len(mci_images) + [1] * len(cn_images) + [1] * len(cn_images[:len(mci_images)-len(cn_images)])\n",
    "train_paths, test_paths, train_labels, test_labels = train_test_split(image_path, labels, test_size = 0.2, random_state=42)\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)\n",
    "train_paths = np.array(train_paths)\n",
    "train_labels = np.array(train_labels)\n",
    "test_paths = np.array(test_paths)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "train_paths, train_labels = shuffle(train_paths, train_labels, random_state=42)\n",
    "test_paths, test_labels = shuffle(test_paths, test_labels, random_state=42)\n",
    "\n",
    "target_shape = (100, 100, 100)\n",
    "batch_size = 10\n",
    "selection_type = 'roi'\n",
    "train_dataset = data_generator(train_paths, train_labels, batch_size, target_shape, \n",
    "                               image_type=selection_type, \n",
    "                               type_dt='train'\n",
    "                              )\n",
    "\n",
    "test_dataset = data_generator(test_paths, test_labels, batch_size, target_shape, \n",
    "                              image_type=selection_type\n",
    "                             )\n",
    "len(test_paths), len(train_labels), class_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 100, 100, 10 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d (Conv3D)                 (None, 50, 50, 50, 1 16128       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 50, 50, 50, 1 512         conv3d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 50, 50, 50, 1 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D)    (None, 25, 25, 25, 1 0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_1 (Conv3D)               (None, 25, 25, 25, 1 2048128     max_pooling3d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 25, 25, 25, 1 512         conv3d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 25, 25, 25, 1 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_2 (Conv3D)               (None, 25, 25, 25, 1 2048128     activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 25, 25, 25, 1 512         conv3d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 25, 25, 25, 1 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling3d (Globa (None, 128)          0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling3d (GlobalMax (None, 128)          0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 64)           8256        global_average_pooling3d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           8256        global_max_pooling3d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 64)           0           dense[0][0]                      \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          8320        add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 128)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 1, 1, 1, 128) 0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_3 (Conv3D)               (None, 25, 25, 25, 1 129         activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 25, 25, 25, 1 0           activation_2[0][0]               \n",
      "                                                                 reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 25, 25, 25, 1 0           activation_2[0][0]               \n",
      "                                                                 conv3d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 25, 25, 25, 1 0           multiply[0][0]                   \n",
      "                                                                 multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 25, 25, 25, 1 0           max_pooling3d[0][0]              \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_4 (Conv3D)               (None, 13, 13, 13, 2 4096256     add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 13, 13, 13, 2 1024        conv3d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 13, 13, 13, 2 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_5 (Conv3D)               (None, 13, 13, 13, 2 8192256     activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 13, 13, 13, 2 1024        conv3d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 13, 13, 13, 2 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling3d_1 (Glo (None, 256)          0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling3d_1 (GlobalM (None, 256)          0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128)          32896       global_average_pooling3d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128)          32896       global_max_pooling3d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 128)          0           dense_3[0][0]                    \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 256)          33024       add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 256)          0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 1, 1, 256) 0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_6 (Conv3D)               (None, 13, 13, 13, 1 257         activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 13, 13, 13, 2 0           activation_5[0][0]               \n",
      "                                                                 reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 13, 13, 13, 2 0           activation_5[0][0]               \n",
      "                                                                 conv3d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_7 (Conv3D)               (None, 13, 13, 13, 2 33024       add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 13, 13, 13, 2 0           multiply_2[0][0]                 \n",
      "                                                                 multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 13, 13, 13, 2 0           conv3d_7[0][0]                   \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_8 (Conv3D)               (None, 7, 7, 7, 512) 16384512    add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 7, 7, 7, 512) 2048        conv3d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 7, 7, 7, 512) 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_9 (Conv3D)               (None, 7, 7, 7, 512) 32768512    activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 7, 7, 7, 512) 2048        conv3d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 7, 7, 7, 512) 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling3d_2 (Glo (None, 512)          0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling3d_2 (GlobalM (None, 512)          0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 256)          131328      global_average_pooling3d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 256)          131328      global_max_pooling3d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 256)          0           dense_6[0][0]                    \n",
      "                                                                 dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 512)          131584      add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 512)          0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 1, 1, 1, 512) 0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_10 (Conv3D)              (None, 7, 7, 7, 1)   513         activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 7, 7, 7, 512) 0           activation_8[0][0]               \n",
      "                                                                 reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_5 (Multiply)           (None, 7, 7, 7, 512) 0           activation_8[0][0]               \n",
      "                                                                 conv3d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_11 (Conv3D)              (None, 7, 7, 7, 512) 131584      add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 7, 7, 7, 512) 0           multiply_4[0][0]                 \n",
      "                                                                 multiply_5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 7, 7, 7, 512) 0           conv3d_11[0][0]                  \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_12 (Conv3D)              (None, 4, 4, 4, 1024 65537024    add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 4, 4, 4, 1024 4096        conv3d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 4, 4, 4, 1024 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_13 (Conv3D)              (None, 4, 4, 4, 1024 131073024   activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 4, 4, 4, 1024 4096        conv3d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 4, 4, 4, 1024 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling3d_3 (Glo (None, 1024)         0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling3d_3 (GlobalM (None, 1024)         0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 512)          524800      global_average_pooling3d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 512)          524800      global_max_pooling3d_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 512)          0           dense_9[0][0]                    \n",
      "                                                                 dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 1024)         525312      add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 1024)         0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 1, 1, 1, 1024 0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_14 (Conv3D)              (None, 4, 4, 4, 1)   1025        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_6 (Multiply)           (None, 4, 4, 4, 1024 0           activation_11[0][0]              \n",
      "                                                                 reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_7 (Multiply)           (None, 4, 4, 4, 1024 0           activation_11[0][0]              \n",
      "                                                                 conv3d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_15 (Conv3D)              (None, 4, 4, 4, 1024 525312      add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 4, 4, 4, 1024 0           multiply_6[0][0]                 \n",
      "                                                                 multiply_7[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 4, 4, 4, 1024 0           conv3d_15[0][0]                  \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 4, 4, 4, 1024 4096        add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 4, 4, 4, 1024 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling3d (AveragePooli (None, 1, 1, 1, 1024 0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1024)         0           average_pooling3d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 2)            2050        flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 264,970,630\n",
      "Trainable params: 264,960,646\n",
      "Non-trainable params: 9,984\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classes = 2\n",
    "image_shape = (*target_shape, 1)\n",
    "model = Resnet3DBuilder.build_resnet_152(input_shape = image_shape, num_outputs=classes)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(0.00001), \n",
    "    loss='binary_crossentropy', \n",
    "    metrics=['accuracy', 'Recall', 'AUC', 'Precision'] \n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28264/3886288769.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_paths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_paths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m )\n",
      "\u001b[0;32m~/miniconda3/envs/tf_conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1062\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1064\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf_conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf_conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[1;32m    777\u001b[0m     \u001b[0;31m# Since we have to know the dtype of the python generator when we build the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m     \u001b[0;31m# dataset, we have to look at a batch to infer the structure.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m     \u001b[0mpeek\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_peek_and_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m     \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m     \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf_conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_peek_and_restore\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    834\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_peek_and_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 836\u001b[0;31m     \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    837\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpeek\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_28264/3875607755.py\u001b[0m in \u001b[0;36mdata_generator\u001b[0;34m(paths, labels, batch_size, target_shape, image_type, type_dt)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mimage_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'roi'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                 \u001b[0mbatch_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mimage_loader_roi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_dt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_paths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_28264/3875607755.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mimage_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'roi'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                 \u001b[0mbatch_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mimage_loader_roi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_dt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_paths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_28264/2532917095.py\u001b[0m in \u001b[0;36mimage_loader_roi\u001b[0;34m(image_path, target_shape, type_dt)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mbase_image\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mnibabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maseg_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manti_aliasing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menhance_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_28264/2815341450.py\u001b[0m in \u001b[0;36mapply_mask\u001b[0;34m(aseg_image, brain_image, labels)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mbrain_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maseg_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mbrain_mask\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maseg_data\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mnew_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morigin_data\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbrain_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mwhere\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epoch = 100\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs = num_epoch,\n",
    "    steps_per_epoch = len(train_paths) // batch_size,\n",
    "    validation_data = test_dataset,\n",
    "    validation_steps= len(test_paths) // batch_size,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"UpgradedFilter_ROI_IJK_100_Epoch_v2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('UpgradedFilter_ROI_IJK_100_Epoch_v2')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.savefig(\"UpgradedFilter_ROI_IJK_100_Epoch_v2.png\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('UpgradedFilter_ROI_IJK_100_Epoch_v3.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=Adam(0.00001), \n",
    "    loss='binary_crossentropy', \n",
    "    metrics=['accuracy', 'Recall', 'AUC', 'Precision'] \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No\n",
    "model_checkpoint = ModelCheckpoint('UpgradedFilter_ROI_IJK_100_Epoch_v2.h5', monitor='val_accuracy', mode='max', save_best_only=True)\n",
    "\n",
    "num_epoch = 20\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=num_epoch,\n",
    "    steps_per_epoch=len(train_paths) // batch_size,\n",
    "    validation_data=test_dataset,\n",
    "    validation_steps=len(test_paths) // batch_size,\n",
    "    callbacks=[model_checkpoint]  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO\n",
    "\n",
    "saved_model = tf.keras.models.load_model('UpgradedFilter_ROI_IJK_100_Epoch_v2.h5')\n",
    "test_accuracy = saved_model.evaluate(\n",
    "    test_dataset,\n",
    "    steps=len(test_paths) // batch_size,\n",
    "    verbose=1\n",
    ")\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "\n",
    "num_epoch = 4\n",
    "best_val_accuracy = 0.0\n",
    "model_checkpoint_path = 'UpgradedFilter_ROI_IJK_100_Epoch_v3.h5'\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    print(\"Epoch {}/{}\".format(epoch + 1, num_epoch))\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        epochs=1,  \n",
    "        steps_per_epoch=len(train_paths) // batch_size,\n",
    "        validation_data=test_dataset,\n",
    "        validation_steps=len(test_paths) // batch_size,\n",
    "        verbose=1 \n",
    "    )\n",
    "\n",
    "    # Evaluate the model on validation data\n",
    "    val_accuracy = history.history['val_accuracy'][0]\n",
    "\n",
    "    # Save the model if validation accuracy improved\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        print(\"Validation accuracy improved from {} to {}. Saving model...\".format(best_val_accuracy, val_accuracy))\n",
    "        best_val_accuracy = val_accuracy\n",
    "        model.save(model_checkpoint_path)\n",
    "    else:\n",
    "        print(\"Validation accuracy did not improve. Model not saved.\")\n",
    "\n",
    "    print(\"\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 105s 9s/step - loss: 1.1408 - accuracy: 0.9167 - recall: 0.9167 - auc: 0.9397 - precision: 0.9167\n",
      "Test Accuracy: [1.14083731174469, 0.9166666865348816, 0.9166666865348816, 0.9396527409553528, 0.9166666865348816]\n"
     ]
    }
   ],
   "source": [
    "# Load the best model and evaluate on test data\n",
    "saved_model = tf.keras.models.load_model('Best_Test_Accuracy_Model.h5')\n",
    "test_accuracy = saved_model.evaluate(\n",
    "    test_dataset,\n",
    "    steps=len(test_paths) // batch_size,\n",
    "    verbose=1\n",
    ")\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(441, 64, 127, 441, array([1.02083333, 0.98      ]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def data_generator(paths, labels, batch_size, target_shape, image_type, type_dt=''):\n",
    "    while True:\n",
    "        for i in range(0, len(paths), batch_size):\n",
    "            batch_paths = paths[i:i+batch_size]\n",
    "            batch_labels = labels[i:i+batch_size]\n",
    "            batch_images = []\n",
    "            \n",
    "    \n",
    "            if image_type == 'roi':\n",
    "                batch_images = [image_loader_roi(image, target_shape, type_dt) for image in batch_paths]\n",
    "\n",
    "\n",
    "            batch_images = np.stack([batch_images] * 1, axis=-1)\n",
    "\n",
    "            batch_labels = to_categorical(batch_labels, num_classes=2)\n",
    "            yield np.array(batch_images), batch_labels\n",
    "base_dir = '/home/uiu/Project/adni-1-5t-filtered-preprocessed-quickseg-dataset'\n",
    "ad = os.path.join(base_dir, 'AD')\n",
    "mci = os.path.join(base_dir, 'MCI')\n",
    "cn = os.path.join(base_dir, 'CN')\n",
    "# original shape (257, 257, 257)\n",
    "\n",
    "ad_images= []\n",
    "mci_images = []\n",
    "cn_images = []\n",
    "\n",
    "for subject_dir in os.listdir(ad):\n",
    "    mri_path = os.path.join(ad, subject_dir, 'mri', 'aparc.DKTatlas+aseg.deep.mgz')\n",
    "    if not (len(os.listdir(os.path.join(ad, subject_dir, 'mri'))) < 6):\n",
    "        ad_images.append(mri_path)\n",
    "        \n",
    "for subject_dir in os.listdir(mci):\n",
    "    mri_path = os.path.join(mci, subject_dir, 'mri', 'aparc.DKTatlas+aseg.deep.mgz')\n",
    "    \n",
    "    if not (len(os.listdir(os.path.join(mci, subject_dir, 'mri'))) < 6):\n",
    "        mci_images.append(mri_path)\n",
    "        \n",
    "for subject_dir in os.listdir(cn):\n",
    "    mri_path = os.path.join(cn, subject_dir, 'mri', 'aparc.DKTatlas+aseg.deep.mgz')\n",
    "    if not (len(os.listdir(os.path.join(cn, subject_dir, 'mri'))) < 6):\n",
    "        cn_images.append(mri_path)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "image_path = mci_images + cn_images + cn_images[:len(mci_images)-len(cn_images)]\n",
    "labels = [0] * len(mci_images) + [1] * len(cn_images) + [1] * len(cn_images[:len(mci_images)-len(cn_images)])\n",
    "len(image_path), len(labels), len(mci_images), len(cn_images + cn_images[:len(mci_images)-len(cn_images)])\n",
    "train_paths, test_paths, train_labels, test_labels = train_test_split(image_path, labels, test_size=0.2, random_state=42)\n",
    "train_paths, val_paths, train_labels, val_labels = train_test_split(train_paths, train_labels, test_size=0.125, random_state=42)\n",
    "\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)\n",
    "len(train_paths), len(val_paths), len(test_paths), np.unique(train_labels)\n",
    "\n",
    "train_paths = np.array(train_paths)\n",
    "train_labels = np.array(train_labels)\n",
    "val_paths = np.array(val_paths)\n",
    "val_labels = np.array(val_labels)\n",
    "test_paths = np.array(test_paths)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "train_paths, train_labels = shuffle(train_paths, train_labels, random_state=42)\n",
    "val_paths, val_labels = shuffle(val_paths, val_labels, random_state=42)\n",
    "test_paths, test_labels = shuffle(test_paths, test_labels, random_state=42)\n",
    "target_shape = (100, 100, 100)\n",
    "batch_size = 10\n",
    "selection_type = 'roi'\n",
    "train_dataset = data_generator(train_paths, train_labels, batch_size, target_shape, \n",
    "                               image_type=selection_type, \n",
    "                               type_dt='train'\n",
    "                              )\n",
    "val_dataset = data_generator(val_paths, val_labels, batch_size, target_shape, \n",
    "                             image_type=selection_type)\n",
    "test_dataset = data_generator(test_paths, test_labels, batch_size, target_shape, \n",
    "                              image_type=selection_type\n",
    "                             )\n",
    "len(train_paths), len(val_paths), len(test_paths), len(train_labels), class_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('UpgradedFilter_ROI_IJK_100_Epoch_v4.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "44/44 [==============================] - 501s 12s/step - loss: 0.9235 - accuracy: 0.9652 - recall: 0.9652 - auc: 0.9920 - precision: 0.9652 - val_loss: 0.9601 - val_accuracy: 0.9167 - val_recall: 0.9167 - val_auc: 0.9881 - val_precision: 0.9167\n",
      "Test accuracy improved from 0.0000 to 0.8417. Saving model.\n",
      "Test Accuracy: 0.8417\n",
      "\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 502s 12s/step - loss: 0.8914 - accuracy: 0.9907 - recall: 0.9907 - auc: 0.9943 - precision: 0.9907 - val_loss: 1.0990 - val_accuracy: 0.9000 - val_recall: 0.9000 - val_auc: 0.9369 - val_precision: 0.9000\n",
      "Test Accuracy: 0.7917\n",
      "\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 502s 12s/step - loss: 0.8847 - accuracy: 0.9838 - recall: 0.9838 - auc: 0.9965 - precision: 0.9838 - val_loss: 1.7554 - val_accuracy: 0.7167 - val_recall: 0.7167 - val_auc: 0.7811 - val_precision: 0.7167\n",
      "Test Accuracy: 0.4917\n",
      "\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 502s 12s/step - loss: 0.9693 - accuracy: 0.9490 - recall: 0.9490 - auc: 0.9792 - precision: 0.9490 - val_loss: 1.0239 - val_accuracy: 0.9167 - val_recall: 0.9167 - val_auc: 0.9669 - val_precision: 0.9167\n",
      "Test Accuracy: 0.8167\n",
      "\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 501s 12s/step - loss: 0.9298 - accuracy: 0.9629 - recall: 0.9629 - auc: 0.9906 - precision: 0.9629 - val_loss: 0.9580 - val_accuracy: 0.9333 - val_recall: 0.9333 - val_auc: 0.9906 - val_precision: 0.9333\n",
      "Test Accuracy: 0.8250\n",
      "\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 498s 12s/step - loss: 0.9264 - accuracy: 0.9629 - recall: 0.9629 - auc: 0.9945 - precision: 0.9629 - val_loss: 1.0428 - val_accuracy: 0.9000 - val_recall: 0.9000 - val_auc: 0.9628 - val_precision: 0.9000\n",
      "Test Accuracy: 0.8250\n",
      "\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 495s 11s/step - loss: 0.8750 - accuracy: 0.9861 - recall: 0.9861 - auc: 0.9988 - precision: 0.9861 - val_loss: 0.9302 - val_accuracy: 0.9500 - val_recall: 0.9500 - val_auc: 0.9933 - val_precision: 0.9500\n",
      "Test Accuracy: 0.8417\n",
      "\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 496s 12s/step - loss: 0.8797 - accuracy: 0.9884 - recall: 0.9884 - auc: 0.9962 - precision: 0.9884 - val_loss: 0.9863 - val_accuracy: 0.9167 - val_recall: 0.9167 - val_auc: 0.9708 - val_precision: 0.9167\n",
      "Test Accuracy: 0.8000\n",
      "\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 495s 11s/step - loss: 0.8751 - accuracy: 0.9791 - recall: 0.9791 - auc: 0.9990 - precision: 0.9791 - val_loss: 0.9853 - val_accuracy: 0.8833 - val_recall: 0.8833 - val_auc: 0.9836 - val_precision: 0.8833\n",
      "Test accuracy improved from 0.8417 to 0.8917. Saving model.\n",
      "Test Accuracy: 0.8917\n",
      "\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 502s 12s/step - loss: 0.8842 - accuracy: 0.9768 - recall: 0.9768 - auc: 0.9961 - precision: 0.9768 - val_loss: 1.0336 - val_accuracy: 0.9000 - val_recall: 0.9000 - val_auc: 0.9556 - val_precision: 0.9000\n",
      "Test Accuracy: 0.7667\n",
      "\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 502s 12s/step - loss: 0.8616 - accuracy: 0.9907 - recall: 0.9907 - auc: 0.9971 - precision: 0.9907 - val_loss: 0.9598 - val_accuracy: 0.9333 - val_recall: 0.9333 - val_auc: 0.9883 - val_precision: 0.9333\n",
      "Test Accuracy: 0.8167\n",
      "\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 498s 12s/step - loss: 0.8762 - accuracy: 0.9838 - recall: 0.9838 - auc: 0.9941 - precision: 0.9838 - val_loss: 1.0323 - val_accuracy: 0.8667 - val_recall: 0.8667 - val_auc: 0.9589 - val_precision: 0.8667\n",
      "Test Accuracy: 0.6833\n",
      "\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 494s 11s/step - loss: 0.9453 - accuracy: 0.9513 - recall: 0.9513 - auc: 0.9839 - precision: 0.9513 - val_loss: 1.0367 - val_accuracy: 0.8833 - val_recall: 0.8833 - val_auc: 0.9683 - val_precision: 0.8833\n",
      "Test accuracy improved from 0.8917 to 0.9167. Saving model.\n",
      "Test Accuracy: 0.9167\n",
      "\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 501s 12s/step - loss: 0.8974 - accuracy: 0.9768 - recall: 0.9768 - auc: 0.9954 - precision: 0.9768 - val_loss: 0.9340 - val_accuracy: 0.9500 - val_recall: 0.9500 - val_auc: 0.9908 - val_precision: 0.9500\n",
      "Test Accuracy: 0.8500\n",
      "\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 499s 12s/step - loss: 0.8751 - accuracy: 0.9838 - recall: 0.9838 - auc: 0.9957 - precision: 0.9838 - val_loss: 0.9519 - val_accuracy: 0.9667 - val_recall: 0.9667 - val_auc: 0.9794 - val_precision: 0.9667\n",
      "Test Accuracy: 0.8000\n",
      "\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 498s 12s/step - loss: 0.8456 - accuracy: 0.9930 - recall: 0.9930 - auc: 0.9997 - precision: 0.9930 - val_loss: 1.0973 - val_accuracy: 0.9167 - val_recall: 0.9167 - val_auc: 0.9547 - val_precision: 0.9167\n",
      "Test Accuracy: 0.7000\n",
      "\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 493s 11s/step - loss: 0.8324 - accuracy: 0.9977 - recall: 0.9977 - auc: 1.0000 - precision: 0.9977 - val_loss: 0.9580 - val_accuracy: 0.9500 - val_recall: 0.9500 - val_auc: 0.9758 - val_precision: 0.9500\n",
      "Test Accuracy: 0.9083\n",
      "\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 497s 12s/step - loss: 0.8417 - accuracy: 0.9884 - recall: 0.9884 - auc: 0.9995 - precision: 0.9884 - val_loss: 0.9411 - val_accuracy: 0.9167 - val_recall: 0.9167 - val_auc: 0.9886 - val_precision: 0.9167\n",
      "Test Accuracy: 0.8250\n",
      "\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 495s 11s/step - loss: 0.8558 - accuracy: 0.9791 - recall: 0.9791 - auc: 0.9967 - precision: 0.9791 - val_loss: 0.9679 - val_accuracy: 0.9667 - val_recall: 0.9667 - val_auc: 0.9764 - val_precision: 0.9667\n",
      "Test Accuracy: 0.8750\n",
      "\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 492s 11s/step - loss: 0.8871 - accuracy: 0.9675 - recall: 0.9675 - auc: 0.9885 - precision: 0.9675 - val_loss: 1.0089 - val_accuracy: 0.9000 - val_recall: 0.9000 - val_auc: 0.9633 - val_precision: 0.9000\n",
      "Test Accuracy: 0.9167\n",
      "\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 490s 11s/step - loss: 0.8684 - accuracy: 0.9745 - recall: 0.9745 - auc: 0.9978 - precision: 0.9745 - val_loss: 0.9153 - val_accuracy: 0.9500 - val_recall: 0.9500 - val_auc: 0.9919 - val_precision: 0.9500\n",
      "Test Accuracy: 0.8833\n",
      "\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 490s 11s/step - loss: 0.8243 - accuracy: 1.0000 - recall: 1.0000 - auc: 1.0000 - precision: 1.0000 - val_loss: 0.8558 - val_accuracy: 0.9833 - val_recall: 0.9833 - val_auc: 0.9997 - val_precision: 0.9833\n",
      "Test Accuracy: 0.8583\n",
      "\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 489s 11s/step - loss: 0.8336 - accuracy: 0.9884 - recall: 0.9884 - auc: 0.9995 - precision: 0.9884 - val_loss: 0.9058 - val_accuracy: 0.9667 - val_recall: 0.9667 - val_auc: 0.9944 - val_precision: 0.9667\n",
      "Test Accuracy: 0.7917\n",
      "\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 489s 11s/step - loss: 0.8441 - accuracy: 0.9814 - recall: 0.9814 - auc: 0.9990 - precision: 0.9814 - val_loss: 0.9423 - val_accuracy: 0.9333 - val_recall: 0.9333 - val_auc: 0.9889 - val_precision: 0.9333\n",
      "Test Accuracy: 0.8917\n",
      "\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 488s 11s/step - loss: 0.8507 - accuracy: 0.9791 - recall: 0.9791 - auc: 0.9965 - precision: 0.9791 - val_loss: 1.1103 - val_accuracy: 0.8833 - val_recall: 0.8833 - val_auc: 0.9350 - val_precision: 0.8833\n",
      "Test Accuracy: 0.6500\n",
      "\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 488s 11s/step - loss: 0.8588 - accuracy: 0.9722 - recall: 0.9722 - auc: 0.9980 - precision: 0.9722 - val_loss: 0.9510 - val_accuracy: 0.9500 - val_recall: 0.9500 - val_auc: 0.9725 - val_precision: 0.9500\n",
      "Test Accuracy: 0.7833\n",
      "\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 490s 11s/step - loss: 0.8501 - accuracy: 0.9838 - recall: 0.9838 - auc: 0.9963 - precision: 0.9838 - val_loss: 1.1164 - val_accuracy: 0.8667 - val_recall: 0.8667 - val_auc: 0.9289 - val_precision: 0.8667\n",
      "Test Accuracy: 0.6250\n",
      "\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 500s 12s/step - loss: 0.8351 - accuracy: 0.9861 - recall: 0.9861 - auc: 0.9970 - precision: 0.9861 - val_loss: 1.2873 - val_accuracy: 0.8333 - val_recall: 0.8333 - val_auc: 0.9068 - val_precision: 0.8333\n",
      "Test Accuracy: 0.5583\n",
      "\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 498s 12s/step - loss: 0.8148 - accuracy: 0.9954 - recall: 0.9954 - auc: 1.0000 - precision: 0.9954 - val_loss: 0.9792 - val_accuracy: 0.9500 - val_recall: 0.9500 - val_auc: 0.9769 - val_precision: 0.9500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7667\n",
      "\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 495s 11s/step - loss: 0.8280 - accuracy: 0.9884 - recall: 0.9884 - auc: 0.9972 - precision: 0.9884 - val_loss: 1.0058 - val_accuracy: 0.9500 - val_recall: 0.9500 - val_auc: 0.9728 - val_precision: 0.9500\n",
      "Test Accuracy: 0.8417\n",
      "\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 493s 11s/step - loss: 0.8389 - accuracy: 0.9884 - recall: 0.9884 - auc: 0.9946 - precision: 0.9884 - val_loss: 0.9350 - val_accuracy: 0.9333 - val_recall: 0.9333 - val_auc: 0.9769 - val_precision: 0.9333\n",
      "Test Accuracy: 0.8083\n",
      "\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 488s 11s/step - loss: 0.8228 - accuracy: 0.9884 - recall: 0.9884 - auc: 0.9972 - precision: 0.9884 - val_loss: 0.9262 - val_accuracy: 0.9167 - val_recall: 0.9167 - val_auc: 0.9892 - val_precision: 0.9167\n",
      "Test Accuracy: 0.8500\n",
      "\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 489s 11s/step - loss: 0.8143 - accuracy: 0.9930 - recall: 0.9930 - auc: 0.9997 - precision: 0.9930 - val_loss: 1.3013 - val_accuracy: 0.7833 - val_recall: 0.7833 - val_auc: 0.8639 - val_precision: 0.7833\n",
      "Test Accuracy: 0.8083\n",
      "\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 489s 11s/step - loss: 0.8221 - accuracy: 0.9838 - recall: 0.9838 - auc: 0.9993 - precision: 0.9838 - val_loss: 0.9618 - val_accuracy: 0.9167 - val_recall: 0.9167 - val_auc: 0.9739 - val_precision: 0.9167\n",
      "Test Accuracy: 0.8083\n",
      "\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 488s 11s/step - loss: 0.8546 - accuracy: 0.9698 - recall: 0.9698 - auc: 0.9913 - precision: 0.9698 - val_loss: 0.9880 - val_accuracy: 0.9000 - val_recall: 0.9000 - val_auc: 0.9650 - val_precision: 0.9000\n",
      "Test Accuracy: 0.7250\n",
      "\n",
      "Epoch 36/100\n",
      "25/44 [================>.............] - ETA: 3:06 - loss: 0.9235 - accuracy: 0.9502 - recall: 0.9502 - auc: 0.9802 - precision: 0.9502"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model_checkpoint = ModelCheckpoint('UpgradedFilter_ROI_IJK_100_Epoch_v5.h5', monitor='val_accuracy', mode='max', save_best_only=True)\n",
    "\n",
    "num_epoch = 100\n",
    "best_test_accuracy = 0.0\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    print(\"Epoch {}/{}\".format(epoch + 1, num_epoch))\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        epochs=1,\n",
    "        steps_per_epoch=len(train_paths) // batch_size,\n",
    "        validation_data=val_dataset,\n",
    "        validation_steps=len(val_paths) // batch_size,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Evaluate the model on test data\n",
    "    test_metrics = model.evaluate(\n",
    "        test_dataset,\n",
    "        steps=len(test_paths) // batch_size,\n",
    "        verbose=0\n",
    "    )\n",
    "    test_accuracy = test_metrics[1]\n",
    "\n",
    "\n",
    "    if test_accuracy > best_test_accuracy:\n",
    "        print(\"Test accuracy improved from {:.4f} to {:.4f}. Saving model.\".format(best_test_accuracy, test_accuracy))\n",
    "        best_test_accuracy = test_accuracy\n",
    "        model.save('Best_Test_Accuracy_Model.h5')\n",
    "\n",
    "\n",
    "    print(\"Test Accuracy: {:.4f}\".format(test_accuracy))\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('Best_Test_Accuracy_Model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "44/44 [==============================] - 514s 12s/step - loss: 0.8993 - accuracy: 0.9773 - recall: 0.9773 - auc: 0.9956 - precision: 0.9773 - val_loss: 1.1124 - val_accuracy: 0.8833 - val_recall: 0.8833 - val_auc: 0.9244 - val_precision: 0.8833\n",
      "Test accuracy improved from 0.0000 to 0.8833. Saving model.\n",
      "Test Accuracy: 0.8833\n",
      "\n",
      "Epoch 2/50\n",
      "44/44 [==============================] - 511s 12s/step - loss: 0.8507 - accuracy: 0.9886 - recall: 0.9886 - auc: 0.9998 - precision: 0.9886 - val_loss: 0.9094 - val_accuracy: 0.9667 - val_recall: 0.9667 - val_auc: 0.9939 - val_precision: 0.9667\n",
      "Test Accuracy: 0.8333\n",
      "\n",
      "Epoch 3/50\n",
      "44/44 [==============================] - 511s 12s/step - loss: 0.8611 - accuracy: 0.9886 - recall: 0.9886 - auc: 0.9968 - precision: 0.9886 - val_loss: 1.2360 - val_accuracy: 0.8500 - val_recall: 0.8500 - val_auc: 0.9019 - val_precision: 0.8500\n",
      "Test Accuracy: 0.8667\n",
      "\n",
      "Epoch 4/50\n",
      "44/44 [==============================] - 507s 12s/step - loss: 0.8862 - accuracy: 0.9727 - recall: 0.9727 - auc: 0.9932 - precision: 0.9727 - val_loss: 0.9235 - val_accuracy: 0.9500 - val_recall: 0.9500 - val_auc: 0.9922 - val_precision: 0.9500\n",
      "Test Accuracy: 0.8417\n",
      "\n",
      "Epoch 5/50\n",
      "44/44 [==============================] - 509s 12s/step - loss: 0.8504 - accuracy: 0.9909 - recall: 0.9909 - auc: 0.9973 - precision: 0.9909 - val_loss: 0.9684 - val_accuracy: 0.9500 - val_recall: 0.9500 - val_auc: 0.9753 - val_precision: 0.9500\n",
      "Test Accuracy: 0.8250\n",
      "\n",
      "Epoch 6/50\n",
      "44/44 [==============================] - 502s 12s/step - loss: 0.8712 - accuracy: 0.9773 - recall: 0.9773 - auc: 0.9938 - precision: 0.9773 - val_loss: 1.2971 - val_accuracy: 0.7500 - val_recall: 0.7500 - val_auc: 0.8636 - val_precision: 0.7500\n",
      "Test Accuracy: 0.8250\n",
      "\n",
      "Epoch 7/50\n",
      "44/44 [==============================] - 506s 12s/step - loss: 0.8527 - accuracy: 0.9864 - recall: 0.9864 - auc: 0.9970 - precision: 0.9864 - val_loss: 0.9748 - val_accuracy: 0.9167 - val_recall: 0.9167 - val_auc: 0.9786 - val_precision: 0.9167\n",
      "Test Accuracy: 0.8167\n",
      "\n",
      "Epoch 8/50\n",
      "44/44 [==============================] - 504s 12s/step - loss: 0.8614 - accuracy: 0.9727 - recall: 0.9727 - auc: 0.9943 - precision: 0.9727 - val_loss: 1.2752 - val_accuracy: 0.8500 - val_recall: 0.8500 - val_auc: 0.8928 - val_precision: 0.8500\n",
      "Test Accuracy: 0.8083\n",
      "\n",
      "Epoch 9/50\n",
      "44/44 [==============================] - 503s 12s/step - loss: 0.8874 - accuracy: 0.9818 - recall: 0.9818 - auc: 0.9910 - precision: 0.9818 - val_loss: 1.0725 - val_accuracy: 0.8667 - val_recall: 0.8667 - val_auc: 0.9403 - val_precision: 0.8667\n",
      "Test Accuracy: 0.8750\n",
      "\n",
      "Epoch 10/50\n",
      "44/44 [==============================] - 499s 12s/step - loss: 0.8541 - accuracy: 0.9773 - recall: 0.9773 - auc: 0.9987 - precision: 0.9773 - val_loss: 1.2577 - val_accuracy: 0.8333 - val_recall: 0.8333 - val_auc: 0.8867 - val_precision: 0.8333\n",
      "Test Accuracy: 0.8750\n",
      "\n",
      "Epoch 11/50\n",
      "44/44 [==============================] - 499s 12s/step - loss: 0.8452 - accuracy: 0.9886 - recall: 0.9886 - auc: 0.9967 - precision: 0.9886 - val_loss: 0.9087 - val_accuracy: 0.9333 - val_recall: 0.9333 - val_auc: 0.9900 - val_precision: 0.9333\n",
      "Test Accuracy: 0.8583\n",
      "\n",
      "Epoch 12/50\n",
      "44/44 [==============================] - 503s 12s/step - loss: 0.8402 - accuracy: 0.9864 - recall: 0.9864 - auc: 0.9971 - precision: 0.9864 - val_loss: 0.9933 - val_accuracy: 0.9167 - val_recall: 0.9167 - val_auc: 0.9714 - val_precision: 0.9167\n",
      "Test Accuracy: 0.7333\n",
      "\n",
      "Epoch 13/50\n",
      "44/44 [==============================] - 498s 12s/step - loss: 0.8260 - accuracy: 0.9909 - recall: 0.9909 - auc: 0.9996 - precision: 0.9909 - val_loss: 0.9878 - val_accuracy: 0.9167 - val_recall: 0.9167 - val_auc: 0.9656 - val_precision: 0.9167\n",
      "Test Accuracy: 0.8667\n",
      "\n",
      "Epoch 14/50\n",
      "44/44 [==============================] - 501s 12s/step - loss: 0.8374 - accuracy: 0.9818 - recall: 0.9818 - auc: 0.9970 - precision: 0.9818 - val_loss: 1.0135 - val_accuracy: 0.9000 - val_recall: 0.9000 - val_auc: 0.9647 - val_precision: 0.9000\n",
      "Test Accuracy: 0.7833\n",
      "\n",
      "Epoch 15/50\n",
      "44/44 [==============================] - 502s 12s/step - loss: 0.8545 - accuracy: 0.9841 - recall: 0.9841 - auc: 0.9917 - precision: 0.9841 - val_loss: 0.9573 - val_accuracy: 0.9167 - val_recall: 0.9167 - val_auc: 0.9736 - val_precision: 0.9167\n",
      "Test Accuracy: 0.8583\n",
      "\n",
      "Epoch 16/50\n",
      "44/44 [==============================] - 498s 12s/step - loss: 0.8557 - accuracy: 0.9818 - recall: 0.9818 - auc: 0.9936 - precision: 0.9818 - val_loss: 1.0733 - val_accuracy: 0.8667 - val_recall: 0.8667 - val_auc: 0.9456 - val_precision: 0.8667\n",
      "Test accuracy improved from 0.8833 to 0.8917. Saving model.\n",
      "Test Accuracy: 0.8917\n",
      "\n",
      "Epoch 17/50\n",
      "44/44 [==============================] - 512s 12s/step - loss: 0.8384 - accuracy: 0.9818 - recall: 0.9818 - auc: 0.9968 - precision: 0.9818 - val_loss: 1.2198 - val_accuracy: 0.8500 - val_recall: 0.8500 - val_auc: 0.9233 - val_precision: 0.8500\n",
      "Test Accuracy: 0.8333\n",
      "\n",
      "Epoch 18/50\n",
      "44/44 [==============================] - 509s 12s/step - loss: 0.8051 - accuracy: 0.9955 - recall: 0.9955 - auc: 1.0000 - precision: 0.9955 - val_loss: 0.9496 - val_accuracy: 0.9500 - val_recall: 0.9500 - val_auc: 0.9722 - val_precision: 0.9500\n",
      "Test Accuracy: 0.8833\n",
      "\n",
      "Epoch 19/50\n",
      "44/44 [==============================] - 507s 12s/step - loss: 0.8235 - accuracy: 0.9886 - recall: 0.9886 - auc: 0.9972 - precision: 0.9886 - val_loss: 1.1842 - val_accuracy: 0.8833 - val_recall: 0.8833 - val_auc: 0.9253 - val_precision: 0.8833\n",
      "Test Accuracy: 0.8667\n",
      "\n",
      "Epoch 20/50\n",
      "44/44 [==============================] - 504s 12s/step - loss: 0.8133 - accuracy: 0.9864 - recall: 0.9864 - auc: 0.9996 - precision: 0.9864 - val_loss: 0.9374 - val_accuracy: 0.9500 - val_recall: 0.9500 - val_auc: 0.9758 - val_precision: 0.9500\n",
      "Test accuracy improved from 0.8917 to 0.9083. Saving model.\n",
      "Test Accuracy: 0.9083\n",
      "\n",
      "Epoch 21/50\n",
      "44/44 [==============================] - 509s 12s/step - loss: 0.8253 - accuracy: 0.9864 - recall: 0.9864 - auc: 0.9972 - precision: 0.9864 - val_loss: 1.1454 - val_accuracy: 0.8667 - val_recall: 0.8667 - val_auc: 0.9361 - val_precision: 0.8667\n",
      "Test Accuracy: 0.8917\n",
      "\n",
      "Epoch 22/50\n",
      "44/44 [==============================] - 507s 12s/step - loss: 0.8581 - accuracy: 0.9727 - recall: 0.9727 - auc: 0.9940 - precision: 0.9727 - val_loss: 1.0135 - val_accuracy: 0.9333 - val_recall: 0.9333 - val_auc: 0.9447 - val_precision: 0.9333\n",
      "Test Accuracy: 0.7667\n",
      "\n",
      "Epoch 23/50\n",
      "44/44 [==============================] - 505s 12s/step - loss: 0.8570 - accuracy: 0.9705 - recall: 0.9705 - auc: 0.9950 - precision: 0.9705 - val_loss: 1.1571 - val_accuracy: 0.8667 - val_recall: 0.8667 - val_auc: 0.9175 - val_precision: 0.8667\n",
      "Test Accuracy: 0.8917\n",
      "\n",
      "Epoch 24/50\n",
      "44/44 [==============================] - 502s 12s/step - loss: 0.8288 - accuracy: 0.9864 - recall: 0.9864 - auc: 0.9949 - precision: 0.9864 - val_loss: 0.9342 - val_accuracy: 0.9667 - val_recall: 0.9667 - val_auc: 0.9739 - val_precision: 0.9667\n",
      "Test Accuracy: 0.8333\n",
      "\n",
      "Epoch 25/50\n",
      "44/44 [==============================] - 500s 12s/step - loss: 0.8199 - accuracy: 0.9864 - recall: 0.9864 - auc: 0.9993 - precision: 0.9864 - val_loss: 1.9538 - val_accuracy: 0.6167 - val_recall: 0.6167 - val_auc: 0.7211 - val_precision: 0.6167\n",
      "Test Accuracy: 0.7250\n",
      "\n",
      "Epoch 26/50\n",
      "44/44 [==============================] - 499s 12s/step - loss: 0.8232 - accuracy: 0.9886 - recall: 0.9886 - auc: 0.9951 - precision: 0.9886 - val_loss: 1.0334 - val_accuracy: 0.8833 - val_recall: 0.8833 - val_auc: 0.9447 - val_precision: 0.8833\n",
      "Test accuracy improved from 0.9083 to 0.9167. Saving model.\n",
      "Test Accuracy: 0.9167\n",
      "\n",
      "Epoch 27/50\n",
      "44/44 [==============================] - 510s 12s/step - loss: 0.8514 - accuracy: 0.9750 - recall: 0.9750 - auc: 0.9927 - precision: 0.9750 - val_loss: 0.9433 - val_accuracy: 0.9167 - val_recall: 0.9167 - val_auc: 0.9839 - val_precision: 0.9167\n",
      "Test Accuracy: 0.8250\n",
      "\n",
      "Epoch 28/50\n",
      "44/44 [==============================] - 509s 12s/step - loss: 0.7946 - accuracy: 0.9932 - recall: 0.9932 - auc: 0.9999 - precision: 0.9932 - val_loss: 1.4696 - val_accuracy: 0.7667 - val_recall: 0.7667 - val_auc: 0.8383 - val_precision: 0.7667\n",
      "Test Accuracy: 0.8167\n",
      "\n",
      "Epoch 29/50\n",
      "44/44 [==============================] - 506s 12s/step - loss: 0.8195 - accuracy: 0.9841 - recall: 0.9841 - auc: 0.9969 - precision: 0.9841 - val_loss: 0.9507 - val_accuracy: 0.9000 - val_recall: 0.9000 - val_auc: 0.9703 - val_precision: 0.9000\n",
      "Test Accuracy: 0.7667\n",
      "\n",
      "Epoch 30/50\n",
      "44/44 [==============================] - 504s 12s/step - loss: 0.8111 - accuracy: 0.9864 - recall: 0.9864 - auc: 0.9950 - precision: 0.9864 - val_loss: 1.1568 - val_accuracy: 0.8667 - val_recall: 0.8667 - val_auc: 0.9139 - val_precision: 0.8667\n",
      "Test Accuracy: 0.8667\n",
      "\n",
      "Epoch 31/50\n",
      "44/44 [==============================] - 504s 12s/step - loss: 0.7953 - accuracy: 0.9932 - recall: 0.9932 - auc: 0.9976 - precision: 0.9932 - val_loss: 0.9578 - val_accuracy: 0.9000 - val_recall: 0.9000 - val_auc: 0.9794 - val_precision: 0.9000\n",
      "Test Accuracy: 0.8500\n",
      "\n",
      "Epoch 32/50\n",
      "44/44 [==============================] - 500s 12s/step - loss: 0.7967 - accuracy: 0.9932 - recall: 0.9932 - auc: 0.9996 - precision: 0.9932 - val_loss: 0.9844 - val_accuracy: 0.9167 - val_recall: 0.9167 - val_auc: 0.9531 - val_precision: 0.9167\n",
      "Test Accuracy: 0.8333\n",
      "\n",
      "Epoch 33/50\n",
      "44/44 [==============================] - 501s 12s/step - loss: 0.8352 - accuracy: 0.9705 - recall: 0.9705 - auc: 0.9957 - precision: 0.9705 - val_loss: 1.0033 - val_accuracy: 0.9333 - val_recall: 0.9333 - val_auc: 0.9625 - val_precision: 0.9333\n",
      "Test Accuracy: 0.8000\n",
      "\n",
      "Epoch 34/50\n",
      "44/44 [==============================] - 503s 12s/step - loss: 0.8156 - accuracy: 0.9773 - recall: 0.9773 - auc: 0.9966 - precision: 0.9773 - val_loss: 0.9485 - val_accuracy: 0.9167 - val_recall: 0.9167 - val_auc: 0.9769 - val_precision: 0.9167\n",
      "Test Accuracy: 0.8833\n",
      "\n",
      "Epoch 35/50\n",
      "44/44 [==============================] - 502s 12s/step - loss: 0.8231 - accuracy: 0.9727 - recall: 0.9727 - auc: 0.9942 - precision: 0.9727 - val_loss: 1.0144 - val_accuracy: 0.8667 - val_recall: 0.8667 - val_auc: 0.9525 - val_precision: 0.8667\n",
      "Test Accuracy: 0.7583\n",
      "\n",
      "Epoch 36/50\n",
      "44/44 [==============================] - 500s 12s/step - loss: 0.7969 - accuracy: 0.9864 - recall: 0.9864 - auc: 0.9994 - precision: 0.9864 - val_loss: 1.0312 - val_accuracy: 0.9167 - val_recall: 0.9167 - val_auc: 0.9569 - val_precision: 0.9167\n",
      "Test Accuracy: 0.9000\n",
      "\n",
      "Epoch 37/50\n",
      "44/44 [==============================] - 497s 12s/step - loss: 0.7735 - accuracy: 0.9977 - recall: 0.9977 - auc: 1.0000 - precision: 0.9977 - val_loss: 0.9597 - val_accuracy: 0.8833 - val_recall: 0.8833 - val_auc: 0.9658 - val_precision: 0.8833\n",
      "Test Accuracy: 0.8500\n",
      "\n",
      "Epoch 38/50\n",
      "44/44 [==============================] - 517s 12s/step - loss: 0.7806 - accuracy: 0.9977 - recall: 0.9977 - auc: 0.9998 - precision: 0.9977 - val_loss: 1.1668 - val_accuracy: 0.9167 - val_recall: 0.9167 - val_auc: 0.9151 - val_precision: 0.9167\n",
      "Test Accuracy: 0.8750\n",
      "\n",
      "Epoch 39/50\n",
      "44/44 [==============================] - 509s 12s/step - loss: 0.7812 - accuracy: 0.9909 - recall: 0.9909 - auc: 0.9997 - precision: 0.9909 - val_loss: 2.0335 - val_accuracy: 0.6167 - val_recall: 0.6167 - val_auc: 0.7064 - val_precision: 0.6167\n",
      "Test Accuracy: 0.7333\n",
      "\n",
      "Epoch 40/50\n",
      "44/44 [==============================] - 509s 12s/step - loss: 0.7872 - accuracy: 0.9909 - recall: 0.9909 - auc: 0.9995 - precision: 0.9909 - val_loss: 1.3109 - val_accuracy: 0.8500 - val_recall: 0.8500 - val_auc: 0.8564 - val_precision: 0.8500\n",
      "Test Accuracy: 0.8417\n",
      "\n",
      "Epoch 41/50\n",
      "44/44 [==============================] - 511s 12s/step - loss: 0.8026 - accuracy: 0.9818 - recall: 0.9818 - auc: 0.9969 - precision: 0.9818 - val_loss: 1.1280 - val_accuracy: 0.8667 - val_recall: 0.8667 - val_auc: 0.9222 - val_precision: 0.8667\n",
      "Test Accuracy: 0.8583\n",
      "\n",
      "Epoch 42/50\n",
      "44/44 [==============================] - 507s 12s/step - loss: 0.7934 - accuracy: 0.9909 - recall: 0.9909 - auc: 0.9972 - precision: 0.9909 - val_loss: 1.0152 - val_accuracy: 0.8833 - val_recall: 0.8833 - val_auc: 0.9342 - val_precision: 0.8833\n",
      "Test Accuracy: 0.7833\n",
      "\n",
      "Epoch 43/50\n",
      "44/44 [==============================] - 508s 12s/step - loss: 0.7942 - accuracy: 0.9841 - recall: 0.9841 - auc: 0.9950 - precision: 0.9841 - val_loss: 1.0741 - val_accuracy: 0.8667 - val_recall: 0.8667 - val_auc: 0.9314 - val_precision: 0.8667\n",
      "Test Accuracy: 0.8833\n",
      "\n",
      "Epoch 44/50\n",
      "44/44 [==============================] - 508s 12s/step - loss: 0.7883 - accuracy: 0.9864 - recall: 0.9864 - auc: 0.9972 - precision: 0.9864 - val_loss: 0.9911 - val_accuracy: 0.8833 - val_recall: 0.8833 - val_auc: 0.9650 - val_precision: 0.8833\n",
      "Test Accuracy: 0.8000\n",
      "\n",
      "Epoch 45/50\n",
      "44/44 [==============================] - 507s 12s/step - loss: 0.8014 - accuracy: 0.9795 - recall: 0.9795 - auc: 0.9964 - precision: 0.9795 - val_loss: 0.9831 - val_accuracy: 0.9000 - val_recall: 0.9000 - val_auc: 0.9544 - val_precision: 0.9000\n",
      "Test Accuracy: 0.8917\n",
      "\n",
      "Epoch 46/50\n",
      "44/44 [==============================] - 503s 12s/step - loss: 0.7971 - accuracy: 0.9841 - recall: 0.9841 - auc: 0.9966 - precision: 0.9841 - val_loss: 0.8994 - val_accuracy: 0.9000 - val_recall: 0.9000 - val_auc: 0.9733 - val_precision: 0.9000\n",
      "Test Accuracy: 0.8583\n",
      "\n",
      "Epoch 47/50\n",
      "44/44 [==============================] - 503s 12s/step - loss: 0.7773 - accuracy: 0.9864 - recall: 0.9864 - auc: 0.9997 - precision: 0.9864 - val_loss: 1.0659 - val_accuracy: 0.8667 - val_recall: 0.8667 - val_auc: 0.9494 - val_precision: 0.8667\n",
      "Test Accuracy: 0.8833\n",
      "\n",
      "Epoch 48/50\n",
      "44/44 [==============================] - 500s 12s/step - loss: 0.7897 - accuracy: 0.9841 - recall: 0.9841 - auc: 0.9946 - precision: 0.9841 - val_loss: 1.0761 - val_accuracy: 0.8500 - val_recall: 0.8500 - val_auc: 0.9386 - val_precision: 0.8500\n",
      "Test Accuracy: 0.9083\n",
      "\n",
      "Epoch 49/50\n",
      "44/44 [==============================] - 504s 12s/step - loss: 0.7709 - accuracy: 0.9955 - recall: 0.9955 - auc: 0.9975 - precision: 0.9955 - val_loss: 1.2888 - val_accuracy: 0.8333 - val_recall: 0.8333 - val_auc: 0.8897 - val_precision: 0.8333\n",
      "Test Accuracy: 0.9000\n",
      "\n",
      "Epoch 50/50\n",
      "44/44 [==============================] - 508s 12s/step - loss: 0.7704 - accuracy: 0.9909 - recall: 0.9909 - auc: 0.9975 - precision: 0.9909 - val_loss: 1.0892 - val_accuracy: 0.8333 - val_recall: 0.8333 - val_auc: 0.9175 - val_precision: 0.8333\n",
      "Test Accuracy: 0.8167\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model_checkpoint = ModelCheckpoint('Best_Test_Accuracy_Model.h5', monitor='val_accuracy', mode='max', save_best_only=True)\n",
    "\n",
    "num_epoch = 50\n",
    "best_test_accuracy = 0.0\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    print(\"Epoch {}/{}\".format(epoch + 1, num_epoch))\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        epochs=1,\n",
    "        steps_per_epoch=len(train_paths) // batch_size,\n",
    "        validation_data=val_dataset,\n",
    "        validation_steps=len(val_paths) // batch_size,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Evaluate the model on test data\n",
    "    test_metrics = model.evaluate(\n",
    "        test_dataset,\n",
    "        steps=len(test_paths) // batch_size,\n",
    "        verbose=0\n",
    "    )\n",
    "    test_accuracy = test_metrics[1]\n",
    "\n",
    "\n",
    "    if test_accuracy > best_test_accuracy:\n",
    "        print(\"Test accuracy improved from {:.4f} to {:.4f}. Saving model.\".format(best_test_accuracy, test_accuracy))\n",
    "        best_test_accuracy = test_accuracy\n",
    "        model.save('Best_Test_Accuracy_Model_v2.h5')\n",
    "\n",
    "\n",
    "    print(\"Test Accuracy: {:.4f}\".format(test_accuracy))\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "44/44 [==============================] - 514s 12s/step - loss: 1.0093 - accuracy: 0.9432 - recall: 0.9432 - auc: 0.9748 - precision: 0.9432 - val_loss: 0.9774 - val_accuracy: 0.9667 - val_recall: 0.9667 - val_auc: 0.9928 - val_precision: 0.9667\n",
      "Validation accuracy improved from 0.0 to 0.9666666388511658. Saving model...\n",
      "Test Accuracy: 0.8833\n",
      "\n",
      "Epoch 2/4\n",
      "44/44 [==============================] - 515s 12s/step - loss: 1.0205 - accuracy: 0.9409 - recall: 0.9409 - auc: 0.9740 - precision: 0.9409 - val_loss: 0.9421 - val_accuracy: 0.9833 - val_recall: 0.9833 - val_auc: 0.9981 - val_precision: 0.9833\n",
      "Validation accuracy improved from 0.9666666388511658 to 0.9833333492279053. Saving model...\n",
      "Test Accuracy: 0.8333\n",
      "\n",
      "Epoch 3/4\n",
      "44/44 [==============================] - 512s 12s/step - loss: 0.9743 - accuracy: 0.9386 - recall: 0.9386 - auc: 0.9875 - precision: 0.9386 - val_loss: 1.0788 - val_accuracy: 0.9000 - val_recall: 0.9000 - val_auc: 0.9692 - val_precision: 0.9000\n",
      "Validation accuracy did not improve. Model not saved.\n",
      "Test Accuracy: 0.8417\n",
      "\n",
      "Epoch 4/4\n",
      "44/44 [==============================] - 504s 12s/step - loss: 0.9658 - accuracy: 0.9523 - recall: 0.9523 - auc: 0.9853 - precision: 0.9523 - val_loss: 0.9729 - val_accuracy: 0.9833 - val_recall: 0.9833 - val_auc: 0.9775 - val_precision: 0.9833\n",
      "Validation accuracy did not improve. Model not saved.\n",
      "Test Accuracy: 0.8333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "num_epoch = 4\n",
    "best_val_accuracy = 0.0\n",
    "model_checkpoint_path = 'UpgradedFilter_ROI_IJK_100_Epoch_v4.h5'\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    print(\"Epoch {}/{}\".format(epoch + 1, num_epoch))\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        epochs=1,  \n",
    "        steps_per_epoch=len(train_paths) // batch_size,\n",
    "        validation_data=val_dataset,\n",
    "        validation_steps=len(val_paths) // batch_size,\n",
    "        verbose=1 \n",
    "    )\n",
    "\n",
    "    # Evaluate the model on validation data\n",
    "    val_accuracy = history.history['val_accuracy'][0]\n",
    "\n",
    "    # Evaluate the model on test data\n",
    "    test_metrics = model.evaluate(\n",
    "        test_dataset,\n",
    "        steps=len(test_paths) // batch_size,\n",
    "        verbose=0\n",
    "    )\n",
    "    test_accuracy = test_metrics[1]\n",
    "\n",
    "    # Save the model if validation accuracy improved\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        print(\"Validation accuracy improved from {} to {}. Saving model...\".format(best_val_accuracy, val_accuracy))\n",
    "        best_val_accuracy = val_accuracy\n",
    "        model.save(model_checkpoint_path)\n",
    "    else:\n",
    "        print(\"Validation accuracy did not improve. Model not saved.\")\n",
    "    \n",
    "    # Print test metrics\n",
    "    print(\"Test Accuracy: {:.4f}\".format(test_accuracy))\n",
    "\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the saved model\n",
    "saved_model = tf.keras.models.load_model('Best_Test_Accuracy_Model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "predictions = saved_model.predict(test_dataset, steps=len(test_paths) // batch_size)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "\n",
    "conf_matrix = confusion_matrix(test_labels[:len(predicted_labels)], predicted_labels)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='g', cmap='Blues', \n",
    "            xticklabels=['AD', 'MCI'], yticklabels=['AD', 'MCI'])\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('AD vs MCI: ROIs')\n",
    "plt.savefig('confusion_matrix_6roi_ADvsMCI.png')\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_conda",
   "language": "python",
   "name": "tf_conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
