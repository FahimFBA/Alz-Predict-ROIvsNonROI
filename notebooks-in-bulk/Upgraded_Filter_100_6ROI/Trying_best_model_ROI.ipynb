{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import nibabel\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from skimage.filters import unsharp_mask\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from skimage.transform import resize\n",
    "from dipy.align.imwarp import SymmetricDiffeomorphicRegistration\n",
    "from dipy.align.metrics import CCMetric\n",
    "from dipy.align.imaffine import AffineMap\n",
    "from dipy.align import resample\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Activation, Dense, Flatten\n",
    "from tensorflow.keras.layers import Conv3D, AveragePooling3D, MaxPooling3D\n",
    "from tensorflow.keras.layers import add, multiply, GlobalAveragePooling3D, GlobalMaxPooling3D, Reshape\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import six\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def _bn_relu(input):\n",
    "    \"\"\"Helper to build a BN -> relu block (by @raghakot).\"\"\"\n",
    "    norm = BatchNormalization(axis=CHANNEL_AXIS)(input)\n",
    "    return Activation(\"relu\")(norm)\n",
    "\n",
    "def _conv_bn_relu3D(**conv_params):\n",
    "    filters = conv_params[\"filters\"]\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1, 1))\n",
    "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1e-4))\n",
    "\n",
    "    def f(input):\n",
    "        conv = Conv3D(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            strides=strides,\n",
    "            kernel_initializer=kernel_initializer,\n",
    "            padding=padding,\n",
    "            kernel_regularizer=kernel_regularizer,\n",
    "        )(input)\n",
    "        return _bn_relu(conv)\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def _bn_relu_conv3d(**conv_params):\n",
    "    filters = conv_params[\"filters\"]\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1, 1))\n",
    "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1e-4))\n",
    "\n",
    "    def f(input):\n",
    "        activation = _bn_relu(input)\n",
    "        return Conv3D(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            strides=strides,\n",
    "            kernel_initializer=kernel_initializer,\n",
    "            padding=padding,\n",
    "            kernel_regularizer=kernel_regularizer,\n",
    "        )(activation)\n",
    "\n",
    "    return f\n",
    "\n",
    "def _shortcut3d(input, residual):\n",
    "    stride_dim1 = ceil(input.shape[DIM1_AXIS] / residual.shape[DIM1_AXIS])\n",
    "    stride_dim2 = ceil(input.shape[DIM2_AXIS] / residual.shape[DIM2_AXIS])\n",
    "    stride_dim3 = ceil(input.shape[DIM3_AXIS] / residual.shape[DIM3_AXIS])\n",
    "    equal_channels = residual.shape[CHANNEL_AXIS] == input.shape[CHANNEL_AXIS]\n",
    "\n",
    "    shortcut = input\n",
    "    if stride_dim1 > 1 or stride_dim2 > 1 or stride_dim3 > 1 or not equal_channels:\n",
    "        shortcut = Conv3D(\n",
    "            filters=residual.shape[CHANNEL_AXIS],\n",
    "            kernel_size=(1, 1, 1),\n",
    "            strides=(stride_dim1, stride_dim2, stride_dim3),\n",
    "            kernel_initializer=\"he_normal\",\n",
    "            padding=\"valid\",\n",
    "            kernel_regularizer=l2(1e-4),\n",
    "        )(input)\n",
    "    return add([shortcut, residual])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def _conv_bn_relu3D(**conv_params):\n",
    "    filters = conv_params[\"filters\"]\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1, 1))\n",
    "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1e-4))\n",
    "\n",
    "    def f(input):\n",
    "        conv = Conv3D(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            strides=strides,\n",
    "            kernel_initializer=kernel_initializer,\n",
    "            padding=padding,\n",
    "            kernel_regularizer=kernel_regularizer,\n",
    "        )(input)\n",
    "        return _bn_relu(conv)\n",
    "\n",
    "    return f\n",
    "\n",
    "def _bn_relu_conv3d(**conv_params):\n",
    "    filters = conv_params[\"filters\"]\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1, 1))\n",
    "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1e-4))\n",
    "\n",
    "    def f(input):\n",
    "        activation = _bn_relu(input)\n",
    "        return Conv3D(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            strides=strides,\n",
    "            kernel_initializer=kernel_initializer,\n",
    "            padding=padding,\n",
    "            kernel_regularizer=kernel_regularizer,\n",
    "        )(activation)\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def _shortcut3d(input, residual):\n",
    "    stride_dim1 = ceil(input.shape[DIM1_AXIS] / residual.shape[DIM1_AXIS])\n",
    "    stride_dim2 = ceil(input.shape[DIM2_AXIS] / residual.shape[DIM2_AXIS])\n",
    "    stride_dim3 = ceil(input.shape[DIM3_AXIS] / residual.shape[DIM3_AXIS])\n",
    "    equal_channels = residual.shape[CHANNEL_AXIS] == input.shape[CHANNEL_AXIS]\n",
    "\n",
    "    shortcut = input\n",
    "    if stride_dim1 > 1 or stride_dim2 > 1 or stride_dim3 > 1 or not equal_channels:\n",
    "        shortcut = Conv3D(\n",
    "            filters=residual.shape[CHANNEL_AXIS],\n",
    "            kernel_size=(1, 1, 1),\n",
    "            strides=(stride_dim1, stride_dim2, stride_dim3),\n",
    "            kernel_initializer=\"he_normal\",\n",
    "            padding=\"valid\",\n",
    "            kernel_regularizer=l2(1e-4),\n",
    "        )(input)\n",
    "    return add([shortcut, residual])\n",
    "\n",
    "def _residual_block_with_cbam(\n",
    "    filters,\n",
    "    kernel_regularizer,\n",
    "    is_first_layer=False,\n",
    "):\n",
    "    def f(input):\n",
    "        strides = (2, 2, 2) if not is_first_layer else (1, 1, 1)\n",
    "        conv1 = _conv_bn_relu3D(\n",
    "            filters=filters,\n",
    "            kernel_size=(5, 5, 5),  # Changed kernel size\n",
    "            strides=strides,\n",
    "            kernel_regularizer=kernel_regularizer,\n",
    "        )(input)\n",
    "        \n",
    "        conv2 = _conv_bn_relu3D(\n",
    "            filters=filters,\n",
    "            kernel_size=(5, 5, 5),  # Changed kernel size\n",
    "            kernel_regularizer=kernel_regularizer,\n",
    "        )(conv1)\n",
    "\n",
    "        # CBAM module\n",
    "        channel_avg_pool = GlobalAveragePooling3D()(conv2)\n",
    "        channel_max_pool = GlobalMaxPooling3D()(conv2)\n",
    "        channel_attention = add([Dense(filters // 2, activation='relu')(channel_avg_pool),\n",
    "                                 Dense(filters // 2, activation='relu')(channel_max_pool)])\n",
    "        channel_attention = Activation('sigmoid')(Dense(filters, activation='relu')(channel_attention))\n",
    "        channel_attention = Reshape((1, 1, 1, filters))(channel_attention)\n",
    "        channel_attention = multiply([conv2, channel_attention])\n",
    "\n",
    "        spatial_attention = Conv3D(1, (1, 1, 1), activation='sigmoid', padding='same', kernel_initializer='he_normal')(conv2)\n",
    "        attention = multiply([conv2, spatial_attention])\n",
    "\n",
    "        conv2 = add([channel_attention, attention])\n",
    "        \n",
    "        return _shortcut3d(input, conv2)\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def basic_block(\n",
    "    filters,\n",
    "    strides=(1, 1, 1),\n",
    "    kernel_regularizer=l2(1e-4),\n",
    "    is_first_block_of_first_layer=False,\n",
    "):\n",
    "    def f(input):\n",
    "        if is_first_block_of_first_layer:\n",
    "            conv1 = Conv3D(\n",
    "                filters=filters,\n",
    "                kernel_size=(5, 5, 5),  # Changed kernel size\n",
    "                strides=strides,\n",
    "                padding=\"same\",\n",
    "                kernel_initializer=\"he_normal\",\n",
    "                kernel_regularizer=kernel_regularizer,\n",
    "            )(input)\n",
    "        else:\n",
    "            conv1 = _bn_relu_conv3d(\n",
    "                filters=filters,\n",
    "                kernel_size=(5, 5, 5),  # Changed kernel size\n",
    "                strides=strides,\n",
    "                kernel_regularizer=kernel_regularizer,\n",
    "            )(input)\n",
    "\n",
    "        residual = _bn_relu_conv3d(\n",
    "            filters=filters,\n",
    "            kernel_size=(5, 5, 5),  # Changed kernel size\n",
    "            kernel_regularizer=kernel_regularizer,\n",
    "        )(conv1)\n",
    "        return _shortcut3d(input, residual)\n",
    "\n",
    "    return f\n",
    "\n",
    "def _handle_data_format():\n",
    "    global DIM1_AXIS\n",
    "    global DIM2_AXIS\n",
    "    global DIM3_AXIS\n",
    "    global CHANNEL_AXIS\n",
    "    if K.image_data_format() == \"channels_last\":\n",
    "        DIM1_AXIS = 1\n",
    "        DIM2_AXIS = 2\n",
    "        DIM3_AXIS = 3\n",
    "        CHANNEL_AXIS = 4\n",
    "    else:\n",
    "        CHANNEL_AXIS = 1\n",
    "        DIM1_AXIS = 2\n",
    "        DIM2_AXIS = 3\n",
    "        DIM3_AXIS = 4\n",
    "\n",
    "def _get_block(identifier):\n",
    "    if isinstance(identifier, six.string_types):\n",
    "        res = globals().get(identifier)\n",
    "        if not res:\n",
    "            raise ValueError(\"Invalid {}\".format(identifier))\n",
    "        return res\n",
    "    return identifier\n",
    "\n",
    "class Resnet3DBuilder(object):\n",
    "    \"\"\"ResNet3D.\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def build(input_shape, num_outputs, block_fn, repetitions, reg_factor):\n",
    "        \"\"\"Instantiate a vanilla ResNet3D keras model.\n",
    "\n",
    "        # Arguments\n",
    "            input_shape: Tuple of input shape in the format\n",
    "            (conv_dim1, conv_dim2, conv_dim3, channels) if dim_ordering='tf'\n",
    "            (filter, conv_dim1, conv_dim2, conv_dim3) if dim_ordering='th'\n",
    "            num_outputs: The number of outputs at the final softmax layer\n",
    "            block_fn: Unit block to use {'basic_block', 'bottlenack_block'}\n",
    "            repetitions: Repetitions of unit blocks\n",
    "        # Returns\n",
    "            model: a 3D ResNet model that takes a 5D tensor (volumetric images\n",
    "            in batch) as input and returns a 1D vector (prediction) as output.\n",
    "        \"\"\"\n",
    "        _handle_data_format()\n",
    "        if len(input_shape) != 4:\n",
    "            raise ValueError(\n",
    "                \"Input shape should be a tuple \"\n",
    "                \"(conv_dim1, conv_dim2, conv_dim3, channels) \"\n",
    "                \"for tensorflow as backend or \"\n",
    "                \"(channels, conv_dim1, conv_dim2, conv_dim3) \"\n",
    "                \"for theano as backend\"\n",
    "            )\n",
    "\n",
    "        block_fn = _get_block(block_fn)\n",
    "        input = Input(shape=input_shape)\n",
    "        # first conv\n",
    "        conv1 = _conv_bn_relu3D(\n",
    "            filters=64,  # Changed filter size\n",
    "            kernel_size=(5, 5, 5),  # Changed kernel size\n",
    "            strides=(2, 2, 2),\n",
    "            kernel_regularizer=l2(reg_factor),\n",
    "        )(input)\n",
    "        pool1 = MaxPooling3D(pool_size=(3, 3, 3), strides=(2, 2, 2), padding=\"same\")(\n",
    "            conv1\n",
    "        )\n",
    "\n",
    "        # repeat blocks\n",
    "        block = pool1\n",
    "        filters = 64  # Changed filter size\n",
    "        for i, r in enumerate(repetitions):\n",
    "            block = _residual_block_with_cbam(\n",
    "                filters=filters,\n",
    "                kernel_regularizer=l2(reg_factor),\n",
    "                is_first_layer=(i == 0),\n",
    "            )(block)\n",
    "            filters *= 2\n",
    "\n",
    "        # last activation\n",
    "        block_output = _bn_relu(block)\n",
    "\n",
    "        # average pool and classification\n",
    "        pool2 = AveragePooling3D(\n",
    "            pool_size=(\n",
    "                block.shape[DIM1_AXIS],\n",
    "                block.shape[DIM2_AXIS],\n",
    "                block.shape[DIM3_AXIS],\n",
    "            ),\n",
    "            strides=(1, 1, 1),\n",
    "        )(block_output)\n",
    "        flatten1 = Flatten()(pool2)\n",
    "        if num_outputs > 1:\n",
    "            dense = Dense(\n",
    "                units=num_outputs,\n",
    "                kernel_initializer=\"he_normal\",\n",
    "                activation=\"softmax\",\n",
    "                kernel_regularizer=l2(reg_factor),\n",
    "            )(flatten1)\n",
    "        else:\n",
    "            dense = Dense(\n",
    "                units=num_outputs,\n",
    "                kernel_initializer=\"he_normal\",\n",
    "                activation=\"sigmoid\",\n",
    "                kernel_regularizer=l2(reg_factor),\n",
    "            )(flatten1)\n",
    "\n",
    "        model = Model(inputs=input, outputs=dense)\n",
    "        return model\n",
    "\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_152(input_shape, num_outputs, reg_factor=1e-4):\n",
    "        \"\"\"Build resnet 152.\"\"\"\n",
    "        return Resnet3DBuilder.build(\n",
    "            input_shape, num_outputs, basic_block, [3, 16, 36, 6], reg_factor=reg_factor\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Testing the model\n",
    "def apply_mask(aseg_image, brain_image, labels = [17, 53, 2, 7, 41, 46]):\n",
    "    brain_data = aseg_image.get_fdata()\n",
    "    aseg_data = aseg_image.get_fdata()\n",
    "    origin_data = brain_image.get_fdata()\n",
    "    \n",
    "    brain_mask = np.zeros_like(aseg_data)\n",
    "    for label in labels:\n",
    "        brain_mask += np.where((aseg_data == label), 1, 0)\n",
    "\n",
    "    new_image = origin_data * brain_mask\n",
    "    \n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def enhance_slice(slice_data):\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    enhanced_slice = clahe.apply(slice_data.astype(np.uint8))\n",
    "\n",
    "    return enhanced_slice\n",
    "\n",
    "def enhance_image(img_data):\n",
    "    enhanced_image = np.zeros_like(img_data)\n",
    "    for i in range(img_data.shape[2]):\n",
    "        enhanced_image[:, :, i] = enhance_slice(img_data[:, :, i])\n",
    "    return enhanced_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sharpen_image(image, strength=1.0):\n",
    "    sharpened_image = unsharp_mask(image, radius=1, amount=strength)\n",
    "    return sharpened_image\n",
    "\n",
    "def apply_nonlinear_registration(moving_image, fixed_image):\n",
    "    metric = CCMetric(3)\n",
    "\n",
    "    sdr = SymmetricDiffeomorphicRegistration(metric, [10, 10, 10], step_length=0.25, ss_sigma_factor=1.5)\n",
    "\n",
    "    mapping = sdr.optimize(fixed_image, moving_image)\n",
    "\n",
    "    warped_moving_image = mapping.transform(moving_image)\n",
    "\n",
    "    return warped_moving_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def image_fixed(image_type, target_shape):\n",
    "    aseg_image = nibabel.load('/home/uiu/Project/adni-1-5t-filtered-preprocessed-quickseg-dataset/AD/I65597.nii')\n",
    "    base_path = \"/home/uiu/Project/adni-1-5t-filtered-preprocessed-quickseg-dataset/AD/I65597.nii/mri/orig.mgz\"\n",
    "    origin_image =  nibabel.load(base_path)\n",
    "    \n",
    "    if (image_type == 'roi') :\n",
    "        image = apply_mask(aseg_image, origin_image)\n",
    "        image = resize(image, target_shape, anti_aliasing=True)\n",
    "        image = sharpen_image(image)\n",
    "        return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage import rotate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def augment(image, rotation_range):\n",
    "    rotation_angle = np.random.uniform(-rotation_range, rotation_range)\n",
    "    rotated_image = rotate(image, rotation_angle, reshape=False)\n",
    "    \n",
    "    return rotated_image\n",
    "\n",
    "\n",
    "\n",
    "def image_loader_roi(image_path, target_shape, type_dt=''):\n",
    "    aseg_image = nibabel.load(image_path)\n",
    "    base_path = \"/\".join(image_path.split('/')[:-1]) + \"/orig.mgz\"\n",
    "    base_image =  nibabel.load(base_path)\n",
    "    \n",
    "    image = apply_mask(aseg_image, base_image)\n",
    "    image = resize(image, target_shape, anti_aliasing=True)\n",
    "    image = enhance_image(image)\n",
    "    image = sharpen_image(image)\n",
    "    \n",
    "    if type_dt=='train':\n",
    "        image = augment(image, 50)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def data_generator(paths, labels, batch_size, target_shape, image_type, type_dt=''):\n",
    "    while True:\n",
    "        for i in range(0, len(paths), batch_size):\n",
    "            batch_paths = paths[i:i+batch_size]\n",
    "            batch_labels = labels[i:i+batch_size]\n",
    "            batch_images = []\n",
    "            \n",
    "    \n",
    "            if image_type == 'roi':\n",
    "                batch_images = [image_loader_roi(image, target_shape, type_dt) for image in batch_paths]\n",
    "\n",
    "\n",
    "            batch_images = np.stack([batch_images] * 1, axis=-1)\n",
    "\n",
    "            batch_labels = to_categorical(batch_labels, num_classes=2)\n",
    "            yield np.array(batch_images), batch_labels\n",
    "base_dir = '/home/uiu/Project/adni-1-5t-filtered-preprocessed-quickseg-dataset'\n",
    "ad = os.path.join(base_dir, 'AD')\n",
    "mci = os.path.join(base_dir, 'MCI')\n",
    "cn = os.path.join(base_dir, 'CN')\n",
    "# original shape (257, 257, 257)\n",
    "\n",
    "ad_images= []\n",
    "mci_images = []\n",
    "cn_images = []\n",
    "\n",
    "for subject_dir in os.listdir(ad):\n",
    "    mri_path = os.path.join(ad, subject_dir, 'mri', 'aparc.DKTatlas+aseg.deep.mgz')\n",
    "    if not (len(os.listdir(os.path.join(ad, subject_dir, 'mri'))) < 6):\n",
    "        ad_images.append(mri_path)\n",
    "        \n",
    "for subject_dir in os.listdir(mci):\n",
    "    mri_path = os.path.join(mci, subject_dir, 'mri', 'aparc.DKTatlas+aseg.deep.mgz')\n",
    "    \n",
    "    if not (len(os.listdir(os.path.join(mci, subject_dir, 'mri'))) < 6):\n",
    "        mci_images.append(mri_path)\n",
    "        \n",
    "for subject_dir in os.listdir(cn):\n",
    "    mri_path = os.path.join(cn, subject_dir, 'mri', 'aparc.DKTatlas+aseg.deep.mgz')\n",
    "    if not (len(os.listdir(os.path.join(cn, subject_dir, 'mri'))) < 6):\n",
    "        cn_images.append(mri_path)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "image_path = mci_images + cn_images + cn_images[:len(mci_images)-len(cn_images)]\n",
    "labels = [0] * len(mci_images) + [1] * len(cn_images) + [1] * len(cn_images[:len(mci_images)-len(cn_images)])\n",
    "len(image_path), len(labels), len(mci_images), len(cn_images + cn_images[:len(mci_images)-len(cn_images)])\n",
    "train_paths, test_paths, train_labels, test_labels = train_test_split(image_path, labels, test_size=0.2, random_state=42)\n",
    "train_paths, val_paths, train_labels, val_labels = train_test_split(train_paths, train_labels, test_size=0.125, random_state=42)\n",
    "\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)\n",
    "len(train_paths), len(val_paths), len(test_paths), np.unique(train_labels)\n",
    "\n",
    "train_paths = np.array(train_paths)\n",
    "train_labels = np.array(train_labels)\n",
    "val_paths = np.array(val_paths)\n",
    "val_labels = np.array(val_labels)\n",
    "test_paths = np.array(test_paths)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "train_paths, train_labels = shuffle(train_paths, train_labels, random_state=42)\n",
    "val_paths, val_labels = shuffle(val_paths, val_labels, random_state=42)\n",
    "test_paths, test_labels = shuffle(test_paths, test_labels, random_state=42)\n",
    "target_shape = (100, 100, 100)\n",
    "batch_size = 10\n",
    "selection_type = 'roi'\n",
    "train_dataset = data_generator(train_paths, train_labels, batch_size, target_shape, \n",
    "                               image_type=selection_type, \n",
    "                               type_dt='train'\n",
    "                              )\n",
    "val_dataset = data_generator(val_paths, val_labels, batch_size, target_shape, \n",
    "                             image_type=selection_type)\n",
    "test_dataset = data_generator(test_paths, test_labels, batch_size, target_shape, \n",
    "                              image_type=selection_type\n",
    "                             )\n",
    "len(train_paths), len(val_paths), len(test_paths), len(train_labels), class_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "classes = 2\n",
    "image_shape = (*target_shape, 1)\n",
    "model = Resnet3DBuilder.build_resnet_152(input_shape = image_shape, num_outputs=classes)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(0.00001), \n",
    "    loss='binary_crossentropy', \n",
    "    metrics=['accuracy', 'Recall', 'AUC', 'Precision'] \n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = ModelCheckpoint('best_model_ROI.h5', monitor='val_accuracy', mode='max', save_best_only=True)\n",
    "\n",
    "num_epoch = 50\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=num_epoch,\n",
    "    steps_per_epoch=len(train_paths) // batch_size,\n",
    "    validation_data=val_dataset,\n",
    "    validation_steps=len(val_paths) // batch_size,\n",
    "    callbacks=[model_checkpoint]  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the best model and evaluate on test data\n",
    "saved_model = tf.keras.models.load_model(model_checkpoint_path)\n",
    "test_accuracy = saved_model.evaluate(\n",
    "    test_dataset,\n",
    "    steps=len(test_paths) // batch_size,\n",
    "    verbose=1\n",
    ")\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_conda",
   "language": "python",
   "name": "tf_conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
