{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uiu/miniconda3/envs/tf_conda/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import nibabel\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from skimage.filters import unsharp_mask\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from skimage.transform import resize\n",
    "from dipy.align.imwarp import SymmetricDiffeomorphicRegistration\n",
    "from dipy.align.metrics import CCMetric\n",
    "from dipy.align.imaffine import AffineMap\n",
    "from dipy.align import resample\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Activation, Dense, Flatten\n",
    "from tensorflow.keras.layers import Conv3D, AveragePooling3D, MaxPooling3D\n",
    "from tensorflow.keras.layers import add, multiply, GlobalAveragePooling3D, GlobalMaxPooling3D, Reshape\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import six\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bn_relu(input):\n",
    "    \"\"\"Helper to build a BN -> relu block (by @raghakot).\"\"\"\n",
    "    norm = BatchNormalization(axis=CHANNEL_AXIS)(input)\n",
    "    return Activation(\"relu\")(norm)\n",
    "\n",
    "def _conv_bn_relu3D(**conv_params):\n",
    "    filters = conv_params[\"filters\"]\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1, 1))\n",
    "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1e-4))\n",
    "\n",
    "    def f(input):\n",
    "        conv = Conv3D(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            strides=strides,\n",
    "            kernel_initializer=kernel_initializer,\n",
    "            padding=padding,\n",
    "            kernel_regularizer=kernel_regularizer,\n",
    "        )(input)\n",
    "        return _bn_relu(conv)\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bn_relu_conv3d(**conv_params):\n",
    "    filters = conv_params[\"filters\"]\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1, 1))\n",
    "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1e-4))\n",
    "\n",
    "    def f(input):\n",
    "        activation = _bn_relu(input)\n",
    "        return Conv3D(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            strides=strides,\n",
    "            kernel_initializer=kernel_initializer,\n",
    "            padding=padding,\n",
    "            kernel_regularizer=kernel_regularizer,\n",
    "        )(activation)\n",
    "\n",
    "    return f\n",
    "\n",
    "def _shortcut3d(input, residual):\n",
    "    stride_dim1 = ceil(input.shape[DIM1_AXIS] / residual.shape[DIM1_AXIS])\n",
    "    stride_dim2 = ceil(input.shape[DIM2_AXIS] / residual.shape[DIM2_AXIS])\n",
    "    stride_dim3 = ceil(input.shape[DIM3_AXIS] / residual.shape[DIM3_AXIS])\n",
    "    equal_channels = residual.shape[CHANNEL_AXIS] == input.shape[CHANNEL_AXIS]\n",
    "\n",
    "    shortcut = input\n",
    "    if stride_dim1 > 1 or stride_dim2 > 1 or stride_dim3 > 1 or not equal_channels:\n",
    "        shortcut = Conv3D(\n",
    "            filters=residual.shape[CHANNEL_AXIS],\n",
    "            kernel_size=(1, 1, 1),\n",
    "            strides=(stride_dim1, stride_dim2, stride_dim3),\n",
    "            kernel_initializer=\"he_normal\",\n",
    "            padding=\"valid\",\n",
    "            kernel_regularizer=l2(1e-4),\n",
    "        )(input)\n",
    "    return add([shortcut, residual])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _conv_bn_relu3D(**conv_params):\n",
    "    filters = conv_params[\"filters\"]\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1, 1))\n",
    "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1e-4))\n",
    "\n",
    "    def f(input):\n",
    "        conv = Conv3D(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            strides=strides,\n",
    "            kernel_initializer=kernel_initializer,\n",
    "            padding=padding,\n",
    "            kernel_regularizer=kernel_regularizer,\n",
    "        )(input)\n",
    "        return _bn_relu(conv)\n",
    "\n",
    "    return f\n",
    "\n",
    "def _bn_relu_conv3d(**conv_params):\n",
    "    filters = conv_params[\"filters\"]\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1, 1))\n",
    "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1e-4))\n",
    "\n",
    "    def f(input):\n",
    "        activation = _bn_relu(input)\n",
    "        return Conv3D(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            strides=strides,\n",
    "            kernel_initializer=kernel_initializer,\n",
    "            padding=padding,\n",
    "            kernel_regularizer=kernel_regularizer,\n",
    "        )(activation)\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _shortcut3d(input, residual):\n",
    "    stride_dim1 = ceil(input.shape[DIM1_AXIS] / residual.shape[DIM1_AXIS])\n",
    "    stride_dim2 = ceil(input.shape[DIM2_AXIS] / residual.shape[DIM2_AXIS])\n",
    "    stride_dim3 = ceil(input.shape[DIM3_AXIS] / residual.shape[DIM3_AXIS])\n",
    "    equal_channels = residual.shape[CHANNEL_AXIS] == input.shape[CHANNEL_AXIS]\n",
    "\n",
    "    shortcut = input\n",
    "    if stride_dim1 > 1 or stride_dim2 > 1 or stride_dim3 > 1 or not equal_channels:\n",
    "        shortcut = Conv3D(\n",
    "            filters=residual.shape[CHANNEL_AXIS],\n",
    "            kernel_size=(1, 1, 1),\n",
    "            strides=(stride_dim1, stride_dim2, stride_dim3),\n",
    "            kernel_initializer=\"he_normal\",\n",
    "            padding=\"valid\",\n",
    "            kernel_regularizer=l2(1e-4),\n",
    "        )(input)\n",
    "    return add([shortcut, residual])\n",
    "\n",
    "def _residual_block_with_cbam(\n",
    "    filters,\n",
    "    kernel_regularizer,\n",
    "    is_first_layer=False,\n",
    "):\n",
    "    def f(input):\n",
    "        strides = (2, 2, 2) if not is_first_layer else (1, 1, 1)\n",
    "        conv1 = _conv_bn_relu3D(\n",
    "            filters=filters,\n",
    "            kernel_size=(5, 5, 5),  # Changed kernel size\n",
    "            strides=strides,\n",
    "            kernel_regularizer=kernel_regularizer,\n",
    "        )(input)\n",
    "        \n",
    "        conv2 = _conv_bn_relu3D(\n",
    "            filters=filters,\n",
    "            kernel_size=(5, 5, 5),  # Changed kernel size\n",
    "            kernel_regularizer=kernel_regularizer,\n",
    "        )(conv1)\n",
    "\n",
    "        # CBAM module\n",
    "        channel_avg_pool = GlobalAveragePooling3D()(conv2)\n",
    "        channel_max_pool = GlobalMaxPooling3D()(conv2)\n",
    "        channel_attention = add([Dense(filters // 2, activation='relu')(channel_avg_pool),\n",
    "                                 Dense(filters // 2, activation='relu')(channel_max_pool)])\n",
    "        channel_attention = Activation('sigmoid')(Dense(filters, activation='relu')(channel_attention))\n",
    "        channel_attention = Reshape((1, 1, 1, filters))(channel_attention)\n",
    "        channel_attention = multiply([conv2, channel_attention])\n",
    "\n",
    "        spatial_attention = Conv3D(1, (1, 1, 1), activation='sigmoid', padding='same', kernel_initializer='he_normal')(conv2)\n",
    "        attention = multiply([conv2, spatial_attention])\n",
    "\n",
    "        conv2 = add([channel_attention, attention])\n",
    "        \n",
    "        return _shortcut3d(input, conv2)\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_block(\n",
    "    filters,\n",
    "    strides=(1, 1, 1),\n",
    "    kernel_regularizer=l2(1e-4),\n",
    "    is_first_block_of_first_layer=False,\n",
    "):\n",
    "    def f(input):\n",
    "        if is_first_block_of_first_layer:\n",
    "            conv1 = Conv3D(\n",
    "                filters=filters,\n",
    "                kernel_size=(5, 5, 5),  # Changed kernel size\n",
    "                strides=strides,\n",
    "                padding=\"same\",\n",
    "                kernel_initializer=\"he_normal\",\n",
    "                kernel_regularizer=kernel_regularizer,\n",
    "            )(input)\n",
    "        else:\n",
    "            conv1 = _bn_relu_conv3d(\n",
    "                filters=filters,\n",
    "                kernel_size=(5, 5, 5),  # Changed kernel size\n",
    "                strides=strides,\n",
    "                kernel_regularizer=kernel_regularizer,\n",
    "            )(input)\n",
    "\n",
    "        residual = _bn_relu_conv3d(\n",
    "            filters=filters,\n",
    "            kernel_size=(5, 5, 5),  # Changed kernel size\n",
    "            kernel_regularizer=kernel_regularizer,\n",
    "        )(conv1)\n",
    "        return _shortcut3d(input, residual)\n",
    "\n",
    "    return f\n",
    "\n",
    "def _handle_data_format():\n",
    "    global DIM1_AXIS\n",
    "    global DIM2_AXIS\n",
    "    global DIM3_AXIS\n",
    "    global CHANNEL_AXIS\n",
    "    if K.image_data_format() == \"channels_last\":\n",
    "        DIM1_AXIS = 1\n",
    "        DIM2_AXIS = 2\n",
    "        DIM3_AXIS = 3\n",
    "        CHANNEL_AXIS = 4\n",
    "    else:\n",
    "        CHANNEL_AXIS = 1\n",
    "        DIM1_AXIS = 2\n",
    "        DIM2_AXIS = 3\n",
    "        DIM3_AXIS = 4\n",
    "\n",
    "def _get_block(identifier):\n",
    "    if isinstance(identifier, six.string_types):\n",
    "        res = globals().get(identifier)\n",
    "        if not res:\n",
    "            raise ValueError(\"Invalid {}\".format(identifier))\n",
    "        return res\n",
    "    return identifier\n",
    "\n",
    "class Resnet3DBuilder(object):\n",
    "    \"\"\"ResNet3D.\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def build(input_shape, num_outputs, block_fn, repetitions, reg_factor):\n",
    "        \"\"\"Instantiate a vanilla ResNet3D keras model.\n",
    "\n",
    "        # Arguments\n",
    "            input_shape: Tuple of input shape in the format\n",
    "            (conv_dim1, conv_dim2, conv_dim3, channels) if dim_ordering='tf'\n",
    "            (filter, conv_dim1, conv_dim2, conv_dim3) if dim_ordering='th'\n",
    "            num_outputs: The number of outputs at the final softmax layer\n",
    "            block_fn: Unit block to use {'basic_block', 'bottlenack_block'}\n",
    "            repetitions: Repetitions of unit blocks\n",
    "        # Returns\n",
    "            model: a 3D ResNet model that takes a 5D tensor (volumetric images\n",
    "            in batch) as input and returns a 1D vector (prediction) as output.\n",
    "        \"\"\"\n",
    "        _handle_data_format()\n",
    "        if len(input_shape) != 4:\n",
    "            raise ValueError(\n",
    "                \"Input shape should be a tuple \"\n",
    "                \"(conv_dim1, conv_dim2, conv_dim3, channels) \"\n",
    "                \"for tensorflow as backend or \"\n",
    "                \"(channels, conv_dim1, conv_dim2, conv_dim3) \"\n",
    "                \"for theano as backend\"\n",
    "            )\n",
    "\n",
    "        block_fn = _get_block(block_fn)\n",
    "        input = Input(shape=input_shape)\n",
    "        # first conv\n",
    "        conv1 = _conv_bn_relu3D(\n",
    "            filters=128,  # Changed filter size\n",
    "            kernel_size=(5, 5, 5),  # Changed kernel size\n",
    "            strides=(2, 2, 2),\n",
    "            kernel_regularizer=l2(reg_factor),\n",
    "        )(input)\n",
    "        pool1 = MaxPooling3D(pool_size=(3, 3, 3), strides=(2, 2, 2), padding=\"same\")(\n",
    "            conv1\n",
    "        )\n",
    "\n",
    "        # repeat blocks\n",
    "        block = pool1\n",
    "        filters = 128  # Changed filter size\n",
    "        for i, r in enumerate(repetitions):\n",
    "            block = _residual_block_with_cbam(\n",
    "                filters=filters,\n",
    "                kernel_regularizer=l2(reg_factor),\n",
    "                is_first_layer=(i == 0),\n",
    "            )(block)\n",
    "            filters *= 2\n",
    "\n",
    "        # last activation\n",
    "        block_output = _bn_relu(block)\n",
    "\n",
    "        # average pool and classification\n",
    "        pool2 = AveragePooling3D(\n",
    "            pool_size=(\n",
    "                block.shape[DIM1_AXIS],\n",
    "                block.shape[DIM2_AXIS],\n",
    "                block.shape[DIM3_AXIS],\n",
    "            ),\n",
    "            strides=(1, 1, 1),\n",
    "        )(block_output)\n",
    "        flatten1 = Flatten()(pool2)\n",
    "        if num_outputs > 1:\n",
    "            dense = Dense(\n",
    "                units=num_outputs,\n",
    "                kernel_initializer=\"he_normal\",\n",
    "                activation=\"softmax\",\n",
    "                kernel_regularizer=l2(reg_factor),\n",
    "            )(flatten1)\n",
    "        else:\n",
    "            dense = Dense(\n",
    "                units=num_outputs,\n",
    "                kernel_initializer=\"he_normal\",\n",
    "                activation=\"sigmoid\",\n",
    "                kernel_regularizer=l2(reg_factor),\n",
    "            )(flatten1)\n",
    "\n",
    "        model = Model(inputs=input, outputs=dense)\n",
    "        return model\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_18(input_shape, num_outputs, reg_factor=1e-4):\n",
    "        \"\"\"Build resnet 18.\"\"\"\n",
    "        return Resnet3DBuilder.build(\n",
    "            input_shape, num_outputs, basic_block, [2, 2, 2, 2], reg_factor=reg_factor\n",
    "        )\n",
    "    @staticmethod\n",
    "    def build_resnet_34(input_shape, num_outputs, reg_factor=1e-4):\n",
    "        \"\"\"Build resnet 34.\"\"\"\n",
    "        return Resnet3DBuilder.build(\n",
    "            input_shape, num_outputs, basic_block, [3, 4, 6, 3], reg_factor=reg_factor\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_50(input_shape, num_outputs, reg_factor=1e-4):\n",
    "        \"\"\"Build resnet 50.\"\"\"\n",
    "        return Resnet3DBuilder.build(\n",
    "            input_shape, num_outputs, basic_block, [3, 4, 6, 3], reg_factor=reg_factor\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_101(input_shape, num_outputs, reg_factor=1e-4):\n",
    "        \"\"\"Build resnet 101.\"\"\"\n",
    "        return Resnet3DBuilder.build(\n",
    "            input_shape, num_outputs, basic_block, [3, 4, 23, 3], reg_factor=reg_factor\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_152(input_shape, num_outputs, reg_factor=1e-4):\n",
    "        \"\"\"Build resnet 152.\"\"\"\n",
    "        return Resnet3DBuilder.build(\n",
    "            input_shape, num_outputs, basic_block, [3, 8, 36, 6], reg_factor=reg_factor\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the model\n",
    "def apply_mask(aseg_image, brain_image, labels = [17, 53, 2, 7, 41, 46]):\n",
    "    brain_data = aseg_image.get_fdata()\n",
    "    aseg_data = aseg_image.get_fdata()\n",
    "    origin_data = brain_image.get_fdata()\n",
    "    \n",
    "    brain_mask = np.zeros_like(aseg_data)\n",
    "    for label in labels:\n",
    "        brain_mask += np.where((aseg_data == label), 1, 0)\n",
    "\n",
    "    new_image = origin_data * brain_mask\n",
    "    \n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_slice(slice_data):\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    enhanced_slice = clahe.apply(slice_data.astype(np.uint8))\n",
    "\n",
    "    return enhanced_slice\n",
    "\n",
    "def enhance_image(img_data):\n",
    "    enhanced_image = np.zeros_like(img_data)\n",
    "    for i in range(img_data.shape[2]):\n",
    "        enhanced_image[:, :, i] = enhance_slice(img_data[:, :, i])\n",
    "    return enhanced_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpen_image(image, strength=1.0):\n",
    "    sharpened_image = unsharp_mask(image, radius=1, amount=strength)\n",
    "    return sharpened_image\n",
    "\n",
    "def apply_nonlinear_registration(moving_image, fixed_image):\n",
    "    metric = CCMetric(3)\n",
    "\n",
    "    sdr = SymmetricDiffeomorphicRegistration(metric, [10, 10, 10], step_length=0.25, ss_sigma_factor=1.5)\n",
    "\n",
    "    mapping = sdr.optimize(fixed_image, moving_image)\n",
    "\n",
    "    warped_moving_image = mapping.transform(moving_image)\n",
    "\n",
    "    return warped_moving_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_fixed(image_type, target_shape):\n",
    "    aseg_image = nibabel.load('/home/uiu/Project/adni-1-5t-filtered-preprocessed-quickseg-dataset/AD/I65597.nii')\n",
    "    base_path = \"/home/uiu/Project/adni-1-5t-filtered-preprocessed-quickseg-dataset/AD/I65597.nii/mri/orig.mgz\"\n",
    "    origin_image =  nibabel.load(base_path)\n",
    "    \n",
    "    if (image_type == 'roi') :\n",
    "        image = apply_mask(aseg_image, origin_image)\n",
    "        image = resize(image, target_shape, anti_aliasing=True)\n",
    "        image = sharpen_image(image)\n",
    "        return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import rotate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(image, rotation_range):\n",
    "    rotation_angle = np.random.uniform(-rotation_range, rotation_range)\n",
    "    rotated_image = rotate(image, rotation_angle, reshape=False)\n",
    "    \n",
    "    return rotated_image\n",
    "\n",
    "\n",
    "\n",
    "def image_loader_roi(image_path, target_shape, type_dt=''):\n",
    "    aseg_image = nibabel.load(image_path)\n",
    "    base_path = \"/\".join(image_path.split('/')[:-1]) + \"/orig.mgz\"\n",
    "    base_image =  nibabel.load(base_path)\n",
    "    \n",
    "    image = apply_mask(aseg_image, base_image)\n",
    "    image = resize(image, target_shape, anti_aliasing=True)\n",
    "    image = enhance_image(image)\n",
    "    image = sharpen_image(image)\n",
    "    \n",
    "    if type_dt=='train':\n",
    "        image = augment(image, 50)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117, 465, array([2.25728155, 0.64226519]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def data_generator(paths, labels, batch_size, target_shape, image_type, type_dt=''):\n",
    "    while True:\n",
    "        for i in range(0, len(paths), batch_size):\n",
    "            batch_paths = paths[i:i+batch_size]\n",
    "            batch_labels = labels[i:i+batch_size]\n",
    "            batch_images = []\n",
    "            \n",
    "    \n",
    "            if image_type == 'roi':\n",
    "                batch_images = [image_loader_roi(image, target_shape, type_dt) for image in batch_paths]\n",
    "\n",
    "\n",
    "            batch_images = np.stack([batch_images] * 1, axis=-1)\n",
    "\n",
    "            batch_labels = to_categorical(batch_labels, num_classes=2)\n",
    "            yield np.array(batch_images), batch_labels\n",
    "base_dir = '/home/uiu/Project/adni-1-5t-filtered-preprocessed-quickseg-dataset'\n",
    "ad = os.path.join(base_dir, 'AD')\n",
    "mci = os.path.join(base_dir, 'MCI')\n",
    "cn = os.path.join(base_dir, 'CN')\n",
    "# original shape (257, 257, 257)\n",
    "\n",
    "ad_images= []\n",
    "mci_images = []\n",
    "cn_images = []\n",
    "\n",
    "for subject_dir in os.listdir(ad):\n",
    "    mri_path = os.path.join(ad, subject_dir, 'mri', 'aparc.DKTatlas+aseg.deep.mgz')\n",
    "    if not (len(os.listdir(os.path.join(ad, subject_dir, 'mri'))) < 6):\n",
    "        ad_images.append(mri_path)\n",
    "        \n",
    "for subject_dir in os.listdir(mci):\n",
    "    mri_path = os.path.join(mci, subject_dir, 'mri', 'aparc.DKTatlas+aseg.deep.mgz')\n",
    "    \n",
    "    if not (len(os.listdir(os.path.join(mci, subject_dir, 'mri'))) < 6):\n",
    "        mci_images.append(mri_path)\n",
    "        \n",
    "for subject_dir in os.listdir(cn):\n",
    "    mri_path = os.path.join(cn, subject_dir, 'mri', 'aparc.DKTatlas+aseg.deep.mgz')\n",
    "    if not (len(os.listdir(os.path.join(cn, subject_dir, 'mri'))) < 6):\n",
    "        cn_images.append(mri_path)\n",
    "\n",
    "\n",
    "image_path = ad_images + mci_images + mci_images[:len(ad_images)-len(mci_images)]\n",
    "labels = [0] * len(ad_images) + [1] * len(mci_images) + [1] * len(mci_images[:len(ad_images)-len(mci_images)])\n",
    "train_paths, test_paths, train_labels, test_labels = train_test_split(image_path, labels, test_size = 0.2, random_state=42)\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)\n",
    "train_paths = np.array(train_paths)\n",
    "train_labels = np.array(train_labels)\n",
    "test_paths = np.array(test_paths)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "train_paths, train_labels = shuffle(train_paths, train_labels, random_state=42)\n",
    "test_paths, test_labels = shuffle(test_paths, test_labels, random_state=42)\n",
    "\n",
    "target_shape = (100, 100, 100)\n",
    "batch_size = 10\n",
    "selection_type = 'roi'\n",
    "train_dataset = data_generator(train_paths, train_labels, batch_size, target_shape, \n",
    "                               image_type=selection_type, \n",
    "                               type_dt='train'\n",
    "                              )\n",
    "\n",
    "test_dataset = data_generator(test_paths, test_labels, batch_size, target_shape, \n",
    "                              image_type=selection_type\n",
    "                             )\n",
    "len(test_paths), len(train_labels), class_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 100, 100, 10 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d (Conv3D)                 (None, 50, 50, 50, 1 16128       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 50, 50, 50, 1 512         conv3d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 50, 50, 50, 1 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D)    (None, 25, 25, 25, 1 0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_1 (Conv3D)               (None, 25, 25, 25, 1 2048128     max_pooling3d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 25, 25, 25, 1 512         conv3d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 25, 25, 25, 1 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_2 (Conv3D)               (None, 25, 25, 25, 1 2048128     activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 25, 25, 25, 1 512         conv3d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 25, 25, 25, 1 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling3d (Globa (None, 128)          0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling3d (GlobalMax (None, 128)          0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 64)           8256        global_average_pooling3d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           8256        global_max_pooling3d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 64)           0           dense[0][0]                      \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          8320        add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 128)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 1, 1, 1, 128) 0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_3 (Conv3D)               (None, 25, 25, 25, 1 129         activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 25, 25, 25, 1 0           activation_2[0][0]               \n",
      "                                                                 reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 25, 25, 25, 1 0           activation_2[0][0]               \n",
      "                                                                 conv3d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 25, 25, 25, 1 0           multiply[0][0]                   \n",
      "                                                                 multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 25, 25, 25, 1 0           max_pooling3d[0][0]              \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_4 (Conv3D)               (None, 13, 13, 13, 2 4096256     add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 13, 13, 13, 2 1024        conv3d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 13, 13, 13, 2 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_5 (Conv3D)               (None, 13, 13, 13, 2 8192256     activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 13, 13, 13, 2 1024        conv3d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 13, 13, 13, 2 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling3d_1 (Glo (None, 256)          0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling3d_1 (GlobalM (None, 256)          0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128)          32896       global_average_pooling3d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128)          32896       global_max_pooling3d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 128)          0           dense_3[0][0]                    \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 256)          33024       add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 256)          0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 1, 1, 256) 0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_6 (Conv3D)               (None, 13, 13, 13, 1 257         activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 13, 13, 13, 2 0           activation_5[0][0]               \n",
      "                                                                 reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 13, 13, 13, 2 0           activation_5[0][0]               \n",
      "                                                                 conv3d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_7 (Conv3D)               (None, 13, 13, 13, 2 33024       add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 13, 13, 13, 2 0           multiply_2[0][0]                 \n",
      "                                                                 multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 13, 13, 13, 2 0           conv3d_7[0][0]                   \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_8 (Conv3D)               (None, 7, 7, 7, 512) 16384512    add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 7, 7, 7, 512) 2048        conv3d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 7, 7, 7, 512) 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_9 (Conv3D)               (None, 7, 7, 7, 512) 32768512    activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 7, 7, 7, 512) 2048        conv3d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 7, 7, 7, 512) 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling3d_2 (Glo (None, 512)          0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling3d_2 (GlobalM (None, 512)          0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 256)          131328      global_average_pooling3d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 256)          131328      global_max_pooling3d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 256)          0           dense_6[0][0]                    \n",
      "                                                                 dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 512)          131584      add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 512)          0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 1, 1, 1, 512) 0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_10 (Conv3D)              (None, 7, 7, 7, 1)   513         activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 7, 7, 7, 512) 0           activation_8[0][0]               \n",
      "                                                                 reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_5 (Multiply)           (None, 7, 7, 7, 512) 0           activation_8[0][0]               \n",
      "                                                                 conv3d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_11 (Conv3D)              (None, 7, 7, 7, 512) 131584      add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 7, 7, 7, 512) 0           multiply_4[0][0]                 \n",
      "                                                                 multiply_5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 7, 7, 7, 512) 0           conv3d_11[0][0]                  \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_12 (Conv3D)              (None, 4, 4, 4, 1024 65537024    add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 4, 4, 4, 1024 4096        conv3d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 4, 4, 4, 1024 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_13 (Conv3D)              (None, 4, 4, 4, 1024 131073024   activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 4, 4, 4, 1024 4096        conv3d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 4, 4, 4, 1024 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling3d_3 (Glo (None, 1024)         0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling3d_3 (GlobalM (None, 1024)         0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 512)          524800      global_average_pooling3d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 512)          524800      global_max_pooling3d_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 512)          0           dense_9[0][0]                    \n",
      "                                                                 dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 1024)         525312      add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 1024)         0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 1, 1, 1, 1024 0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_14 (Conv3D)              (None, 4, 4, 4, 1)   1025        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_6 (Multiply)           (None, 4, 4, 4, 1024 0           activation_11[0][0]              \n",
      "                                                                 reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_7 (Multiply)           (None, 4, 4, 4, 1024 0           activation_11[0][0]              \n",
      "                                                                 conv3d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_15 (Conv3D)              (None, 4, 4, 4, 1024 525312      add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 4, 4, 4, 1024 0           multiply_6[0][0]                 \n",
      "                                                                 multiply_7[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 4, 4, 4, 1024 0           conv3d_15[0][0]                  \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 4, 4, 4, 1024 4096        add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 4, 4, 4, 1024 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling3d (AveragePooli (None, 1, 1, 1, 1024 0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1024)         0           average_pooling3d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 2)            2050        flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 264,970,630\n",
      "Trainable params: 264,960,646\n",
      "Non-trainable params: 9,984\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classes = 2\n",
    "image_shape = (*target_shape, 1)\n",
    "model = Resnet3DBuilder.build_resnet_152(input_shape = image_shape, num_outputs=classes)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(0.00001), \n",
    "    loss='binary_crossentropy', \n",
    "    metrics=['accuracy', 'Recall', 'AUC', 'Precision'] \n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "46/46 [==============================] - 597s 13s/step - loss: 1.7630 - accuracy: 0.6802 - recall: 0.6802 - auc: 0.7050 - precision: 0.6802 - val_loss: 1.7524 - val_accuracy: 0.7455 - val_recall: 0.7455 - val_auc: 0.7447 - val_precision: 0.7455\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 571s 13s/step - loss: 1.6461 - accuracy: 0.8019 - recall: 0.8019 - auc: 0.8121 - precision: 0.8019 - val_loss: 1.7051 - val_accuracy: 0.7455 - val_recall: 0.7455 - val_auc: 0.7726 - val_precision: 0.7455\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 568s 13s/step - loss: 1.6517 - accuracy: 0.7877 - recall: 0.7877 - auc: 0.8111 - precision: 0.7877 - val_loss: 1.6911 - val_accuracy: 0.7455 - val_recall: 0.7455 - val_auc: 0.7854 - val_precision: 0.7455\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 569s 13s/step - loss: 1.6458 - accuracy: 0.7793 - recall: 0.7793 - auc: 0.8231 - precision: 0.7793 - val_loss: 1.6913 - val_accuracy: 0.7455 - val_recall: 0.7455 - val_auc: 0.7938 - val_precision: 0.7455\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 569s 13s/step - loss: 1.6288 - accuracy: 0.7923 - recall: 0.7923 - auc: 0.8320 - precision: 0.7923 - val_loss: 1.6883 - val_accuracy: 0.7545 - val_recall: 0.7545 - val_auc: 0.8016 - val_precision: 0.7545\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 576s 13s/step - loss: 1.6278 - accuracy: 0.7726 - recall: 0.7726 - auc: 0.8411 - precision: 0.7726 - val_loss: 1.6749 - val_accuracy: 0.7455 - val_recall: 0.7455 - val_auc: 0.7966 - val_precision: 0.7455\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 572s 13s/step - loss: 1.6025 - accuracy: 0.7867 - recall: 0.7867 - auc: 0.8457 - precision: 0.7867 - val_loss: 1.6903 - val_accuracy: 0.7818 - val_recall: 0.7818 - val_auc: 0.7879 - val_precision: 0.7818\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 574s 13s/step - loss: 1.6084 - accuracy: 0.7796 - recall: 0.7796 - auc: 0.8413 - precision: 0.7796 - val_loss: 1.6529 - val_accuracy: 0.7455 - val_recall: 0.7455 - val_auc: 0.7982 - val_precision: 0.7455\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 573s 13s/step - loss: 1.5962 - accuracy: 0.7824 - recall: 0.7824 - auc: 0.8376 - precision: 0.7824 - val_loss: 1.6368 - val_accuracy: 0.7455 - val_recall: 0.7455 - val_auc: 0.8071 - val_precision: 0.7455\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 576s 13s/step - loss: 1.5984 - accuracy: 0.7700 - recall: 0.7700 - auc: 0.8456 - precision: 0.7700 - val_loss: 1.6251 - val_accuracy: 0.7636 - val_recall: 0.7636 - val_auc: 0.8025 - val_precision: 0.7636\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 576s 13s/step - loss: 1.5676 - accuracy: 0.7858 - recall: 0.7858 - auc: 0.8586 - precision: 0.7858 - val_loss: 1.6475 - val_accuracy: 0.7455 - val_recall: 0.7455 - val_auc: 0.8022 - val_precision: 0.7455\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 572s 13s/step - loss: 1.5825 - accuracy: 0.7842 - recall: 0.7842 - auc: 0.8373 - precision: 0.7842 - val_loss: 1.6161 - val_accuracy: 0.7727 - val_recall: 0.7727 - val_auc: 0.8064 - val_precision: 0.7727\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 575s 13s/step - loss: 1.5509 - accuracy: 0.8038 - recall: 0.8038 - auc: 0.8531 - precision: 0.8038 - val_loss: 1.6200 - val_accuracy: 0.7636 - val_recall: 0.7636 - val_auc: 0.8039 - val_precision: 0.7636\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 576s 13s/step - loss: 1.5280 - accuracy: 0.7964 - recall: 0.7964 - auc: 0.8731 - precision: 0.7964 - val_loss: 1.6935 - val_accuracy: 0.7455 - val_recall: 0.7455 - val_auc: 0.7939 - val_precision: 0.7455\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 575s 13s/step - loss: 1.5103 - accuracy: 0.7899 - recall: 0.7899 - auc: 0.8845 - precision: 0.7899 - val_loss: 1.6802 - val_accuracy: 0.7455 - val_recall: 0.7455 - val_auc: 0.8058 - val_precision: 0.7455\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 568s 13s/step - loss: 1.5322 - accuracy: 0.8066 - recall: 0.8066 - auc: 0.8616 - precision: 0.8066 - val_loss: 2.0724 - val_accuracy: 0.7455 - val_recall: 0.7455 - val_auc: 0.7703 - val_precision: 0.7455\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 574s 13s/step - loss: 1.5297 - accuracy: 0.7901 - recall: 0.7901 - auc: 0.8608 - precision: 0.7901 - val_loss: 1.6625 - val_accuracy: 0.7455 - val_recall: 0.7455 - val_auc: 0.8135 - val_precision: 0.7455\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 569s 13s/step - loss: 1.5274 - accuracy: 0.7998 - recall: 0.7998 - auc: 0.8599 - precision: 0.7998 - val_loss: 2.0161 - val_accuracy: 0.7455 - val_recall: 0.7455 - val_auc: 0.7567 - val_precision: 0.7455\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 568s 13s/step - loss: 1.4924 - accuracy: 0.8109 - recall: 0.8109 - auc: 0.8807 - precision: 0.8109 - val_loss: 1.5957 - val_accuracy: 0.7727 - val_recall: 0.7727 - val_auc: 0.8180 - val_precision: 0.7727\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 574s 13s/step - loss: 1.4077 - accuracy: 0.8464 - recall: 0.8464 - auc: 0.9239 - precision: 0.8464 - val_loss: 2.0678 - val_accuracy: 0.7455 - val_recall: 0.7455 - val_auc: 0.7590 - val_precision: 0.7455\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 573s 13s/step - loss: 1.4086 - accuracy: 0.8516 - recall: 0.8516 - auc: 0.9197 - precision: 0.8516 - val_loss: 1.7518 - val_accuracy: 0.7545 - val_recall: 0.7545 - val_auc: 0.8189 - val_precision: 0.7545\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 575s 13s/step - loss: 1.3737 - accuracy: 0.8699 - recall: 0.8699 - auc: 0.9372 - precision: 0.8699 - val_loss: 2.5204 - val_accuracy: 0.7455 - val_recall: 0.7455 - val_auc: 0.7455 - val_precision: 0.7455\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 574s 13s/step - loss: 1.3424 - accuracy: 0.8768 - recall: 0.8768 - auc: 0.9498 - precision: 0.8768 - val_loss: 2.5855 - val_accuracy: 0.7455 - val_recall: 0.7455 - val_auc: 0.7455 - val_precision: 0.7455\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 575s 13s/step - loss: 1.3379 - accuracy: 0.8795 - recall: 0.8795 - auc: 0.9511 - precision: 0.8795 - val_loss: 1.8089 - val_accuracy: 0.7455 - val_recall: 0.7455 - val_auc: 0.8023 - val_precision: 0.7455\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 569s 13s/step - loss: 1.3116 - accuracy: 0.8862 - recall: 0.8862 - auc: 0.9557 - precision: 0.8862 - val_loss: 1.7145 - val_accuracy: 0.7909 - val_recall: 0.7909 - val_auc: 0.8089 - val_precision: 0.7909\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 576s 13s/step - loss: 1.3416 - accuracy: 0.8762 - recall: 0.8762 - auc: 0.9382 - precision: 0.8762 - val_loss: 2.5175 - val_accuracy: 0.7455 - val_recall: 0.7455 - val_auc: 0.7455 - val_precision: 0.7455\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 574s 13s/step - loss: 1.3601 - accuracy: 0.8636 - recall: 0.8636 - auc: 0.9308 - precision: 0.8636 - val_loss: 1.9797 - val_accuracy: 0.7636 - val_recall: 0.7636 - val_auc: 0.7818 - val_precision: 0.7636\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 572s 13s/step - loss: 1.3229 - accuracy: 0.8853 - recall: 0.8853 - auc: 0.9434 - precision: 0.8853 - val_loss: 1.5738 - val_accuracy: 0.8000 - val_recall: 0.8000 - val_auc: 0.8453 - val_precision: 0.8000\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 577s 13s/step - loss: 1.2980 - accuracy: 0.8816 - recall: 0.8816 - auc: 0.9566 - precision: 0.8816 - val_loss: 1.6186 - val_accuracy: 0.7727 - val_recall: 0.7727 - val_auc: 0.8593 - val_precision: 0.7727\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 574s 13s/step - loss: 1.2965 - accuracy: 0.8920 - recall: 0.8920 - auc: 0.9516 - precision: 0.8920 - val_loss: 1.6390 - val_accuracy: 0.6818 - val_recall: 0.6818 - val_auc: 0.7644 - val_precision: 0.6818\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 575s 13s/step - loss: 1.2557 - accuracy: 0.9024 - recall: 0.9024 - auc: 0.9676 - precision: 0.9024 - val_loss: 1.8522 - val_accuracy: 0.7636 - val_recall: 0.7636 - val_auc: 0.8163 - val_precision: 0.7636\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 574s 13s/step - loss: 1.2450 - accuracy: 0.9110 - recall: 0.9110 - auc: 0.9668 - precision: 0.9110 - val_loss: 1.5347 - val_accuracy: 0.8000 - val_recall: 0.8000 - val_auc: 0.8696 - val_precision: 0.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100\n",
      "46/46 [==============================] - 571s 13s/step - loss: 1.2156 - accuracy: 0.9395 - recall: 0.9395 - auc: 0.9716 - precision: 0.9395 - val_loss: 1.5576 - val_accuracy: 0.7727 - val_recall: 0.7727 - val_auc: 0.8521 - val_precision: 0.7727\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 571s 13s/step - loss: 1.2249 - accuracy: 0.9122 - recall: 0.9122 - auc: 0.9705 - precision: 0.9122 - val_loss: 1.7449 - val_accuracy: 0.8000 - val_recall: 0.8000 - val_auc: 0.8398 - val_precision: 0.8000\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 572s 13s/step - loss: 1.2479 - accuracy: 0.9098 - recall: 0.9098 - auc: 0.9652 - precision: 0.9098 - val_loss: 1.5792 - val_accuracy: 0.8000 - val_recall: 0.8000 - val_auc: 0.8647 - val_precision: 0.8000\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 571s 13s/step - loss: 1.1973 - accuracy: 0.9178 - recall: 0.9178 - auc: 0.9802 - precision: 0.9178 - val_loss: 2.0836 - val_accuracy: 0.7545 - val_recall: 0.7545 - val_auc: 0.7731 - val_precision: 0.7545\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 569s 13s/step - loss: 1.2136 - accuracy: 0.9089 - recall: 0.9089 - auc: 0.9684 - precision: 0.9089 - val_loss: 1.7535 - val_accuracy: 0.7909 - val_recall: 0.7909 - val_auc: 0.8313 - val_precision: 0.7909\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 570s 13s/step - loss: 1.1325 - accuracy: 0.9695 - recall: 0.9695 - auc: 0.9886 - precision: 0.9695 - val_loss: 1.6526 - val_accuracy: 0.7273 - val_recall: 0.7273 - val_auc: 0.8055 - val_precision: 0.7273\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 568s 13s/step - loss: 1.2022 - accuracy: 0.9158 - recall: 0.9158 - auc: 0.9759 - precision: 0.9158 - val_loss: 2.0632 - val_accuracy: 0.7636 - val_recall: 0.7636 - val_auc: 0.7891 - val_precision: 0.7636\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 569s 13s/step - loss: 1.1670 - accuracy: 0.9380 - recall: 0.9380 - auc: 0.9820 - precision: 0.9380 - val_loss: 1.5706 - val_accuracy: 0.8091 - val_recall: 0.8091 - val_auc: 0.8582 - val_precision: 0.8091\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 577s 13s/step - loss: 1.1451 - accuracy: 0.9414 - recall: 0.9414 - auc: 0.9873 - precision: 0.9414 - val_loss: 1.8091 - val_accuracy: 0.7636 - val_recall: 0.7636 - val_auc: 0.8281 - val_precision: 0.7636\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 576s 13s/step - loss: 1.1251 - accuracy: 0.9563 - recall: 0.9563 - auc: 0.9914 - precision: 0.9563 - val_loss: 2.0647 - val_accuracy: 0.7636 - val_recall: 0.7636 - val_auc: 0.8106 - val_precision: 0.7636\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 578s 13s/step - loss: 1.1389 - accuracy: 0.9340 - recall: 0.9340 - auc: 0.9875 - precision: 0.9340 - val_loss: 2.5938 - val_accuracy: 0.7455 - val_recall: 0.7455 - val_auc: 0.7522 - val_precision: 0.7455\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 577s 13s/step - loss: 1.1814 - accuracy: 0.9371 - recall: 0.9371 - auc: 0.9753 - precision: 0.9371 - val_loss: 1.4505 - val_accuracy: 0.7818 - val_recall: 0.7818 - val_auc: 0.8817 - val_precision: 0.7818\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 574s 13s/step - loss: 1.0954 - accuracy: 0.9683 - recall: 0.9683 - auc: 0.9937 - precision: 0.9683 - val_loss: 1.4821 - val_accuracy: 0.8091 - val_recall: 0.8091 - val_auc: 0.8693 - val_precision: 0.8091\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 578s 13s/step - loss: 1.0938 - accuracy: 0.9622 - recall: 0.9622 - auc: 0.9917 - precision: 0.9622 - val_loss: 1.7688 - val_accuracy: 0.8000 - val_recall: 0.8000 - val_auc: 0.8263 - val_precision: 0.8000\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 576s 13s/step - loss: 1.1046 - accuracy: 0.9582 - recall: 0.9582 - auc: 0.9914 - precision: 0.9582 - val_loss: 2.0701 - val_accuracy: 0.7727 - val_recall: 0.7727 - val_auc: 0.8131 - val_precision: 0.7727\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 578s 13s/step - loss: 1.0850 - accuracy: 0.9621 - recall: 0.9621 - auc: 0.9923 - precision: 0.9621 - val_loss: 2.2353 - val_accuracy: 0.5636 - val_recall: 0.5636 - val_auc: 0.5664 - val_precision: 0.5636\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 580s 13s/step - loss: 1.1072 - accuracy: 0.9560 - recall: 0.9560 - auc: 0.9838 - precision: 0.9560 - val_loss: 1.7296 - val_accuracy: 0.6909 - val_recall: 0.6909 - val_auc: 0.7326 - val_precision: 0.6909\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 571s 13s/step - loss: 1.1215 - accuracy: 0.9504 - recall: 0.9504 - auc: 0.9812 - precision: 0.9504 - val_loss: 1.8204 - val_accuracy: 0.6818 - val_recall: 0.6818 - val_auc: 0.6991 - val_precision: 0.6818\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 572s 13s/step - loss: 1.0636 - accuracy: 0.9806 - recall: 0.9806 - auc: 0.9949 - precision: 0.9806 - val_loss: 1.5541 - val_accuracy: 0.8091 - val_recall: 0.8091 - val_auc: 0.8548 - val_precision: 0.8091\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 574s 13s/step - loss: 1.0776 - accuracy: 0.9584 - recall: 0.9584 - auc: 0.9945 - precision: 0.9584 - val_loss: 1.5642 - val_accuracy: 0.7182 - val_recall: 0.7182 - val_auc: 0.8089 - val_precision: 0.7182\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 571s 13s/step - loss: 1.1267 - accuracy: 0.9362 - recall: 0.9362 - auc: 0.9792 - precision: 0.9362 - val_loss: 2.3713 - val_accuracy: 0.7455 - val_recall: 0.7455 - val_auc: 0.7658 - val_precision: 0.7455\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 577s 13s/step - loss: 1.0748 - accuracy: 0.9597 - recall: 0.9597 - auc: 0.9913 - precision: 0.9597 - val_loss: 1.5995 - val_accuracy: 0.8182 - val_recall: 0.8182 - val_auc: 0.8503 - val_precision: 0.8182\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 579s 13s/step - loss: 1.0540 - accuracy: 0.9700 - recall: 0.9700 - auc: 0.9952 - precision: 0.9700 - val_loss: 1.5024 - val_accuracy: 0.7727 - val_recall: 0.7727 - val_auc: 0.8564 - val_precision: 0.7727\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 575s 13s/step - loss: 1.0264 - accuracy: 0.9801 - recall: 0.9801 - auc: 0.9968 - precision: 0.9801 - val_loss: 1.5493 - val_accuracy: 0.7818 - val_recall: 0.7818 - val_auc: 0.8465 - val_precision: 0.7818\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 569s 13s/step - loss: 1.0971 - accuracy: 0.9450 - recall: 0.9450 - auc: 0.9852 - precision: 0.9450 - val_loss: 1.7971 - val_accuracy: 0.6364 - val_recall: 0.6364 - val_auc: 0.6870 - val_precision: 0.6364\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 566s 13s/step - loss: 1.0209 - accuracy: 0.9752 - recall: 0.9752 - auc: 0.9983 - precision: 0.9752 - val_loss: 1.5879 - val_accuracy: 0.8000 - val_recall: 0.8000 - val_auc: 0.8608 - val_precision: 0.8000\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 563s 12s/step - loss: 1.0613 - accuracy: 0.9602 - recall: 0.9602 - auc: 0.9883 - precision: 0.9602 - val_loss: 1.5363 - val_accuracy: 0.7909 - val_recall: 0.7909 - val_auc: 0.8645 - val_precision: 0.7909\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 564s 12s/step - loss: 1.0185 - accuracy: 0.9765 - recall: 0.9765 - auc: 0.9978 - precision: 0.9765 - val_loss: 1.5075 - val_accuracy: 0.8091 - val_recall: 0.8091 - val_auc: 0.8361 - val_precision: 0.8091\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 564s 13s/step - loss: 1.0389 - accuracy: 0.9640 - recall: 0.9640 - auc: 0.9944 - precision: 0.9640 - val_loss: 1.4309 - val_accuracy: 0.7909 - val_recall: 0.7909 - val_auc: 0.8964 - val_precision: 0.7909\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 566s 13s/step - loss: 1.0317 - accuracy: 0.9708 - recall: 0.9708 - auc: 0.9955 - precision: 0.9708 - val_loss: 1.6705 - val_accuracy: 0.8182 - val_recall: 0.8182 - val_auc: 0.8527 - val_precision: 0.8182\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 569s 13s/step - loss: 1.0310 - accuracy: 0.9650 - recall: 0.9650 - auc: 0.9964 - precision: 0.9650 - val_loss: 1.5259 - val_accuracy: 0.7909 - val_recall: 0.7909 - val_auc: 0.8650 - val_precision: 0.7909\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 575s 13s/step - loss: 1.0202 - accuracy: 0.9846 - recall: 0.9846 - auc: 0.9896 - precision: 0.9846 - val_loss: 1.4934 - val_accuracy: 0.8091 - val_recall: 0.8091 - val_auc: 0.8596 - val_precision: 0.8091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100\n",
      "46/46 [==============================] - 572s 13s/step - loss: 1.0142 - accuracy: 0.9769 - recall: 0.9769 - auc: 0.9953 - precision: 0.9769 - val_loss: 1.4481 - val_accuracy: 0.8182 - val_recall: 0.8182 - val_auc: 0.8738 - val_precision: 0.8182\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 570s 13s/step - loss: 1.0041 - accuracy: 0.9788 - recall: 0.9788 - auc: 0.9969 - precision: 0.9788 - val_loss: 1.3912 - val_accuracy: 0.8273 - val_recall: 0.8273 - val_auc: 0.8992 - val_precision: 0.8273\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 574s 13s/step - loss: 0.9991 - accuracy: 0.9780 - recall: 0.9780 - auc: 0.9953 - precision: 0.9780 - val_loss: 2.0316 - val_accuracy: 0.7818 - val_recall: 0.7818 - val_auc: 0.8022 - val_precision: 0.7818\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 569s 13s/step - loss: 1.0019 - accuracy: 0.9665 - recall: 0.9665 - auc: 0.9954 - precision: 0.9665 - val_loss: 1.7573 - val_accuracy: 0.8000 - val_recall: 0.8000 - val_auc: 0.8145 - val_precision: 0.8000\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 572s 13s/step - loss: 1.0112 - accuracy: 0.9627 - recall: 0.9627 - auc: 0.9945 - precision: 0.9627 - val_loss: 2.3625 - val_accuracy: 0.7545 - val_recall: 0.7545 - val_auc: 0.7957 - val_precision: 0.7545\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 568s 13s/step - loss: 1.0699 - accuracy: 0.9331 - recall: 0.9331 - auc: 0.9800 - precision: 0.9331 - val_loss: 1.8940 - val_accuracy: 0.8000 - val_recall: 0.8000 - val_auc: 0.8105 - val_precision: 0.8000\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 569s 13s/step - loss: 1.0255 - accuracy: 0.9691 - recall: 0.9691 - auc: 0.9872 - precision: 0.9691 - val_loss: 1.4711 - val_accuracy: 0.8273 - val_recall: 0.8273 - val_auc: 0.8860 - val_precision: 0.8273\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 569s 13s/step - loss: 1.0033 - accuracy: 0.9757 - recall: 0.9757 - auc: 0.9957 - precision: 0.9757 - val_loss: 1.3769 - val_accuracy: 0.8364 - val_recall: 0.8364 - val_auc: 0.8840 - val_precision: 0.8364\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 574s 13s/step - loss: 1.0298 - accuracy: 0.9548 - recall: 0.9548 - auc: 0.9914 - precision: 0.9548 - val_loss: 2.6324 - val_accuracy: 0.7545 - val_recall: 0.7545 - val_auc: 0.7862 - val_precision: 0.7545\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 574s 13s/step - loss: 1.0397 - accuracy: 0.9662 - recall: 0.9662 - auc: 0.9850 - precision: 0.9662 - val_loss: 1.4622 - val_accuracy: 0.8273 - val_recall: 0.8273 - val_auc: 0.8841 - val_precision: 0.8273\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 571s 13s/step - loss: 1.0066 - accuracy: 0.9600 - recall: 0.9600 - auc: 0.9942 - precision: 0.9600 - val_loss: 1.6010 - val_accuracy: 0.8091 - val_recall: 0.8091 - val_auc: 0.8542 - val_precision: 0.8091\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 568s 13s/step - loss: 0.9992 - accuracy: 0.9637 - recall: 0.9637 - auc: 0.9917 - precision: 0.9637 - val_loss: 1.7268 - val_accuracy: 0.8182 - val_recall: 0.8182 - val_auc: 0.8552 - val_precision: 0.8182\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 569s 13s/step - loss: 0.9829 - accuracy: 0.9741 - recall: 0.9741 - auc: 0.9922 - precision: 0.9741 - val_loss: 1.4973 - val_accuracy: 0.7909 - val_recall: 0.7909 - val_auc: 0.8265 - val_precision: 0.7909\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 570s 13s/step - loss: 0.9673 - accuracy: 0.9878 - recall: 0.9878 - auc: 0.9972 - precision: 0.9878 - val_loss: 1.3308 - val_accuracy: 0.8273 - val_recall: 0.8273 - val_auc: 0.8954 - val_precision: 0.8273\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 569s 13s/step - loss: 0.9972 - accuracy: 0.9689 - recall: 0.9689 - auc: 0.9898 - precision: 0.9689 - val_loss: 2.2555 - val_accuracy: 0.7909 - val_recall: 0.7909 - val_auc: 0.7954 - val_precision: 0.7909\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 570s 13s/step - loss: 0.9720 - accuracy: 0.9827 - recall: 0.9827 - auc: 0.9935 - precision: 0.9827 - val_loss: 1.6170 - val_accuracy: 0.8182 - val_recall: 0.8182 - val_auc: 0.8539 - val_precision: 0.8182\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 569s 13s/step - loss: 0.9519 - accuracy: 0.9800 - recall: 0.9800 - auc: 0.9988 - precision: 0.9800 - val_loss: 1.4228 - val_accuracy: 0.8364 - val_recall: 0.8364 - val_auc: 0.8903 - val_precision: 0.8364\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 570s 13s/step - loss: 0.9578 - accuracy: 0.9833 - recall: 0.9833 - auc: 0.9940 - precision: 0.9833 - val_loss: 1.8639 - val_accuracy: 0.7909 - val_recall: 0.7909 - val_auc: 0.8102 - val_precision: 0.7909\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 570s 13s/step - loss: 0.9591 - accuracy: 0.9853 - recall: 0.9853 - auc: 0.9961 - precision: 0.9853 - val_loss: 1.5049 - val_accuracy: 0.8545 - val_recall: 0.8545 - val_auc: 0.8637 - val_precision: 0.8545\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 568s 13s/step - loss: 0.9512 - accuracy: 0.9807 - recall: 0.9807 - auc: 0.9980 - precision: 0.9807 - val_loss: 2.0017 - val_accuracy: 0.7818 - val_recall: 0.7818 - val_auc: 0.7921 - val_precision: 0.7818\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 567s 13s/step - loss: 0.9485 - accuracy: 0.9770 - recall: 0.9770 - auc: 0.9985 - precision: 0.9770 - val_loss: 2.0074 - val_accuracy: 0.7818 - val_recall: 0.7818 - val_auc: 0.8061 - val_precision: 0.7818\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 569s 13s/step - loss: 0.9410 - accuracy: 0.9883 - recall: 0.9883 - auc: 0.9985 - precision: 0.9883 - val_loss: 1.8450 - val_accuracy: 0.7818 - val_recall: 0.7818 - val_auc: 0.8245 - val_precision: 0.7818\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 567s 13s/step - loss: 0.9588 - accuracy: 0.9618 - recall: 0.9618 - auc: 0.9973 - precision: 0.9618 - val_loss: 1.4907 - val_accuracy: 0.8364 - val_recall: 0.8364 - val_auc: 0.8873 - val_precision: 0.8364\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 572s 13s/step - loss: 0.9283 - accuracy: 0.9907 - recall: 0.9907 - auc: 0.9993 - precision: 0.9907 - val_loss: 1.4145 - val_accuracy: 0.8091 - val_recall: 0.8091 - val_auc: 0.8717 - val_precision: 0.8091\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 571s 13s/step - loss: 0.9682 - accuracy: 0.9729 - recall: 0.9729 - auc: 0.9920 - precision: 0.9729 - val_loss: 1.3461 - val_accuracy: 0.8000 - val_recall: 0.8000 - val_auc: 0.9051 - val_precision: 0.8000\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 568s 13s/step - loss: 0.9460 - accuracy: 0.9773 - recall: 0.9773 - auc: 0.9944 - precision: 0.9773 - val_loss: 1.2791 - val_accuracy: 0.8364 - val_recall: 0.8364 - val_auc: 0.9201 - val_precision: 0.8364\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 565s 13s/step - loss: 0.9356 - accuracy: 0.9828 - recall: 0.9828 - auc: 0.9980 - precision: 0.9828 - val_loss: 1.7213 - val_accuracy: 0.8364 - val_recall: 0.8364 - val_auc: 0.8600 - val_precision: 0.8364\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 565s 13s/step - loss: 0.9262 - accuracy: 0.9782 - recall: 0.9782 - auc: 0.9971 - precision: 0.9782 - val_loss: 1.9596 - val_accuracy: 0.7818 - val_recall: 0.7818 - val_auc: 0.8244 - val_precision: 0.7818\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 565s 13s/step - loss: 0.9218 - accuracy: 0.9835 - recall: 0.9835 - auc: 0.9976 - precision: 0.9835 - val_loss: 1.6078 - val_accuracy: 0.8364 - val_recall: 0.8364 - val_auc: 0.8511 - val_precision: 0.8364\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 565s 13s/step - loss: 0.9578 - accuracy: 0.9694 - recall: 0.9694 - auc: 0.9946 - precision: 0.9694 - val_loss: 1.5944 - val_accuracy: 0.7273 - val_recall: 0.7273 - val_auc: 0.7917 - val_precision: 0.7273\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 567s 13s/step - loss: 0.9069 - accuracy: 0.9887 - recall: 0.9887 - auc: 0.9970 - precision: 0.9887 - val_loss: 1.6795 - val_accuracy: 0.7091 - val_recall: 0.7091 - val_auc: 0.7722 - val_precision: 0.7091\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 568s 13s/step - loss: 0.9208 - accuracy: 0.9884 - recall: 0.9884 - auc: 0.9953 - precision: 0.9884 - val_loss: 1.3339 - val_accuracy: 0.8455 - val_recall: 0.8455 - val_auc: 0.8899 - val_precision: 0.8455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      "46/46 [==============================] - 562s 12s/step - loss: 0.9337 - accuracy: 0.9839 - recall: 0.9839 - auc: 0.9889 - precision: 0.9839 - val_loss: 1.4437 - val_accuracy: 0.8000 - val_recall: 0.8000 - val_auc: 0.8428 - val_precision: 0.8000\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 563s 12s/step - loss: 0.9463 - accuracy: 0.9730 - recall: 0.9730 - auc: 0.9823 - precision: 0.9730 - val_loss: 1.5080 - val_accuracy: 0.7455 - val_recall: 0.7455 - val_auc: 0.7979 - val_precision: 0.7455\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 561s 12s/step - loss: 0.9130 - accuracy: 0.9864 - recall: 0.9864 - auc: 0.9986 - precision: 0.9864 - val_loss: 1.6104 - val_accuracy: 0.8273 - val_recall: 0.8273 - val_auc: 0.8498 - val_precision: 0.8273\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 561s 12s/step - loss: 0.8923 - accuracy: 0.9958 - recall: 0.9958 - auc: 0.9999 - precision: 0.9958 - val_loss: 1.3698 - val_accuracy: 0.8182 - val_recall: 0.8182 - val_auc: 0.8755 - val_precision: 0.8182\n"
     ]
    }
   ],
   "source": [
    "# No\n",
    "model_checkpoint = ModelCheckpoint('UpgradedFilter_ROI_ADNI_ADvsMCI.h5', monitor='val_accuracy', mode='max', save_best_only=True)\n",
    "\n",
    "num_epoch = 100\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=num_epoch,\n",
    "    steps_per_epoch=len(train_paths) // batch_size,\n",
    "    validation_data=test_dataset,\n",
    "    validation_steps=len(test_paths) // batch_size,\n",
    "    callbacks=[model_checkpoint]  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 93s 9s/step - loss: 1.5049 - accuracy: 0.8545 - recall: 0.8545 - auc: 0.8637 - precision: 0.8545\n",
      "Test Accuracy: [1.5049301385879517, 0.8545454740524292, 0.8545454740524292, 0.8637189269065857, 0.8545454740524292]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "saved_model = tf.keras.models.load_model('UpgradedFilter_ROI_ADNI_ADvsMCI.h5')\n",
    "test_accuracy = saved_model.evaluate(\n",
    "    test_dataset,\n",
    "    steps=len(test_paths) // batch_size,\n",
    "    verbose=1\n",
    ")\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_27401/728640983.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'UpgradedFilter_ROI_IJK_100_Epoch_v2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('UpgradedFilter_ROI_IJK_100_Epoch_v2')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.savefig(\"UpgradedFilter_ROI_IJK_100_Epoch_v2.png\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('UpgradedFilter_ROI_ADNI_ADvsMCI.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "46/46 [==============================] - 588s 13s/step - loss: 0.9547 - accuracy: 0.9804 - recall: 0.9804 - auc: 0.9945 - precision: 0.9804 - val_loss: 1.3119 - val_accuracy: 0.8091 - val_recall: 0.8091 - val_auc: 0.9088 - val_precision: 0.8091\n",
      "Epoch 2/50\n",
      "46/46 [==============================] - 583s 13s/step - loss: 0.9789 - accuracy: 0.9626 - recall: 0.9626 - auc: 0.9923 - precision: 0.9626 - val_loss: 1.4895 - val_accuracy: 0.8091 - val_recall: 0.8091 - val_auc: 0.8807 - val_precision: 0.8091\n",
      "Epoch 3/50\n",
      "46/46 [==============================] - 573s 13s/step - loss: 0.9587 - accuracy: 0.9714 - recall: 0.9714 - auc: 0.9976 - precision: 0.9714 - val_loss: 1.3950 - val_accuracy: 0.8273 - val_recall: 0.8273 - val_auc: 0.8945 - val_precision: 0.8273\n",
      "Epoch 4/50\n",
      "46/46 [==============================] - 576s 13s/step - loss: 0.9308 - accuracy: 0.9868 - recall: 0.9868 - auc: 0.9995 - precision: 0.9868 - val_loss: 1.4487 - val_accuracy: 0.8182 - val_recall: 0.8182 - val_auc: 0.8507 - val_precision: 0.8182\n",
      "Epoch 5/50\n",
      "46/46 [==============================] - 574s 13s/step - loss: 0.9291 - accuracy: 0.9868 - recall: 0.9868 - auc: 0.9992 - precision: 0.9868 - val_loss: 1.5314 - val_accuracy: 0.7818 - val_recall: 0.7818 - val_auc: 0.8314 - val_precision: 0.7818\n",
      "Epoch 6/50\n",
      "46/46 [==============================] - 571s 13s/step - loss: 0.9228 - accuracy: 0.9890 - recall: 0.9890 - auc: 0.9974 - precision: 0.9890 - val_loss: 2.2042 - val_accuracy: 0.6182 - val_recall: 0.6182 - val_auc: 0.6202 - val_precision: 0.6182\n",
      "Epoch 7/50\n",
      "46/46 [==============================] - 573s 13s/step - loss: 0.9259 - accuracy: 0.9846 - recall: 0.9846 - auc: 0.9990 - precision: 0.9846 - val_loss: 1.4478 - val_accuracy: 0.8000 - val_recall: 0.8000 - val_auc: 0.8282 - val_precision: 0.8000\n",
      "Epoch 8/50\n",
      "46/46 [==============================] - 569s 13s/step - loss: 0.9570 - accuracy: 0.9692 - recall: 0.9692 - auc: 0.9951 - precision: 0.9692 - val_loss: 2.0656 - val_accuracy: 0.7727 - val_recall: 0.7727 - val_auc: 0.8086 - val_precision: 0.7727\n",
      "Epoch 9/50\n",
      "46/46 [==============================] - 575s 13s/step - loss: 0.9216 - accuracy: 0.9846 - recall: 0.9846 - auc: 0.9993 - precision: 0.9846 - val_loss: 1.3681 - val_accuracy: 0.8182 - val_recall: 0.8182 - val_auc: 0.8802 - val_precision: 0.8182\n",
      "Epoch 10/50\n",
      "46/46 [==============================] - 572s 13s/step - loss: 0.9186 - accuracy: 0.9846 - recall: 0.9846 - auc: 0.9990 - precision: 0.9846 - val_loss: 1.5045 - val_accuracy: 0.7545 - val_recall: 0.7545 - val_auc: 0.8207 - val_precision: 0.7545\n",
      "Epoch 11/50\n",
      "46/46 [==============================] - 573s 13s/step - loss: 0.9073 - accuracy: 0.9912 - recall: 0.9912 - auc: 0.9996 - precision: 0.9912 - val_loss: 1.2356 - val_accuracy: 0.8818 - val_recall: 0.8818 - val_auc: 0.9112 - val_precision: 0.8818\n",
      "Epoch 12/50\n",
      "46/46 [==============================] - 577s 13s/step - loss: 0.9119 - accuracy: 0.9868 - recall: 0.9868 - auc: 0.9971 - precision: 0.9868 - val_loss: 1.3148 - val_accuracy: 0.8636 - val_recall: 0.8636 - val_auc: 0.9116 - val_precision: 0.8636\n",
      "Epoch 13/50\n",
      "46/46 [==============================] - 580s 13s/step - loss: 0.9292 - accuracy: 0.9758 - recall: 0.9758 - auc: 0.9980 - precision: 0.9758 - val_loss: 1.3783 - val_accuracy: 0.8636 - val_recall: 0.8636 - val_auc: 0.8876 - val_precision: 0.8636\n",
      "Epoch 14/50\n",
      "46/46 [==============================] - 577s 13s/step - loss: 0.9051 - accuracy: 0.9846 - recall: 0.9846 - auc: 0.9973 - precision: 0.9846 - val_loss: 1.2377 - val_accuracy: 0.8545 - val_recall: 0.8545 - val_auc: 0.9096 - val_precision: 0.8545\n",
      "Epoch 15/50\n",
      "46/46 [==============================] - 579s 13s/step - loss: 0.9271 - accuracy: 0.9758 - recall: 0.9758 - auc: 0.9919 - precision: 0.9758 - val_loss: 1.8804 - val_accuracy: 0.8000 - val_recall: 0.8000 - val_auc: 0.8234 - val_precision: 0.8000\n",
      "Epoch 16/50\n",
      "46/46 [==============================] - 579s 13s/step - loss: 0.9133 - accuracy: 0.9802 - recall: 0.9802 - auc: 0.9989 - precision: 0.9802 - val_loss: 2.0922 - val_accuracy: 0.7909 - val_recall: 0.7909 - val_auc: 0.8297 - val_precision: 0.7909\n",
      "Epoch 17/50\n",
      "46/46 [==============================] - 578s 13s/step - loss: 0.9000 - accuracy: 0.9824 - recall: 0.9824 - auc: 0.9992 - precision: 0.9824 - val_loss: 1.5227 - val_accuracy: 0.8636 - val_recall: 0.8636 - val_auc: 0.8607 - val_precision: 0.8636\n",
      "Epoch 18/50\n",
      "46/46 [==============================] - 574s 13s/step - loss: 0.9060 - accuracy: 0.9802 - recall: 0.9802 - auc: 0.9968 - precision: 0.9802 - val_loss: 2.3755 - val_accuracy: 0.7636 - val_recall: 0.7636 - val_auc: 0.7869 - val_precision: 0.7636\n",
      "Epoch 19/50\n",
      "46/46 [==============================] - 577s 13s/step - loss: 0.9010 - accuracy: 0.9846 - recall: 0.9846 - auc: 0.9989 - precision: 0.9846 - val_loss: 1.7765 - val_accuracy: 0.8000 - val_recall: 0.8000 - val_auc: 0.8450 - val_precision: 0.8000\n",
      "Epoch 20/50\n",
      "46/46 [==============================] - 573s 13s/step - loss: 0.9102 - accuracy: 0.9758 - recall: 0.9758 - auc: 0.9939 - precision: 0.9758 - val_loss: 1.4629 - val_accuracy: 0.8636 - val_recall: 0.8636 - val_auc: 0.8783 - val_precision: 0.8636\n",
      "Epoch 21/50\n",
      "46/46 [==============================] - 579s 13s/step - loss: 0.8921 - accuracy: 0.9802 - recall: 0.9802 - auc: 0.9992 - precision: 0.9802 - val_loss: 1.3679 - val_accuracy: 0.8545 - val_recall: 0.8545 - val_auc: 0.8945 - val_precision: 0.8545\n",
      "Epoch 22/50\n",
      "46/46 [==============================] - 576s 13s/step - loss: 0.8750 - accuracy: 0.9934 - recall: 0.9934 - auc: 0.9998 - precision: 0.9934 - val_loss: 1.4990 - val_accuracy: 0.8545 - val_recall: 0.8545 - val_auc: 0.8700 - val_precision: 0.8545\n",
      "Epoch 23/50\n",
      "46/46 [==============================] - 577s 13s/step - loss: 0.8746 - accuracy: 0.9934 - recall: 0.9934 - auc: 0.9996 - precision: 0.9934 - val_loss: 1.4654 - val_accuracy: 0.8545 - val_recall: 0.8545 - val_auc: 0.8882 - val_precision: 0.8545\n",
      "Epoch 24/50\n",
      "46/46 [==============================] - 578s 13s/step - loss: 0.8709 - accuracy: 0.9956 - recall: 0.9956 - auc: 0.9998 - precision: 0.9956 - val_loss: 1.4443 - val_accuracy: 0.8545 - val_recall: 0.8545 - val_auc: 0.8960 - val_precision: 0.8545\n",
      "Epoch 25/50\n",
      "46/46 [==============================] - 578s 13s/step - loss: 0.8888 - accuracy: 0.9802 - recall: 0.9802 - auc: 0.9988 - precision: 0.9802 - val_loss: 1.4590 - val_accuracy: 0.8000 - val_recall: 0.8000 - val_auc: 0.8468 - val_precision: 0.8000\n",
      "Epoch 26/50\n",
      "46/46 [==============================] - 574s 13s/step - loss: 0.8833 - accuracy: 0.9846 - recall: 0.9846 - auc: 0.9991 - precision: 0.9846 - val_loss: 1.7783 - val_accuracy: 0.8091 - val_recall: 0.8091 - val_auc: 0.8355 - val_precision: 0.8091\n",
      "Epoch 27/50\n",
      "46/46 [==============================] - 573s 13s/step - loss: 0.8578 - accuracy: 0.9956 - recall: 0.9956 - auc: 1.0000 - precision: 0.9956 - val_loss: 1.6727 - val_accuracy: 0.8273 - val_recall: 0.8273 - val_auc: 0.8503 - val_precision: 0.8273\n",
      "Epoch 28/50\n",
      "46/46 [==============================] - 573s 13s/step - loss: 0.8540 - accuracy: 0.9956 - recall: 0.9956 - auc: 0.9999 - precision: 0.9956 - val_loss: 1.4952 - val_accuracy: 0.8455 - val_recall: 0.8455 - val_auc: 0.8605 - val_precision: 0.8455\n",
      "Epoch 29/50\n",
      "46/46 [==============================] - 573s 13s/step - loss: 0.8613 - accuracy: 0.9912 - recall: 0.9912 - auc: 0.9995 - precision: 0.9912 - val_loss: 1.6449 - val_accuracy: 0.7091 - val_recall: 0.7091 - val_auc: 0.7760 - val_precision: 0.7091\n",
      "Epoch 30/50\n",
      "46/46 [==============================] - 569s 13s/step - loss: 0.8638 - accuracy: 0.9912 - recall: 0.9912 - auc: 0.9994 - precision: 0.9912 - val_loss: 1.1947 - val_accuracy: 0.8545 - val_recall: 0.8545 - val_auc: 0.9140 - val_precision: 0.8545\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - 569s 13s/step - loss: 0.8619 - accuracy: 0.9868 - recall: 0.9868 - auc: 0.9995 - precision: 0.9868 - val_loss: 1.5367 - val_accuracy: 0.8273 - val_recall: 0.8273 - val_auc: 0.8569 - val_precision: 0.8273\n",
      "Epoch 32/50\n",
      "46/46 [==============================] - 569s 13s/step - loss: 0.8801 - accuracy: 0.9758 - recall: 0.9758 - auc: 0.9965 - precision: 0.9758 - val_loss: 1.6791 - val_accuracy: 0.8364 - val_recall: 0.8364 - val_auc: 0.8568 - val_precision: 0.8364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50\n",
      "46/46 [==============================] - 572s 13s/step - loss: 0.8603 - accuracy: 0.9890 - recall: 0.9890 - auc: 0.9995 - precision: 0.9890 - val_loss: 1.5738 - val_accuracy: 0.8364 - val_recall: 0.8364 - val_auc: 0.8655 - val_precision: 0.8364\n",
      "Epoch 34/50\n",
      "46/46 [==============================] - 572s 13s/step - loss: 0.8394 - accuracy: 0.9978 - recall: 0.9978 - auc: 1.0000 - precision: 0.9978 - val_loss: 2.1866 - val_accuracy: 0.7727 - val_recall: 0.7727 - val_auc: 0.7829 - val_precision: 0.7727\n",
      "Epoch 35/50\n",
      "46/46 [==============================] - 571s 13s/step - loss: 0.8592 - accuracy: 0.9846 - recall: 0.9846 - auc: 0.9992 - precision: 0.9846 - val_loss: 1.9133 - val_accuracy: 0.7818 - val_recall: 0.7818 - val_auc: 0.8131 - val_precision: 0.7818\n",
      "Epoch 36/50\n",
      "46/46 [==============================] - 574s 13s/step - loss: 0.8682 - accuracy: 0.9824 - recall: 0.9824 - auc: 0.9945 - precision: 0.9824 - val_loss: 1.4636 - val_accuracy: 0.7727 - val_recall: 0.7727 - val_auc: 0.8375 - val_precision: 0.7727\n",
      "Epoch 37/50\n",
      "46/46 [==============================] - 574s 13s/step - loss: 0.8790 - accuracy: 0.9714 - recall: 0.9714 - auc: 0.9978 - precision: 0.9714 - val_loss: 3.3529 - val_accuracy: 0.7455 - val_recall: 0.7455 - val_auc: 0.7590 - val_precision: 0.7455\n",
      "Epoch 38/50\n",
      "46/46 [==============================] - 572s 13s/step - loss: 0.8453 - accuracy: 0.9890 - recall: 0.9890 - auc: 0.9996 - precision: 0.9890 - val_loss: 1.4347 - val_accuracy: 0.8455 - val_recall: 0.8455 - val_auc: 0.8974 - val_precision: 0.8455\n",
      "Epoch 39/50\n",
      "46/46 [==============================] - 566s 13s/step - loss: 0.8330 - accuracy: 0.9956 - recall: 0.9956 - auc: 0.9999 - precision: 0.9956 - val_loss: 1.3463 - val_accuracy: 0.8636 - val_recall: 0.8636 - val_auc: 0.9019 - val_precision: 0.8636\n",
      "Epoch 40/50\n",
      "46/46 [==============================] - 568s 13s/step - loss: 0.8487 - accuracy: 0.9846 - recall: 0.9846 - auc: 0.9972 - precision: 0.9846 - val_loss: 1.2655 - val_accuracy: 0.8545 - val_recall: 0.8545 - val_auc: 0.9170 - val_precision: 0.8545\n",
      "Epoch 41/50\n",
      "46/46 [==============================] - 569s 13s/step - loss: 0.8606 - accuracy: 0.9780 - recall: 0.9780 - auc: 0.9946 - precision: 0.9780 - val_loss: 1.5080 - val_accuracy: 0.8364 - val_recall: 0.8364 - val_auc: 0.8717 - val_precision: 0.8364\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - 567s 13s/step - loss: 0.8518 - accuracy: 0.9846 - recall: 0.9846 - auc: 0.9990 - precision: 0.9846 - val_loss: 1.7565 - val_accuracy: 0.6727 - val_recall: 0.6727 - val_auc: 0.7107 - val_precision: 0.6727\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 569s 13s/step - loss: 0.8313 - accuracy: 0.9912 - recall: 0.9912 - auc: 0.9998 - precision: 0.9912 - val_loss: 1.4503 - val_accuracy: 0.7636 - val_recall: 0.7636 - val_auc: 0.8417 - val_precision: 0.7636\n",
      "Epoch 44/50\n",
      "46/46 [==============================] - 568s 13s/step - loss: 0.8383 - accuracy: 0.9890 - recall: 0.9890 - auc: 0.9973 - precision: 0.9890 - val_loss: 1.3760 - val_accuracy: 0.8364 - val_recall: 0.8364 - val_auc: 0.8787 - val_precision: 0.8364\n",
      "Epoch 45/50\n",
      "46/46 [==============================] - 571s 13s/step - loss: 0.8448 - accuracy: 0.9912 - recall: 0.9912 - auc: 0.9969 - precision: 0.9912 - val_loss: 1.5121 - val_accuracy: 0.8455 - val_recall: 0.8455 - val_auc: 0.8728 - val_precision: 0.8455\n",
      "Epoch 46/50\n",
      "46/46 [==============================] - 572s 13s/step - loss: 0.8189 - accuracy: 0.9956 - recall: 0.9956 - auc: 0.9999 - precision: 0.9956 - val_loss: 1.5808 - val_accuracy: 0.7273 - val_recall: 0.7273 - val_auc: 0.8007 - val_precision: 0.7273\n",
      "Epoch 47/50\n",
      "46/46 [==============================] - 573s 13s/step - loss: 0.8171 - accuracy: 0.9934 - recall: 0.9934 - auc: 0.9998 - precision: 0.9934 - val_loss: 1.8000 - val_accuracy: 0.6727 - val_recall: 0.6727 - val_auc: 0.7226 - val_precision: 0.6727\n",
      "Epoch 48/50\n",
      "46/46 [==============================] - 571s 13s/step - loss: 0.8311 - accuracy: 0.9891 - recall: 0.9891 - auc: 0.9993 - precision: 0.9891 - val_loss: 1.3876 - val_accuracy: 0.8091 - val_recall: 0.8091 - val_auc: 0.8531 - val_precision: 0.8091\n",
      "Epoch 49/50\n",
      "46/46 [==============================] - 577s 13s/step - loss: 0.8231 - accuracy: 0.9890 - recall: 0.9890 - auc: 0.9975 - precision: 0.9890 - val_loss: 1.4644 - val_accuracy: 0.7455 - val_recall: 0.7455 - val_auc: 0.8344 - val_precision: 0.7455\n",
      "Epoch 50/50\n",
      "46/46 [==============================] - 573s 13s/step - loss: 0.8195 - accuracy: 0.9868 - recall: 0.9868 - auc: 0.9996 - precision: 0.9868 - val_loss: 1.3594 - val_accuracy: 0.8000 - val_recall: 0.8000 - val_auc: 0.8645 - val_precision: 0.8000\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = ModelCheckpoint('UpgradedFilter_ROI_ADNI_ADvsMCI_v2.h5', monitor='val_accuracy', mode='max', save_best_only=True)\n",
    "\n",
    "num_epoch = 50\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=num_epoch,\n",
    "    steps_per_epoch=len(train_paths) // batch_size,\n",
    "    validation_data=test_dataset,\n",
    "    validation_steps=len(test_paths) // batch_size,\n",
    "    callbacks=[model_checkpoint]  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 94s 9s/step - loss: 1.2356 - accuracy: 0.8818 - recall: 0.8818 - auc: 0.9112 - precision: 0.8818\n",
      "Test Accuracy: [1.235592007637024, 0.8818181753158569, 0.8818181753158569, 0.9112396836280823, 0.8818181753158569]\n"
     ]
    }
   ],
   "source": [
    "# Load the best model and evaluate on test data\n",
    "saved_model = tf.keras.models.load_model('UpgradedFilter_ROI_ADNI_ADvsMCI_v2.h5')\n",
    "test_accuracy = saved_model.evaluate(\n",
    "    test_dataset,\n",
    "    steps=len(test_paths) // batch_size,\n",
    "    verbose=1\n",
    ")\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the saved model\n",
    "saved_model = tf.keras.models.load_model('UpgradedFilter_ROI_ADNI_ADvsMCI_v2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoAAAAIhCAYAAADejQtoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAABKy0lEQVR4nO3deVyVZf7/8fcN4gEUUFxYzAUVNfd9rdAKd0enqTRb3DIVzRgrjWxcyiCtzMytZVSmXGpKnRY1LY2ZcSnMXcmyUKsRd0URQfD+/eGP8+0EKoc4HDz36zmP+/GI67rPdX/OAcYPn+u6r9swTdMUAAAALMPL3QEAAACgZJEAAgAAWAwJIAAAgMWQAAIAAFgMCSAAAIDFkAACAABYDAkgAACAxZAAAgAAWAwJIAAAgMWQAOKmsnjxYhmGIcMw9NVXX+XrN01TdevWlWEY6ty5c77+9PR0vfjii2rdurUCAwNls9lUq1YtDR06VNu3b893nW3btrnw3RTe7t27NWTIEEVERMjX11fly5dXy5YtNWPGDJ0+fdp+XufOnWUYhrp3755vjEOHDskwDL3yyitFiuGrr76yf/aGYcjb21tVqlRRnz59SuRzGjx4sGrVquXy67jajh07FBUVpaCgIBmGoVmzZl3zXMMwNGbMmCJdZ+nSpdcdu7TYv3+/pkyZokOHDrk7FMBSSABxUwoICNDf//73fO1JSUn68ccfFRAQkK/vxx9/VIsWLfTSSy+pS5cuWrZsmdatW6epU6fq2LFjatWqlc6dO1cS4Tvl7bffVqtWrZScnKynn35aa9eu1cqVK3XfffdpwYIFGjZsWL7XfP7559qwYYNL4omPj9eWLVv01Vdf6W9/+5s2b96sqKgo/fDDDy65Xp6//e1vWrlypUuvURKGDh2qo0ePavny5dqyZYsGDBjgkuvcTAng1KlTSQCBElbG3QEARdG/f38tWbJEc+fOVWBgoL3973//uzp06KD09HSH83Nzc/XnP/9ZJ0+e1JYtW9S4cWN7X1RUlAYNGqQ1a9bIx8enxN5DYWzZskWjRo1SdHS0Vq1aJZvNZu+Ljo7Wk08+qbVr1zq8pl69esrJydH48eOVnJwswzCKNabIyEi1b99eknT77berQoUKGjRokN577z1NnTq1WK/1W3Xq1HHZ2CVp7969Gj58uHr06OHuUIokMzNTfn5+7g4DwB9EBRA3pQceeECStGzZMnvbuXPn9NFHH2no0KH5zl+1apX27NmjuLg4h+Tvt3r06CF/f/9Cx7Br1y4ZhlFgJXLNmjUyDEMff/yxJOnEiRN67LHHVL16ddlsNlWpUkWdOnXSF198cd1rxMfHyzAMvfXWWw7JX56yZcvqT3/6k0Obj4+PXnzxRX377bd6//33C/1+iqp169aSpGPHjjm0//DDDxo4cKCqVq0qm82mW2+9VXPnzs33+n379qlr167y9/dXlSpVNHr0aH322Wf5pvkLmgK+dOmS4uLiFBERobJly6patWoaPXq0zp4963BerVq11Lt3b61du1YtW7aUn5+fGjRooIULFzqcd/HiRT311FP2qfbg4GC1bt3a4efsWvbu3au+ffuqYsWK8vX1VfPmzZWYmGjvz1tWkJOTo/nz59un0p2RNw2/bNkyTZw4UeHh4QoMDNTdd9+tAwcO2M/r3LmzPvvsMx0+fNhh2j5Pdna2pk2bpgYNGth/HocMGaITJ04U+LmtWLFCLVq0kK+vrz3JT0tL04gRI3TLLbeobNmyioiI0NSpU5WTk+Mwxvz589WsWTOVL19eAQEBatCggZ599ln7Z3LfffdJkrp06WKPc/HixZKuTpf37t3b/jMUHh6uXr166ZdffnHqcwOQHxVA3JQCAwN17733auHChRoxYoSkq8mgl5eX+vfvn2/qa926dZKkfv36FVsMzZo1U4sWLbRo0aJ807CLFy9W1apV1bNnT0nSww8/rO3bt+vFF19UvXr1dPbsWW3fvl2nTp265vi5ubnasGGDWrVqperVqzsVW//+/fXKK6/oueee01/+8pfrVjbzkqqiTsGlpqZKulp5zLN//3517NhRNWrU0KuvvqrQ0FB9/vnnGjt2rE6ePKnJkydLko4ePaqoqCiVK1dO8+fPV9WqVbVs2bJCrXszTVP9+vXTl19+qbi4ON1+++3avXu3Jk+erC1btmjLli0OSfOuXbv05JNP6plnnlFISIjeeecdDRs2THXr1tUdd9whSRo3bpzeffddTZs2TS1atFBGRob27t173e+TJB04cEAdO3ZU1apVNXv2bFWqVEnvvfeeBg8erGPHjmn8+PHq1auXtmzZog4dOujee+/Vk08+6fRnnefZZ59Vp06d9M477yg9PV0TJkxQnz59lJKSIm9vb82bN0+PPfaYfvzxx3zT5leuXFHfvn31n//8R+PHj1fHjh11+PBhTZ48WZ07d9a2bdscKnzbt29XSkqKnnvuOUVERKhcuXJKS0tT27Zt5eXlpUmTJqlOnTrasmWLpk2bpkOHDmnRokWSpOXLlysmJkaPP/64XnnlFXl5eengwYPav3+/JKlXr16Kj4/Xs88+q7lz56ply5aSrlZ7MzIyFB0drYiICM2dO1chISFKS0vTxo0bdf78+SJ/dgD+PxO4iSxatMiUZCYnJ5sbN240JZl79+41TdM027RpYw4ePNg0TdNs1KiRGRUVZX9d9+7dTUnmpUuXnL7O9cyePduUZB44cMDedvr0adNms5lPPvmkva18+fJmbGxsYd+maZqmmZaWZkoyBwwYUOjXREVFmY0aNTJN0zS/+OILU5L5xhtvmKZpmqmpqaYk8+WXX3Z4TZ06dcw6derccOy8z/v99983L1++bF68eNHctGmTWb9+fbNhw4bmmTNn7Od269bNvOWWW8xz5845jDFmzBjT19fXPH36tGmapvn000+bhmGY+/btczivW7dupiRz48aN9rZBgwaZNWvWtH+9du1aU5I5Y8YMh9e+//77piTzrbfesrfVrFnT9PX1NQ8fPmxvy8zMNIODg80RI0bY2xo3bmz269fvhp/F7w0YMMC02WzmkSNHHNp79Ohh+vv7m2fPnrW3STJHjx5dqHF/f27e96Bnz54O533wwQemJHPLli32tl69ejl8XnmWLVtmSjI/+ugjh/bk5GRTkjlv3jx7W82aNU1vb2+Hn2/TNM0RI0aY5cuXd/g8TdM0X3nlFVOS/fs5ZswYs0KFCtd9j//85z/zfa9N0zS3bdtmSjJXrVp13dcDKBqmgHHTioqKUp06dbRw4ULt2bNHycnJBU7/utKDDz4om81mn7KSrlYis7KyNGTIEHtb27ZttXjxYk2bNk1bt27V5cuXXR7bXXfdpa5du+r555+/bsXk4MGDOnjwYKHH7d+/v3x8fOTv769OnTopPT1dn332mSpUqCDp6rTsl19+qT//+c/y9/dXTk6O/ejZs6cuXbqkrVu3Srp6007jxo3VsGFDh2vkTfFfT95NLoMHD3Zov++++1SuXDl9+eWXDu3NmzdXjRo17F/7+vqqXr16Onz4sL2tbdu2WrNmjZ555hl99dVXyszMLNRnsmHDBt111135KrWDBw/WxYsXtWXLlkKNU1i/n/Zv2rSpJDm8l2v59NNPVaFCBfXp08fhe9O8eXOFhobmu7u+adOmDtXdvDG6dOmi8PBwhzHy1jUmJSVJuvp5nj17Vg888ID+9a9/6eTJk4V+j3Xr1lXFihU1YcIELViwwF41BFA8SABx0zIMQ0OGDNF7772nBQsWqF69err99tsLPDfvH/686criEhwcrD/96U/6xz/+odzcXElXp3/btm2rRo0a2c97//33NWjQIL3zzjvq0KGDgoOD9cgjjygtLe2aY1euXFn+/v5/KObp06fr5MmTRd765VpjJicnKykpSRMnTtSxY8fUr18/ZWVlSZJOnTqlnJwcvfHGG/Lx8XE48qbE8xKBU6dOKSQkJN81Cmr7vVOnTqlMmTKqUqWKQ7thGAoNDc03bVupUqV8Y9hsNockb/bs2ZowYYJWrVqlLl26KDg4WP369bvhHc6nTp1SWFhYvvbw8HB7f3H6/XvJm+ouTMJ67NgxnT17VmXLls33/UlLS8uXpBX0vo4dO6ZPPvkk3+vzfubzxnj44Ye1cOFCHT58WH/5y19UtWpVtWvXTuvXr79hnEFBQUpKSlLz5s317LPPqlGjRgoPD9fkyZNL5A8owNORAOKmNnjwYJ08eVILFixwqLj9Xrdu3SRdvRmkuA0ZMkS//vqr1q9fr/379ys5OTlfLJUrV9asWbN06NAhHT58WAkJCVqxYkW+6tVveXt766677tK3335b5EXvzZs31wMPPKCZM2fmu0mjqGrXrq3WrVvrjjvu0LRp0/T8889r165deuONNyRJFStWlLe3twYPHqzk5OQCj7xEsFKlSgXGdb3EOE+lSpWUk5OT78YF0zSVlpamypUrO/3eypUrp6lTp+q7775TWlqa5s+fr61bt6pPnz43jOXo0aP52v/3v/9JUpFicZXKlSurUqVK1/zezJs3z+H8gm5UqVy5srp27XrNMX67JnbIkCHavHmzzp07p88++0ymaap3796FqlY2adJEy5cv16lTp7Rz5071799fzz//vF599dU//kEAFkcCiJtatWrV9PTTT6tPnz4aNGjQNc/r27evmjRpooSEBO3du7fAcz7//HNdvHjR6Ri6du2qatWqadGiRVq0aJF8fX2vO4VZo0YNjRkzRtHR0Q6bTxckLi5Opmlq+PDhys7Oztd/+fJlffLJJ9cdY9q0acrOznbZFi3jx49X3bp19dJLL+n8+fPy9/dXly5dtGPHDjVt2lStW7fOd+RVsKKiorR3795803vLly+/4XXvuusuSdJ7773n0P7RRx8pIyPD3l9UISEhGjx4sB544AEdOHDguj8bd911lzZs2GBP+PL84x//kL+/v33bnJL0++pmnt69e+vUqVPKzc0t8HtTv379G47du3dv7d27V3Xq1ClwjLzK52+VK1dOPXr00MSJE5Wdna19+/bZ45SuX700DEPNmjXTa6+9pgoVKtzw9wbAjXEXMG56L7300g3P8fb21sqVK9W1a1d16NBBo0aNUpcuXVSuXDkdPnxYH374oT755BOdOXPG6et7e3vrkUce0cyZMxUYGKh77rlHQUFB9v5z586pS5cuGjhwoBo0aKCAgAAlJydr7dq1uueee647docOHTR//nzFxMSoVatWGjVqlBo1aqTLly9rx44deuutt9S4cePrVqgiIiI0atQovf766wX2161bV5KcWgf4Wz4+PoqPj9f999+v119/Xc8995xef/113Xbbbbr99ts1atQo1apVS+fPn9fBgwf1ySef2NfvxcbGauHCherRo4eef/55hYSEaOnSpfruu+8kSV5e1/4bNTo6Wt26ddOECROUnp6uTp062e8CbtGihR5++GGn30u7du3Uu3dvNW3aVBUrVlRKSoreffdddejQ4bpbBE2ePNm+Lm7SpEkKDg7WkiVL9Nlnn2nGjBkOPw8lpUmTJlqxYoXmz5+vVq1aycvLS61bt9aAAQO0ZMkS9ezZU0888YTatm0rHx8f/fLLL9q4caP69u2rP//5z9cd+/nnn9f69evVsWNHjR07VvXr19elS5d06NAhrV69WgsWLNAtt9yi4cOHy8/PT506dVJYWJjS0tKUkJCgoKAgtWnTRpLs2zK99dZbCggIkK+vryIiIrRlyxbNmzdP/fr1U+3atWWaplasWKGzZ88qOjra5Z8f4PHcew8K4JzC3p37+7uA85w9e9Z84YUXzJYtW5rly5c3fXx8zBo1apgPPfSQuWnTJqevk+f77783JZmSzPXr1zv0Xbp0yRw5cqTZtGlTMzAw0PTz8zPr169vTp482czIyCjU+Dt37jQHDRpk1qhRwyxbtqxZrlw5s0WLFuakSZPM48eP28/77V3Av3XixAkzMDCwwLuAa9asWeDdor+XdwfqP//5zwL727VrZ1asWNF+x2tqaqo5dOhQs1q1aqaPj49ZpUoVs2PHjua0adMcXrd3717z7rvvNn19fc3g4GBz2LBhZmJioinJ3LVrl/28398FbJpX7+SdMGGCWbNmTdPHx8cMCwszR40a5XBHct577NWrV76Yo6KiHH5OnnnmGbN169ZmxYoVTZvNZtauXdv861//ap48efKGn8+ePXvMPn36mEFBQWbZsmXNZs2amYsWLcp3norhLuDffw/y7vD+7fVOnz5t3nvvvWaFChVMwzDM3/7f/eXLl81XXnnFbNasmenr62uWL1/ebNCggTlixAjzhx9+sJ93rc/NNK/+TI0dO9aMiIgwfXx8zODgYLNVq1bmxIkTzQsXLpimaZqJiYlmly5dzJCQELNs2bJmeHi4ef/995u7d+92GGvWrFlmRESE6e3tbX8f3333nfnAAw+YderUMf38/MygoCCzbdu25uLFiwv12QG4PsM0TdMtmScAXMNjjz2mZcuW6dSpUypbtqy7wwEAj8MUMAC3ev755xUeHq7atWvrwoUL+vTTT/XOO+/oueeeI/kDABchAQTgVj4+Pnr55Zf1yy+/KCcnR5GRkZo5c6aeeOIJd4cGAB6LKWAAAACLYRsYAAAAiyEBBAAAsBgSQAAAAIshAQQAALAYj7wLeMfh8+4OAYCLRFS99hM5ANzcKvh5u+3afi3GuGzszB1zXDZ2UVEBBAAAsBiPrAACAAA4xbBWTYwEEAAAwDDcHUGJsla6CwAAACqAAAAAVpsCtta7BQAAABVAAAAA1gACAADAo1EBBAAAYA0gAAAAPBkVQAAAAIutASQBBAAAYAoYAAAAnowKIAAAgMWmgKkAAgAAWAwVQAAAANYAAgAAwJNRAQQAAGANIAAAADwZFUAAAACLrQEkAQQAAGAKGAAAAJ6MCiAAAIDFpoCt9W4BAABABRAAAIAKIAAAADwaFUAAAAAv7gIGAACAB6MCCAAAYLE1gCSAAAAAbAQNAAAAT0YFEAAAwGJTwNZ6twAAAKACCAAAwBpAAAAAeDQqgAAAAKwBBAAAgCejAggAAGCxNYAkgAAAAEwBAwAAwJORAAIAABiG6w4n1KpVS4Zh5DtGjx4tSTJNU1OmTFF4eLj8/PzUuXNn7du3z+m3SwIIAABQSiQnJ+vo0aP2Y/369ZKk++67T5I0Y8YMzZw5U3PmzFFycrJCQ0MVHR2t8+fPO3UdEkAAAADDy3WHE6pUqaLQ0FD78emnn6pOnTqKioqSaZqaNWuWJk6cqHvuuUeNGzdWYmKiLl68qKVLlzp1HRJAAAAAF8rKylJ6errDkZWVdcPXZWdn67333tPQoUNlGIZSU1OVlpamrl272s+x2WyKiorS5s2bnYqJBBAAAMCFawATEhIUFBTkcCQkJNwwpFWrVuns2bMaPHiwJCktLU2SFBIS4nBeSEiIva+w2AYGAADAheLi4jRu3DiHNpvNdsPX/f3vf1ePHj0UHh7u0G787sYS0zTztd0ICSAAAIAL9wG02WyFSvh+6/Dhw/riiy+0YsUKe1toaKikq5XAsLAwe/vx48fzVQVvhClgAACAUnITSJ5FixapatWq6tWrl70tIiJCoaGh9juDpavrBJOSktSxY0enxqcCCAAAUIpcuXJFixYt0qBBg1SmzP+laoZhKDY2VvHx8YqMjFRkZKTi4+Pl7++vgQMHOnUNEkAAAIBS9CzgL774QkeOHNHQoUPz9Y0fP16ZmZmKiYnRmTNn1K5dO61bt04BAQFOXcMwTdMsroBLix2HndsMEcDNI6Kqv7tDAOAiFfy83XZtvz/Nd9nYmR+PctnYRUUFEAAAwIU3gZRG1nq3AAAAoAIIAABQmtYAlgQqgAAAABZDBRAAAMBiawBJAAEAAJgCBgAAgCejAggAACzPoAIIAAAAT0YFEAAAWB4VQAAAAHg0KoAAAADWKgBSAQQAALAaKoAAAMDyrLYGkAQQAABYntUSQKaAAQAALIYKIAAAsDwqgAAAAPBoVAABAIDlUQEEAACAR6MCCAAAYK0CIBVAAAAAq6ECCAAALI81gAAAAPBoVAABAIDlWa0CSAIIAAAsz2oJIFPAAAAAFkMFEAAAWB4VQAAAAHg0KoAAAADWKgBSAQQAALAaKoAAAMDyWAMIAAAAj0YFEAAAWJ7VKoAkgAAAwPKslgAyBQwAAGAxVAABAACsVQCkAggAAGA1VAABAIDlsQYQAAAAHo0KIAAAsDwqgAAAAPBoVAABAIDlWa0CSAIIAAAsz2oJIFPAAAAAFkMFEAAAwFoFQCqAAAAAVkMFEAAAWB5rAAEAAODRqAACAADLowIIAAAAj0YFEAAAWJ7VKoAkgAAAANbK/5gCBgAAKE1+/fVXPfTQQ6pUqZL8/f3VvHlzffvtt/Z+0zQ1ZcoUhYeHy8/PT507d9a+ffucugYJIAAAsDzDMFx2OOPMmTPq1KmTfHx8tGbNGu3fv1+vvvqqKlSoYD9nxowZmjlzpubMmaPk5GSFhoYqOjpa58+fL/R13DoFPHv27EKdN3bsWBdHAgAA4H7Tp09X9erVtWjRIntbrVq17P9tmqZmzZqliRMn6p577pEkJSYmKiQkREuXLtWIESMKdR3DNE2zWCN3QkRExA3PMQxDP/30k1Pj7jhc+AwYwM0loqq/u0MA4CIV/Lzddu2aYz9x2djfv9xVWVlZDm02m002my3fuQ0bNlS3bt30yy+/KCkpSdWqVVNMTIyGDx8uSfrpp59Up04dbd++XS1atLC/rm/fvqpQoYISExMLFZNbK4CpqanuvDwAAIDLJSQkaOrUqQ5tkydP1pQpU/Kd+9NPP2n+/PkaN26cnn32WX3zzTcaO3asbDabHnnkEaWlpUmSQkJCHF4XEhKiw4cPFzom7gJGqbdq2SJ9s2mj/vfzIZUta1O9hk018NHHFV69lv0c0zT14btvacPqlbpw4bzqNmikoWMmqHqtOu4LHECR5OTk6J0Fc7V29ac6feqkKlWuol5/6qehw0fKy4ul63ANV24DExcXp3Hjxjm0FVT9k6QrV66odevWio+PlyS1aNFC+/bt0/z58/XII49cM17TNJ16D279TdqwYYMaNmyo9PT0fH3nzp1To0aN9O9//9sNkaE0SdmzXV3/dJ9eeH2RJr40V7lXchUfN0aXMjPt53z8QaJWr1iqIWPGK/6NRFWoWEnxz4xW5sUMN0YOoCjeXfSOVnz4vp565jktX/GpxsQ+qSWJC/XBsiXuDg0oEpvNpsDAQIfjWglgWFiYGjZs6NB266236siRI5Kk0NBQSbJXAvMcP348X1XwetyaAM6aNUvDhw9XYGBgvr6goCCNGDFCr732mhsiQ2kSF/+GOnfto+q16qhmnXoa9eRknTyeptQfUiRd/atnzcpl6vfAELW97U5Vj6irmKenKivrkjZtWOvm6AE4a8/uXbqj85267Y4ohVerpruiu6lth05K2b/X3aHBg5WWu4A7deqkAwcOOLR9//33qlmzpqSr90+EhoZq/fr19v7s7GwlJSWpY8eOhb6OWxPAXbt2qXv37tfs79q1q8O+N4AkXcy4IEkqH3D1D4fjab/q7OlTatqqvf0cn7JldWvTlvp+/263xAig6Jq1aKltX2/VkcOHJEnfH/hOu3ZsV8fb7nBvYPBshgsPJ/z1r3/V1q1bFR8fr4MHD2rp0qV66623NHr06KthGoZiY2MVHx+vlStXau/evRo8eLD8/f01cODAQl/HrWsAjx07Jh8fn2v2lylTRidOnLjuGFlZWfnurMnOylbZa5RWcXMzTVPvvjlT9Rs3V/WIupKks6dPSZKCKlZyODeoQiWdPH60xGME8Mc8MuRRXbhwXvf36yUvb29dyc3VyDFPqFuPXu4ODXC5Nm3aaOXKlYqLi9Pzzz+viIgIzZo1Sw8++KD9nPHjxyszM1MxMTE6c+aM2rVrp3Xr1ikgIKDQ13FrAlitWjXt2bNHdevWLbB/9+7dCgsLu+4YBd1Z89gTz2jkX58ttjhReiyaM0OHUw9q6sx38vUZ+f7Mcm5BLIDSYf3na7T2s0/1fMLLql2nrr4/8J1eezlBVapUVa8/9XN3ePBQpenfi969e6t3797X7DcMQ1OmTCnwLuLCcmsC2LNnT02aNEk9evSQr6+vQ19mZqYmT5583Q9AKvjOmpS07GKPFe63aO4Mbdvyb0159S1VqvJ/C10rBF+t/J09c1IVK1W2t587e1pBFYJLPE4Af8wbr72iR4Y8qq7de0qS6kbWU9rR/ylx4dskgEAxcWsC+Nxzz2nFihWqV6+exowZo/r168swDKWkpGju3LnKzc3VxIkTrztGQRsplj3DRtCexDRNLZo7Q8mbvtKkV95U1bBqDv1VQ6upQnAl7dn+tSLqNpAk5Vy+rJTd2zVw2OPuCBnAH3DpUma+7V68vLx05coVN0UEKyhNFcCS4NYEMCQkRJs2bVJMTIzi4uKU91ASwzDUrVs3zZs3z6lbmuGZFr4xXZs2rtVTU1+Vn5+/zp4+KUnyL1deZW2+MgxDPf78gFYtW6TQ8BoKq1ZdK5cvks3mq053XvsmIwCl0+13dNGid95USGjY/58CTtGy9xLVp+897g4N8BhufRTcb505c0YHDx6UaZqKjIxUxYoVizwWj4LzLAO6ti6wfeRTk9W5ax9J/7cR9JerVyjj/HnVbdBYQ8eMt98oAs/Bo+A8X0ZGht6cO1tJG7/QmdOnVblKVXXt3lPDRoySj09Zd4cHF3Lno+DqPrXGZWMffKWHy8YuKrcmgEOHDi3UeQsXLnRqXBJAwHORAAKeiwSw5Lh1Cnjx4sWqWbOmWrRooVJSiAQAABbEGsASNHLkSC1fvlw//fSThg4dqoceekjBwdy1CQAASpbF8j/3Pglk3rx5Onr0qCZMmKBPPvlE1atX1/3336/PP/+ciiAAAICLuDUBlK5u4/LAAw9o/fr12r9/vxo1aqSYmBjVrFlTFy5ccHd4AADAAkrLs4BLitsTwN/K+6BM02S/JwAAABdxewKYlZWlZcuWKTo6WvXr19eePXs0Z84cHTlyROXLl3d3eAAAwAIMw3VHaeTWm0BiYmK0fPly1ahRQ0OGDNHy5ctVqVIld4YEAADg8dyaAC5YsEA1atRQRESEkpKSlJSUVOB5K1asKOHIAACAlXh5ldJSnYu4NQF85JFHSu3iSAAAAE/l9o2gAQAA3M1q9Si3JoAAAAClgdVmJN1+FzAAAABKFhVAAABgeRYrAFIBBAAAsBoqgAAAwPJYAwgAAACPRgUQAABYHhVAAAAAeDQqgAAAwPIsVgAkAQQAAGAKGAAAAB6NCiAAALA8ixUAqQACAABYDRVAAABgeawBBAAAgEejAggAACzPYgVAKoAAAABWQwUQAABYHmsAAQAA4NGoAAIAAMuzWAGQBBAAAIApYAAAAHg0KoAAAMDyLFYApAIIAABgNVQAAQCA5bEGEAAAAB6NCiAAALA8ixUAqQACAABYDRVAAABgeVZbA0gCCAAALM9i+R9TwAAAAFZDBRAAAFie1aaAqQACAABYDBVAAABgeVQAAQAA4NGoAAIAAMuzWAGQCiAAAIDVUAEEAACWxxpAAAAAizEM1x3OmDJligzDcDhCQ0Pt/aZpasqUKQoPD5efn586d+6sffv2Of1+SQABAABKkUaNGuno0aP2Y8+ePfa+GTNmaObMmZozZ46Sk5MVGhqq6OhonT9/3qlrMAUMAAAsrzRNAZcpU8ah6pfHNE3NmjVLEydO1D333CNJSkxMVEhIiJYuXaoRI0YU+hpUAAEAAFwoKytL6enpDkdWVtY1z//hhx8UHh6uiIgIDRgwQD/99JMkKTU1VWlpaeratav9XJvNpqioKG3evNmpmEgAAQCA5blyDWBCQoKCgoIcjoSEhALjaNeunf7xj3/o888/19tvv620tDR17NhRp06dUlpamiQpJCTE4TUhISH2vsJiChgAAMCF4uLiNG7cOIc2m81W4Lk9evSw/3eTJk3UoUMH1alTR4mJiWrfvr2k/NPVpmk6PYVNAggAACzPy4VrAG022zUTvhspV66cmjRpoh9++EH9+vWTJKWlpSksLMx+zvHjx/NVBW+EKWAAAIBSKisrSykpKQoLC1NERIRCQ0O1fv16e392draSkpLUsWNHp8alAggAACyvtNwE/NRTT6lPnz6qUaOGjh8/rmnTpik9PV2DBg2SYRiKjY1VfHy8IiMjFRkZqfj4ePn7+2vgwIFOXYcEEAAAWF5p2Qbml19+0QMPPKCTJ0+qSpUqat++vbZu3aqaNWtKksaPH6/MzEzFxMTozJkzateundatW6eAgACnrmOYpmm64g24047Dzm2GCODmEVHV390hAHCRCn7ebrt2t3lfu2zsz2PauWzsoqICCAAALM+rdBQASww3gQAAAFgMFUAAAGB5pWUNYEmhAggAAGAxVAABAIDlWawASAUQAADAaqgAAgAAyzNkrRIgCSAAALA8toEBAACAR6MCCAAALI9tYAAAAODRqAACAADLs1gBkAogAACA1VABBAAAludlsRIgFUAAAACL+cMJYG5urnbu3KkzZ84URzwAAAAlzjBcd5RGTieAsbGx+vvf/y7pavIXFRWlli1bqnr16vrqq6+KOz4AAACXMwzDZUdp5HQC+OGHH6pZs2aSpE8++USpqan67rvvFBsbq4kTJxZ7gAAAACheTieAJ0+eVGhoqCRp9erVuu+++1SvXj0NGzZMe/bsKfYAAQAAXI0p4BsICQnR/v37lZubq7Vr1+ruu++WJF28eFHe3t7FHiAAAACKl9PbwAwZMkT333+/wsLCZBiGoqOjJUlff/21GjRoUOwBAgAAuJrVtoFxOgGcMmWKGjdurJ9//ln33XefbDabJMnb21vPPPNMsQcIAACA4lWkjaDvvffefG2DBg36w8EAAAC4g7Xqf4VMAGfPnl3oAceOHVvkYAAAAOB6hUoAX3vttUINZhgGCSAAALjplNb9+lylUAlgamqqq+MAAABwGy9r5X9FfxRcdna2Dhw4oJycnOKMBwAAAC7mdAJ48eJFDRs2TP7+/mrUqJGOHDki6erav5deeqnYAwQAAHA1HgV3A3Fxcdq1a5e++uor+fr62tvvvvtuvf/++8UaHAAAAIqf09vArFq1Su+//77at2/vkNU2bNhQP/74Y7EGBwAAUBJKaaHOZZyuAJ44cUJVq1bN156RkVFqy5wAAAD4P04ngG3atNFnn31m/zov6Xv77bfVoUOH4osMAACghFhtDaDTU8AJCQnq3r279u/fr5ycHL3++uvat2+ftmzZoqSkJFfECAAAgGLkdAWwY8eO2rRpky5evKg6depo3bp1CgkJ0ZYtW9SqVStXxAgAAOBSXobrjtKoSM8CbtKkiRITE4s7FgAAALcorVO1rlKkBDA3N1crV65USkqKDMPQrbfeqr59+6pMmSINBwAAgBLkdMa2d+9e9e3bV2lpaapfv74k6fvvv1eVKlX08ccfq0mTJsUeJAAAgCtZq/5XhDWAjz76qBo1aqRffvlF27dv1/bt2/Xzzz+radOmeuyxx1wRIwAAAIqR0xXAXbt2adu2bapYsaK9rWLFinrxxRfVpk2bYg0OAACgJHhZbA2g0xXA+vXr69ixY/najx8/rrp16xZLUAAAAHCdQlUA09PT7f8dHx+vsWPHasqUKWrfvr0kaevWrXr++ec1ffp010QJAADgQhYrABYuAaxQoYLD7dGmaer++++3t5mmKUnq06ePcnNzXRAmAAAAikuhEsCNGze6Og4AAAC3YR/AAkRFRbk6DgAAAJSQIu/cfPHiRR05ckTZ2dkO7U2bNv3DQQEAAJQkixUAnU8AT5w4oSFDhmjNmjUF9rMGEAAA3GzYBuYGYmNjdebMGW3dulV+fn5au3atEhMTFRkZqY8//tgVMQIAAKAYOV0B3LBhg/71r3+pTZs28vLyUs2aNRUdHa3AwEAlJCSoV69erogTAADAZSxWAHS+ApiRkaGqVatKkoKDg3XixAlJUpMmTbR9+/bijQ4AAADFrkhPAjlw4IAkqXnz5nrzzTf166+/asGCBQoLCyv2AAEAAFzNMAyXHaWR01PAsbGxOnr0qCRp8uTJ6tatm5YsWaKyZctq8eLFxR0fAAAAiplh5j3Go4guXryo7777TjVq1FDlypWLK64/5FKOuyMA4CoV24xxdwgAXCRzxxy3XfvxlSkuG/uNP9/qsrGLqsj7AObx9/dXy5YtiyMWAAAAlIBCJYDjxo0r9IAzZ84scjAAAADuUFrX6iUkJOjZZ5/VE088oVmzZkmSTNPU1KlT9dZbb+nMmTNq166d5s6dq0aNGhV63EIlgDt27CjUYKX1wwMAALger1KYwiQnJ+utt97K95S1GTNmaObMmVq8eLHq1aunadOmKTo6WgcOHFBAQEChxi5UArhx40bnowYAAECRXLhwQQ8++KDefvttTZs2zd5umqZmzZqliRMn6p577pEkJSYmKiQkREuXLtWIESMKNb7T28AAAAB4Gi/DdUdWVpbS09MdjqysrOvGM3r0aPXq1Ut33323Q3tqaqrS0tLUtWtXe5vNZlNUVJQ2b95c+Pfr3McDAAAAZyQkJCgoKMjhSEhIuOb5y5cv1/bt2ws8Jy0tTZIUEhLi0B4SEmLvK4w/fBcwAADAzc6V9zHExcXlu6HWZrMVeO7PP/+sJ554QuvWrZOvr+81x/x9vKZpOvUeSAABAABcyGazXTPh+71vv/1Wx48fV6tWrextubm5+ve//605c+bYn8aWlpbm8AS248eP56sKXg9TwAAAwPJcuQbQGXfddZf27NmjnTt32o/WrVvrwQcf1M6dO1W7dm2FhoZq/fr19tdkZ2crKSlJHTt2LPR1ilQBfPfdd7VgwQKlpqZqy5YtqlmzpmbNmqWIiAj17du3KEMCAABYXkBAgBo3buzQVq5cOVWqVMneHhsbq/j4eEVGRioyMlLx8fHy9/fXwIEDC30dpyuA8+fP17hx49SzZ0+dPXtWubm5kqQKFSrYNygEAAC4mRiG647iNn78eMXGxiomJkatW7fWr7/+qnXr1hV6D0CpCM8CbtiwoeLj49WvXz8FBARo165dql27tvbu3avOnTvr5MmTTr+R4sazgAHPxbOAAc/lzmcBP7P6e5eN/VLPei4bu6icrgCmpqaqRYsW+dptNpsyMjKKJSgAAAC4jtMJYEREhHbu3Jmvfc2aNWrYsGFxxAQAAFCivFx4lEZO3wTy9NNPa/To0bp06ZJM09Q333yjZcuWKSEhQe+8844rYgQAAEAxcjoBHDJkiHJycjR+/HhdvHhRAwcOVLVq1fT6669rwIABrogRAADApVy4D3SpVKRtYIYPH67hw4fr5MmTunLliqpWrVrccQEAAMBF/tCTQCpXrlxccQAAALiNl8VKgE4ngBEREdd91txPP/30hwICAACAazmdAMbGxjp8ffnyZe3YsUNr167V008/XVxxAQAAlBiLFQCdTwCfeOKJAtvnzp2rbdu2/eGAAAAASpqzz+y92RXb9jQ9evTQRx99VFzDAQAAwEX+0E0gv/Xhhx8qODi4uIYDAAAoMdwEcgMtWrRwuAnENE2lpaXpxIkTmjdvXrEGBwAAgOLndALYr18/h6+9vLxUpUoVde7cWQ0aNCiuuAAAAEqMxQqAziWAOTk5qlWrlrp166bQ0FBXxQQAAAAXcuomkDJlymjUqFHKyspyVTwAAAAlzstw3VEaOX0XcLt27bRjxw5XxAIAAIAS4PQawJiYGD355JP65Zdf1KpVK5UrV86hv2nTpsUWHAAAQEkwVEpLdS5S6ARw6NChmjVrlvr37y9JGjt2rL3PMAyZpinDMJSbm1v8UQIAALhQaZ2qdZVCJ4CJiYl66aWXlJqa6sp4AAAA4GKFTgBN05Qk1axZ02XBAAAAuIPVKoBO3QRiWG2THAAAAA/k1E0g9erVu2ESePr06T8UEAAAQEmzWpHLqQRw6tSpCgoKclUsAAAAKAFOJYADBgxQ1apVXRULAACAW7AG8BqsVhoFAADwVE7fBQwAAOBprFbnKnQCeOXKFVfGAQAA4DZeFssAnX4WMAAAAG5uTj8LGAAAwNNwEwgAAAA8GhVAAABgeRZbAkgFEAAAwGqoAAIAAMvzkrVKgFQAAQAALIYKIAAAsDyrrQEkAQQAAJbHNjAAAADwaFQAAQCA5fEoOAAAAHg0KoAAAMDyLFYApAIIAABgNVQAAQCA5bEGEAAAAB6NCiAAALA8ixUASQABAACsNiVqtfcLAABgeVQAAQCA5RkWmwOmAggAAGAxVAABAIDlWav+RwUQAADAcqgAAgAAy2MjaAAAAHg0KoAAAMDyrFX/owIIAAAgw3Dd4Yz58+eradOmCgwMVGBgoDp06KA1a9bY+03T1JQpUxQeHi4/Pz917txZ+/btc/r9kgACAACUErfccoteeuklbdu2Tdu2bdOdd96pvn372pO8GTNmaObMmZozZ46Sk5MVGhqq6OhonT9/3qnrGKZpmq54A+50KcfdEQBwlYptxrg7BAAukrljjtuuvWzHry4b+4EW1f7Q64ODg/Xyyy9r6NChCg8PV2xsrCZMmCBJysrKUkhIiKZPn64RI0YUekwqgAAAAC6UlZWl9PR0hyMrK+uGr8vNzdXy5cuVkZGhDh06KDU1VWlpaeratav9HJvNpqioKG3evNmpmEgAAQCA5Xm58EhISFBQUJDDkZCQcM1Y9uzZo/Lly8tms2nkyJFauXKlGjZsqLS0NElSSEiIw/khISH2vsLiLmAAAAAXiouL07hx4xzabDbbNc+vX7++du7cqbNnz+qjjz7SoEGDlJSUZO///XOLTdN0+lnGJIAAAMDynE2gnGGz2a6b8P1e2bJlVbduXUlS69atlZycrNdff92+7i8tLU1hYWH2848fP56vKngjTAEDAACUYqZpKisrSxEREQoNDdX69evtfdnZ2UpKSlLHjh2dGpMKIAAAsLzSshH0s88+qx49eqh69eo6f/68li9frq+++kpr166VYRiKjY1VfHy8IiMjFRkZqfj4ePn7+2vgwIFOXYcEEAAAoJQ4duyYHn74YR09elRBQUFq2rSp1q5dq+joaEnS+PHjlZmZqZiYGJ05c0bt2rXTunXrFBAQ4NR12AcQwE2FfQABz+XOfQA/3HXUZWPf2yzsxieVMCqAAADA8qx2U4TV3i8AAIDlUQEEAACW58ptYEojKoAAAAAWQwUQAABYnrXqf1QAAQAALIcKIAAAsDyLLQGkAggAAGA1VAABAIDleVlsFSAJIAAAsDymgAEAAODRqAACAADLMyw2BUwFEAAAwGKoAAIAAMtjDSAAAAA8GhVAAABgeVbbBoYKIAAAgMVQAQQAAJZntTWAJIAAAMDyrJYAMgUMAABgMVQAAQCA5bERNAAAADwaFUAAAGB5XtYqAFIBBAAAsBoqgAAAwPJYAwgAAACPRgUQAABYntX2ASQBBAAAlscUMAAAADwaFUAAAGB5bAMDAAAAj0YFEAAAWJ7V1gC6LQHs0qWLjBvccmMYhr788ssSiggAAMAa3JYANm/e/Jp96enpWrZsmbKyskouINxU5s99QwvmzXFoq1Spsjb8e5ObIgJQVN99NlU1wyvla1/w/r/115c+UOaOOQW8Snr2tZV67R8UCVA82AamhLz22mv52nJycjR37ly9+OKLqlatml544QU3RIabRZ26kXrrnUX2r728vd0YDYCiuu2hl+X9mxX4DeuGa/WCx7Vi/Q5JUq274xzO79qpkRZMHqiVX+4syTABj1Jq1gAuWbJEkyZNUmZmpqZMmaLHHntMZcqUmvBQCpXx9lblKlXcHQaAP+jkmQsOXz81pLF+PHJC//n2B0nSsVPnHfr7dG6ipOQfdOjXUyUWIzyfxQqA7k8A165dq2eeeUapqal66qmnNG7cOJUrV87dYeEmcPjIYd3d+Tb5lC2rJk2baewT43RL9eruDgvAH+BTxlsDerbR7Pc2FNhfNThA3W9rrOGT3i3hyODpvCw2B+y2BPCbb77RhAkTtHXrVo0cOVJffPGFKleu7PQ4WVlZ+dYKmt422Wy24goVpVCTpk31Yvx01axVS6dOndLbb87XIw8O0IqPP1WFChXdHR6AIvpTl6aqEOCn9z75usD+h/q00/mLl7Rqw86SDQzwMG5LANu3by8/Pz+NGjVKtWrV0tKlSws8b+zYsdcdJyEhQVOnTnVom/i3yXpu0pTiChWl0G23R9n/O1JS02bN1bt7tD5etUqPDB7ivsAA/CGD+nXU55v26+iJcwX2P9K3vd5fs01Z2TklHBk8nbXqf25MAGvUqCHDMLRy5cprnmMYxg0TwLi4OI0bN86hzfSm+mc1/v7+iqxXT0eOHHJ3KACKqEZYRd3Zrr4GPPV2gf2dWtRR/YhQPfzMogL7ARSe2xLAQ4cOFcs4Nlv+6d5L/GFoOdnZ2frppx/VomUrd4cCoIge/lMHHT99Xmv+s6/A/kH9Oujb/Ue05/tfSzgyWILFSoBuexTchg0b1LBhQ6Wnp+frO3funBo1aqT//Oc/bogMN4NXX56ubcnf6Jdfftbu3bv0ZOxYZVy4oD/1+7O7QwNQBIZh6JG+7bXk06+Vm3slX39AOV/dE91Ci1dudkN0gOdxWwVw1qxZGj58uAIDA/P1BQUFacSIEZo5c6Zuv/12N0SH0u7YsTQ98/Q4nTlzVhWDK6pp0+Z6d+kHCg+v5u7QABTBne3qq0ZYsBJXbS2w/75urWTI0Adrt5VwZLAKqz0KzjBN03THhWvWrKm1a9fq1ltvLbD/u+++U9euXXXkyBGnx2YKGPBcFduMcXcIAFzkWk99KQlf/1jwjUfFoV2dIJeNXVRuqwAeO3ZMPj4+1+wvU6aMTpw4UYIRAQAAq7LYNoDuWwNYrVo17dmz55r9u3fvVlhYWAlGBAAArMpw4VEauS0B7NmzpyZNmqRLly7l68vMzNTkyZPVu3dvN0QGAADg2dy2BvDYsWNq2bKlvL29NWbMGNWvX1+GYSglJUVz585Vbm6utm/frpCQEKfHZg0g4LlYAwh4LneuAUxOdd0awDYRrAG0CwkJ0ebNmzVq1CjFxcUpLw81DEPdunXTvHnzipT8AQAA4PrclgBKV+8EXr16tc6cOaODBw/KNE1FRkaqYkWe5QoAAEqO1baBcWsCmKdixYpq06aNu8MAAACwhFKRAAIAALgT28AAAADAo1EBBAAAlmexAiAVQAAAgNKyE3RCQoLatGmjgIAAVa1aVf369dOBAwcczjFNU1OmTFF4eLj8/PzUuXNn7du3z6nrkAACAACUEklJSRo9erS2bt2q9evXKycnR127dlVGRob9nBkzZmjmzJmaM2eOkpOTFRoaqujoaJ0/f77Q13HbRtCuxEbQgOdiI2jAc7lzI+gdhwufPDmrYWhZZWVlObTZbDbZbLYbvvbEiROqWrWqkpKSdMcdd8g0TYWHhys2NlYTJkyQJGVlZSkkJETTp0/XiBEjChUTFUAAAAAXSkhIUFBQkMORkJBQqNeeO3f1CSXBwcGSpNTUVKWlpalr1672c2w2m6KiorR58+ZCx8RNIAAAwPJcuQ1MXFycxo0b59BWmOqfaZoaN26cbrvtNjVu3FiSlJaWJkn5npYWEhKiw4cPFzomEkAAAAAXKux07++NGTNGu3fv1n//+998fcbvMlbTNPO1XQ9TwAAAwPJKyU3Ado8//rg+/vhjbdy4Ubfccou9PTQ0VNL/VQLzHD9+PF9V8HpIAAEAAEoJ0zQ1ZswYrVixQhs2bFBERIRDf0REhEJDQ7V+/Xp7W3Z2tpKSktSxY8dCX4cpYAAAgFKyE/To0aO1dOlS/etf/1JAQIC90hcUFCQ/Pz8ZhqHY2FjFx8crMjJSkZGRio+Pl7+/vwYOHFjo65AAAgAAyzNKSQY4f/58SVLnzp0d2hctWqTBgwdLksaPH6/MzEzFxMTozJkzateundatW6eAgIBCX4d9AAHcVNgHEPBc7twHcPfPF1w2dtPq5V02dlFRAQQAAJbnym1gSiNuAgEAALAYKoAAAMDyLFYApAIIAABgNVQAAQAALFYCpAIIAABgMVQAAQCA5ZWWfQBLChVAAAAAi6ECCAAALM9q+wCSAAIAAMuzWP7HFDAAAIDVUAEEAACwWAmQCiAAAIDFUAEEAACWxzYwAAAA8GhUAAEAgOVZbRsYKoAAAAAWQwUQAABYnsUKgCSAAAAAVssAmQIGAACwGCqAAADA8tgGBgAAAB6NCiAAALA8toEBAACAR6MCCAAALM9iBUAqgAAAAFZDBRAAAMBiJUASQAAAYHlsAwMAAACPRgUQAABYHtvAAAAAwKNRAQQAAJZnsQIgFUAAAACroQIIAABgsRIgFUAAAACLoQIIAAAsz2r7AJIAAgAAy2MbGAAAAHg0KoAAAMDyLFYApAIIAABgNVQAAQCA5bEGEAAAAB6NCiAAAIDFVgFSAQQAALAYKoAAAMDyrLYGkAQQAABYnsXyP6aAAQAArIYKIAAAsDyrTQFTAQQAALAYKoAAAMDyDIutAqQCCAAAYDFUAAEAAKxVAKQCCAAAYDUkgAAAwPIMFx7O+ve//60+ffooPDxchmFo1apVDv2maWrKlCkKDw+Xn5+fOnfurH379jl1DRJAAABgeYbhusNZGRkZatasmebMmVNg/4wZMzRz5kzNmTNHycnJCg0NVXR0tM6fP1/oa7AGEAAAoBTp0aOHevToUWCfaZqaNWuWJk6cqHvuuUeSlJiYqJCQEC1dulQjRowo1DWoAAIAAMszXPi/rKwspaenOxxZWVlFijM1NVVpaWnq2rWrvc1msykqKkqbN28u9DgkgAAAAC6UkJCgoKAghyMhIaFIY6WlpUmSQkJCHNpDQkLsfYXBFDAAAIALt4GJi4vTuHHjHNpsNtsfGtP43eJC0zTztV0PCSAAAIAL2Wy2P5zw5QkNDZV0tRIYFhZmbz9+/Hi+quD1MAUMAAAsrzRtA3M9ERERCg0N1fr16+1t2dnZSkpKUseOHQs9DhVAAACAUuTChQs6ePCg/evU1FTt3LlTwcHBqlGjhmJjYxUfH6/IyEhFRkYqPj5e/v7+GjhwYKGvQQIIAAAsryj79bnKtm3b1KVLF/vXeesHBw0apMWLF2v8+PHKzMxUTEyMzpw5o3bt2mndunUKCAgo9DUM0zTNYo/czS7luDsCAK5Ssc0Yd4cAwEUydxS88XFJOJ2R67Kxg8t5u2zsomINIAAAgMUwBQwAACyvNE0BlwQqgAAAABZDAggAAGAxJIAAAAAWwxpAAABgeawBBAAAgEejAggAACzPKPaHtpVuJIAAAMDymAIGAACAR6MCCAAALM9iBUAqgAAAAFZDBRAAAMBiJUAqgAAAABZDBRAAAFie1baBoQIIAABgMVQAAQCA5bEPIAAAADwaFUAAAGB5FisAkgACAABYLQNkChgAAMBiqAACAADLYxsYAAAAeDQqgAAAwPLYBgYAAAAezTBN03R3EEBRZWVlKSEhQXFxcbLZbO4OB0Ax4vcbcB0SQNzU0tPTFRQUpHPnzikwMNDd4QAoRvx+A67DFDAAAIDFkAACAABYDAkgAACAxZAA4qZms9k0efJkFogDHojfb8B1uAkEAADAYqgAAgAAWAwJIAAAgMWQAAIAAFgMCSAAAIDFkACiVBo8eLAMw9DIkSPz9cXExMgwDA0ePNjelpaWpscff1y1a9eWzWZT9erV1adPH3355Zf2c2rVqqVZs2aVQPQAnHGj399atWrJMAxt3brV4XWxsbHq3LmzGyIGbn4kgCi1qlevruXLlyszM9PedunSJS1btkw1atSwtx06dEitWrXShg0bNGPGDO3Zs0dr165Vly5dNHr0aHeEDqCQCvv76+vrqwkTJrgxUsCzlHF3AMC1tGzZUj/99JNWrFihBx98UJK0YsUKVa9eXbVr17afl1cR/Oabb1SuXDl7e6NGjTR06NASjxtA4RX293fEiBGaP3++Vq9erZ49e7ojVMCjUAFEqTZkyBAtWrTI/vXChQsd/lE4ffq01q5dq9GjRzv845GnQoUKJREmgCJw5ve3Vq1aGjlypOLi4nTlypUSjBLwTCSAKNUefvhh/fe//9WhQ4d0+PBhbdq0SQ899JC9/+DBgzJNUw0aNHBjlACKwtnf3+eee06pqalasmSJiyMDPB9TwCjVKleurF69eikxMVGmaapXr16qXLmyvT/vQTaGYbgrRABF5Ozvb5UqVfTUU09p0qRJ6t+/vytDAzweFUCUekOHDtXixYuVmJiYb01fZGSkDMNQSkqKm6IDUFRF+f0dN26cMjMzNW/ePBdGBng+EkCUet27d1d2drays7PVrVs3h77g4GB169ZNc+fOVUZGRr7Xnj17toSiBOCsovz+li9fXn/729/04osvKj09vQSiBDwTCSBKPW9vb6WkpCglJUXe3t75+ufNm6fc3Fy1bdtWH330kX744QelpKRo9uzZ6tChgxsiBlBYRfn9feyxxxQUFKRly5aVcLSA5yABxE0hMDBQgYGBBfZFRERo+/bt6tKli5588kk1btxY0dHR+vLLLzV//vwSjhSAM4ry++vj46MXXnhBly5dKuFoAc9hmHmrcAEAAGAJVAABAAAshgQQAADAYkgAAQAALIYEEAAAwGJIAAEAACyGBBAAAMBiSAABAAAshgQQAADAYkgAAfxhU6ZMUfPmze1fDx48WP369SvxOA4dOiTDMLRz585rnlOrVi3NmjWr0GMuXrxYFSpU+MOxGYahVatW/eFxAKA4kAACHmrw4MEyDEOGYcjHx0e1a9fWU089pYyMDJdf+/XXX9fixYsLdW5hkjYAQPEq4+4AALhO9+7dtWjRIl2+fFn/+c9/9OijjyojI6PAZ6xevnxZPj4+xXLdoKCgYhkHAOAaVAABD2az2RQaGqrq1atr4MCBevDBB+3TkHnTtgsXLlTt2rVls9lkmqbOnTunxx57TFWrVlVgYKDuvPNO7dq1y2Hcl156SSEhIQoICNCwYcN06dIlh/7fTwFfuXJF06dPV926dWWz2VSjRg29+OKLkqSIiAhJUosWLWQYhjp37mx/3aJFi3TrrbfK19dXDRo00Lx58xyu880336hFixby9fVV69attWPHDqc/o5kzZ6pJkyYqV66cqlevrpiYGF24cCHfeatWrVK9evXk6+ur6Oho/fzzzw79n3zyiVq1aiVfX1/Vrl1bU6dOVU5OToHXzM7O1pgxYxQWFiZfX1/VqlVLCQkJTscOAEVFBRCwED8/P12+fNn+9cGDB/XBBx/oo48+kre3tySpV69eCg4O1urVqxUUFKQ333xTd911l77//nsFBwfrgw8+0OTJkzV37lzdfvvtevfddzV79mzVrl37mteNi4vT22+/rddee0233Xabjh49qu+++07S1SSubdu2+uKLL9SoUSOVLVtWkvT2229r8uTJmjNnjlq0aKEdO3Zo+PDhKleunAYNGqSMjAz17t1bd955p9577z2lpqbqiSeecPoz8fLy0uzZs1WrVi2lpqYqJiZG48ePd0g2L168qBdffFGJiYkqW7asYmJiNGDAAG3atEmS9Pnnn+uhhx7S7Nmzdfvtt+vHH3/UY489JkmaPHlyvmvOnj1bH3/8sT744APVqFFDP//8c76EEgBcygTgkQYNGmT27dvX/vXXX39tVqpUybz//vtN0zTNyZMnmz4+Pubx48ft53z55ZdmYGCgeenSJYex6tSpY7755pumaZpmhw4dzJEjRzr0t2vXzmzWrFmB105PTzdtNpv59ttvFxhnamqqKcncsWOHQ3v16tXNpUuXOrS98MILZocOHUzTNM0333zTDA4ONjMyMuz98+fPL3Cs36pZs6b52muvXbP/gw8+MCtVqmT/etGiRaYkc+vWrfa2lJQUU5L59ddfm6ZpmrfffrsZHx/vMM67775rhoWF2b+WZK5cudI0TdN8/PHHzTvvvNO8cuXKNeMAAFeiAgh4sE8//VTly5dXTk6OLl++rL59++qNN96w99esWVNVqlSxf/3tt9/qwoULqlSpksM4mZmZ+vHHHyVJKSkpGjlypEN/hw4dtHHjxgJjSElJUVZWlu66665Cx33ixAn9/PPPGjZsmIYPH25vz8nJsa8vTElJUbNmzeTv7+8Qh7M2btyo+Ph47d+/X+np6crJydGlS5eUkZGhcuXKSZLKlCmj1q1b21/ToEEDVahQQSkpKWrbtq2+/fZbJScn26e1JSk3N1eXLl3SxYsXHWKUrk6RR0dHq379+urevbt69+6trl27Oh07ABQVCSDgwbp06aL58+fLx8dH4eHh+W7yyEtw8ly5ckVhYWH66quv8o1V1K1Q/Pz8nH7NlStXJF2dBm7Xrp1DX95UtWmaRYrntw4fPqyePXtq5MiReuGFFxQcHKz//ve/GjZsmMNUuXR1G5ffy2u7cuWKpk6dqnvuuSffOb6+vvnaWrZsqdTUVK1Zs0ZffPGF7r//ft1999368MMP//B7AoDCIAEEPFi5cuVUt27dQp/fsmVLpaWlqUyZMqpVq1aB59x6663aunWrHnnkEXvb1q1brzlmZGSk/Pz89OWXX+rRRx/N15+35i83N9feFhISomrVqumnn37Sgw8+WOC4DRs21LvvvqvMzEx7knm9OAqybds25eTk6NVXX5WX19V74j744IN85+Xk5Gjbtm1q27atJOnAgQM6e/asGjRoIOnq53bgwAGnPuvAwED1799f/fv317333qvu3bvr9OnTCg4Oduo9AEBRkAACsLv77rvVoUMH9evXT9OnT1f9+vX1v//9T6tXr1a/fv3UunVrPfHEExo0aJBat26t2267TUuWLNG+ffuueROIr6+vJkyYoPHjx6ts2bLq1KmTTpw4oX379mnYsGGqWrWq/Pz8tHbtWt1yyy3y9fVVUFCQpkyZorFjxyowMFA9evRQVlaWtm3bpjNnzmjcuHEaOHCgJk6cqGHDhum5557ToUOH9Morrzj1fuvUqaOcnBy98cYb6tOnjzZt2qQFCxbkO8/Hx0ePP/64Zs+eLR8fH40ZM0bt27e3J4STJk1S7969Vb16dd13333y8vLS7t27tWfPHk2bNi3feK+99prCwsLUvHlzeXl56Z///KdCQ0OLZcNpACgMtoEBYGcYhlavXq077rhDQ4cOVb169TRgwAAdOnRIISEhkqT+/ftr0qRJmjBhglq1aqXDhw9r1KhR1x33b3/7m5588klNmjRJt956q/r376/jx49Lurq+bvbs2XrzzTcVHh6uvn37SpIeffRRvfPOO1q8eLGaNGmiqKgoLV682L5tTPny5fXJJ59o//79atGihSZOnKjp06c79X6bN2+umTNnavr06WrcuLGWLFlS4HYs/v7+mjBhggYOHKgOHTrIz89Py5cvt/d369ZNn376qdavX682bdqoffv2mjlzpmrWrFngdcuXL6/p06erdevWatOmjQ4dOqTVq1fbq5AA4GqGWRwLaQAAAHDT4M9NAAAAiyEBBAAAsBgSQAAAAIshAQQAALAYEkAAAACLIQEEAACwGBJAAAAAiyEBBAAAsBgSQAAAAIshAQQAALAYEkAAAACL+X/eMtbOho355gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "predictions = saved_model.predict(test_dataset, steps=len(test_paths) // batch_size)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "\n",
    "conf_matrix = confusion_matrix(test_labels[:len(predicted_labels)], predicted_labels)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='g', cmap='Blues', \n",
    "            xticklabels=['MCI', 'CN'], yticklabels=['MCI', 'CN'])\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('MCI vs CN: Regions of Interests')\n",
    "plt.savefig('confusion_matrix_roi_MCIvsCN.png')\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_conda",
   "language": "python",
   "name": "tf_conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
